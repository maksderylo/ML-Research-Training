{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SAE implementations",
   "id": "c36299e8cc347f22"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:56.879847Z",
     "start_time": "2025-11-01T16:15:54.886541Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.training = True\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.k_top = k_top\n",
    "        self.name = \"Default Sparse Autoencoder\"\n",
    "\n",
    "        # Encoder maps input to hidden representation\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Decoder maps hidden representation back to input space\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def _topk_mask(self, activations: torch.Tensor) -> torch.Tensor:\n",
    "        # activations: (batch, hidden)\n",
    "        k = max(0, min(self.k_top, activations.size(1)))\n",
    "        _, idx = torch.topk(activations, k, dim=1)\n",
    "        mask = torch.zeros_like(activations)\n",
    "        mask.scatter_(1, idx, 1.0)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        pre_activations = self.encoder(x)\n",
    "        pre_activations = F.relu(pre_activations)\n",
    "        mask = self._topk_mask(pre_activations)\n",
    "        h = pre_activations * mask\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat\n",
    "\n",
    "\n",
    "    def compute_loss(self, x, h, x_hat):\n",
    "        # We compute sum of squares and normalize by batch size\n",
    "        recon_loss = torch.sum((x - x_hat) ** 2) / (x.size(0))\n",
    "\n",
    "        return recon_loss"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:56.933964Z",
     "start_time": "2025-11-01T16:15:56.931127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderInit(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20):\n",
    "        super(SparseAutoencoderInit, self).__init__(input_size, hidden_size, k_top)\n",
    "\n",
    "        self.name = \"Sparse Autoencoder with just weight initialization\"\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n"
   ],
   "id": "a70c6493dc195d4d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:56.985106Z",
     "start_time": "2025-11-01T16:15:56.981647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderJumpReLU(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20, jump_value=0.1):\n",
    "        super(SparseAutoencoderJumpReLU, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Jump ReLU\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        # Apply JumpReLU\n",
    "        h = torch.where(h > self.jump_value, h, torch.zeros_like(h))\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat"
   ],
   "id": "5d8d293203ac3d5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:57.021782Z",
     "start_time": "2025-11-01T16:15:57.018244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderInitJumpReLU(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20, jump_value=0.1):\n",
    "        super(SparseAutoencoderInitJumpReLU, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Initialization and Jump ReLU\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        # Apply JumpReLU\n",
    "        h = torch.where(h > self.jump_value, h, torch.zeros_like(h))\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat"
   ],
   "id": "aa80385d49115bf2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implementing auxiliary loss SAE",
   "id": "b565b8d2503ed656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:57.078622Z",
     "start_time": "2025-11-01T16:15:57.072851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderAuxLoss(SparseAutoencoder):\n",
    "    def __init__(self, input_size, hidden_size, k_top, k_aux, k_aux_param, dead_feature_threshold):\n",
    "        super(SparseAutoencoderAuxLoss, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Auxiliary Loss\"\n",
    "        # k_aux is typically 2*k or more to revive dead features\n",
    "        self.k_aux = k_aux if k_aux is not None else 2 * k_top\n",
    "        self.k_aux_param = k_aux_param\n",
    "        # Track dead features: count steps since each feature was last active\n",
    "        self.register_buffer('steps_since_active', torch.zeros(hidden_size))\n",
    "        self.dead_feature_threshold = dead_feature_threshold\n",
    "\n",
    "    # Function to track which features are dead\n",
    "    def _update_dead_features(self, h: torch.Tensor):\n",
    "        # Feature is active if ANY sample in batch activates it\n",
    "        active_mask = (h.abs() > 1e-8).any(dim=0)\n",
    "\n",
    "        # Increment counter for inactive features, reset for active ones\n",
    "        self.steps_since_active += 1\n",
    "        self.steps_since_active[active_mask] = 0\n",
    "\n",
    "    def _get_dead_feature_mask(self) -> torch.Tensor:\n",
    "        \"\"\"Return boolean mask of dead features\"\"\"\n",
    "        return self.steps_since_active > self.dead_feature_threshold\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        x_hat = self.decoder(h)\n",
    "\n",
    "        # Track dead features during training\n",
    "        if self.training:\n",
    "            self._update_dead_features(h)\n",
    "\n",
    "        return h, x_hat\n",
    "\n",
    "    def compute_loss(self, x, h, x_hat):\n",
    "\n",
    "        recon_loss = torch.sum((x - x_hat) ** 2) / x.size(0)\n",
    "\n",
    "        aux_loss = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "        if self.training:\n",
    "            dead_mask = self._get_dead_feature_mask()\n",
    "            n_dead = dead_mask.sum().item()\n",
    "\n",
    "            if n_dead > 0:\n",
    "                recon_error_vec = x - x_hat\n",
    "                h_raw = self.encoder(x)\n",
    "\n",
    "                h_dead = h_raw * dead_mask.float().unsqueeze(0)\n",
    "                k_aux_features = min(self.k_aux, n_dead)\n",
    "                _, idx_aux = torch.topk(h_dead, k_aux_features, dim=1)\n",
    "                mask_aux = torch.zeros_like(h_dead)\n",
    "                mask_aux.scatter_(1, idx_aux, 1.0)\n",
    "\n",
    "                z_aux = h_raw * mask_aux\n",
    "                e_hat = self.decoder(z_aux)\n",
    "\n",
    "                aux_loss = torch.sum((recon_error_vec - e_hat) ** 2) / x.size(0)\n",
    "\n",
    "        total_loss = recon_loss + self.k_aux_param * aux_loss\n",
    "        return total_loss, recon_loss, aux_loss\n",
    "\n"
   ],
   "id": "72f4004d2c87ef37",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Complete with relu, init and aux loss implementation.",
   "id": "bcf91031d67e0628"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:57.134667Z",
     "start_time": "2025-11-01T16:15:57.125246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderComplete(SparseAutoencoder):\n",
    "    def __init__(self, input_size, hidden_size, k_top, k_aux, k_aux_param, dead_feature_threshold, jump_value):\n",
    "        super(SparseAutoencoderComplete, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "        # k_aux is typically 2*k or more to revive dead features\n",
    "        self.k_aux = k_aux if k_aux is not None else 2 * k_top\n",
    "        self.k_aux_param = k_aux_param\n",
    "        # Track dead features: count steps since each feature was last active\n",
    "        self.register_buffer('steps_since_active', torch.zeros(hidden_size))\n",
    "        self.dead_feature_threshold = dead_feature_threshold\n",
    "\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n",
    "\n",
    "    # Function to track which features are dead\n",
    "    def _update_dead_features(self, h: torch.Tensor):\n",
    "        # Feature is active if ANY sample in batch activates it\n",
    "        active_mask = (h.abs() > 1e-8).any(dim=0)\n",
    "\n",
    "        # Increment counter for inactive features, reset for active ones\n",
    "        self.steps_since_active += 1\n",
    "        self.steps_since_active[active_mask] = 0\n",
    "\n",
    "    def _get_dead_feature_mask(self) -> torch.Tensor:\n",
    "        \"\"\"Return boolean mask of dead features\"\"\"\n",
    "        return self.steps_since_active > self.dead_feature_threshold\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pre_activations = self.encoder(x)\n",
    "        pre_activations = F.relu(pre_activations)\n",
    "        mask = self._topk_mask(pre_activations)\n",
    "        h = pre_activations * mask\n",
    "        x_hat = self.decoder(h)\n",
    "\n",
    "        # Track dead features during training\n",
    "        if self.training:\n",
    "            self._update_dead_features(h)\n",
    "\n",
    "        return h, x_hat\n",
    "\n",
    "    def compute_loss(self, x, h, x_hat):\n",
    "        # Main reconstruction loss\n",
    "        recon_error = torch.sum((x - x_hat) ** 2)\n",
    "        recon_loss = recon_error / x.size(0)\n",
    "\n",
    "        # Auxiliary loss using dead features only\n",
    "        aux_loss = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "        if self.training:\n",
    "            dead_mask = self._get_dead_feature_mask()  # (hidden_size,)\n",
    "            n_dead = dead_mask.sum().item()\n",
    "\n",
    "            if n_dead > 0:\n",
    "                # Compute reconstruction error: e = x - x_hat\n",
    "                recon_error_vec = x - x_hat  # (batch, input_size)\n",
    "\n",
    "                # Get raw activations again (before TopK masking)\n",
    "                with torch.no_grad():\n",
    "                    h_raw = self.encoder(x)\n",
    "\n",
    "                # Select only dead features\n",
    "                h_dead = h_raw * dead_mask.float().unsqueeze(0)  # (batch, hidden_size)\n",
    "\n",
    "                # Select top-k_aux dead features\n",
    "                k_aux_features = min(self.k_aux, n_dead)\n",
    "                _, idx_aux = torch.topk(h_dead, k_aux_features, dim=1)\n",
    "                mask_aux = torch.zeros_like(h_dead)\n",
    "                mask_aux.scatter_(1, idx_aux, 1.0)\n",
    "\n",
    "                # Sparse activations using only dead features\n",
    "                z_aux = h_raw * mask_aux  # (batch, hidden_size)\n",
    "\n",
    "                # Reconstruct error using dead features\n",
    "                e_hat = self.decoder(z_aux)  # (batch, input_size)\n",
    "\n",
    "                # Auxiliary loss: ||e - e_hat||^2\n",
    "                aux_loss = torch.sum((recon_error_vec - e_hat) ** 2) / x.size(0)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = recon_loss + self.k_aux_param * aux_loss\n",
    "\n",
    "        return total_loss, recon_loss, aux_loss"
   ],
   "id": "6b95f44957f5b99f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading and Preprocessing",
   "id": "1c8bfa281ef7655d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:58.906504Z",
     "start_time": "2025-11-01T16:15:57.179215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, Subset\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_mnist_data(batch_size=256):\n",
    "    # First load raw data to compute mean\n",
    "    raw_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to [0,1] and creates tensor\n",
    "    ])\n",
    "\n",
    "    # Load training set to compute mean\n",
    "    trainset_raw = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                              download=True, transform=raw_transform)\n",
    "\n",
    "    # Compute mean over entire training set\n",
    "    train_loader_temp = DataLoader(trainset_raw, batch_size=len(trainset_raw), shuffle=False)\n",
    "    all_data = next(iter(train_loader_temp))[0]\n",
    "    all_data = all_data.view(all_data.size(0), -1)  # Flatten to (N, 784)\n",
    "    dataset_mean = all_data.mean(dim=0)  # Mean across samples, shape (784,)\n",
    "\n",
    "    # Define preprocessing transform with mean subtraction and normalization\n",
    "    def preprocess(x):\n",
    "        x_flat = x.view(-1)  # Flatten from (1, 28, 28) to (784,)\n",
    "        x_centered = x_flat - dataset_mean  # Subtract mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)  # Normalize to unit norm\n",
    "        return x_norm\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(preprocess)\n",
    "    ])\n",
    "\n",
    "    # Load datasets with proper preprocessing\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "9dffec9ed378ec9c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:58.946473Z",
     "start_time": "2025-11-01T16:15:58.943591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b4de654eb035f402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.047761Z",
     "start_time": "2025-11-01T16:15:59.041069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_olivetti_data(batch_size=32, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Load Olivetti Faces dataset (400 images, 64x64 grayscale)\n",
    "    Returns data with shape (N, 4096) after flattening\n",
    "    \"\"\"\n",
    "    # Download Olivetti Faces using sklearn\n",
    "    faces = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
    "    data = faces.data  # Already normalized to [0, 1], shape (400, 4096)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    data_tensor = torch.FloatTensor(data)  # Shape: (400, 4096)\n",
    "\n",
    "    # Compute mean over entire dataset\n",
    "    dataset_mean = data_tensor.mean(dim=0)  # Shape: (4096,)\n",
    "\n",
    "    # Define preprocessing function\n",
    "    def preprocess(x):\n",
    "        x_centered = x - dataset_mean  # Subtract mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)  # Unit norm\n",
    "        return x_norm\n",
    "\n",
    "    # Apply preprocessing to all data\n",
    "    preprocessed_data = torch.stack([preprocess(x) for x in data_tensor])\n",
    "\n",
    "    # Create dataset (no labels needed for autoencoder)\n",
    "    dataset = TensorDataset(preprocessed_data)\n",
    "\n",
    "    # Split into train/test\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainset, testset = random_split(dataset, [train_size, test_size],\n",
    "                                     generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "d600891fa864567",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.076362Z",
     "start_time": "2025-11-01T16:15:59.065429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def load_imagenet_subset(batch_size=128, subset_size=50000, img_size=64,\n",
    "                         data_root='./data/imagenet', use_color=True):\n",
    "    train_dir = os.path.join(data_root, 'train')\n",
    "    val_dir = os.path.join(data_root, 'val_organized')\n",
    "\n",
    "    # Raw transform for mean computation\n",
    "    if use_color:\n",
    "        raw_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        num_channels = 3\n",
    "    else:\n",
    "        raw_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        num_channels = 1\n",
    "\n",
    "    # Compute mean on subset\n",
    "    print(\"Computing dataset mean...\")\n",
    "    trainset_raw = ImageFolder(train_dir, transform=raw_transform)\n",
    "    mean_indices = torch.randperm(len(trainset_raw))[:10000].tolist()\n",
    "    trainset_mean = Subset(trainset_raw, mean_indices)\n",
    "\n",
    "    temp_loader = DataLoader(trainset_mean, batch_size=256,\n",
    "                            num_workers=4, pin_memory=True)\n",
    "\n",
    "    mean_accumulator = None\n",
    "    count = 0\n",
    "    for batch_data, _ in temp_loader:\n",
    "        batch_flat = batch_data.view(batch_data.size(0), -1)\n",
    "        if mean_accumulator is None:\n",
    "            mean_accumulator = batch_flat.sum(dim=0)\n",
    "        else:\n",
    "            mean_accumulator += batch_flat.sum(dim=0)\n",
    "        count += batch_data.size(0)\n",
    "\n",
    "    dataset_mean = mean_accumulator / count\n",
    "    print(f\"✓ Mean computed over {count} images\")\n",
    "\n",
    "    # Preprocessing with mean subtraction\n",
    "    def preprocess(x):\n",
    "        x_flat = x.view(-1)\n",
    "        x_centered = x_flat - dataset_mean\n",
    "        norm = torch.norm(x_centered)\n",
    "        return x_centered / (norm + 1e-8) if norm > 1e-8 else x_centered\n",
    "\n",
    "    if use_color:\n",
    "        final_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(preprocess)\n",
    "        ])\n",
    "    else:\n",
    "        final_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(preprocess)\n",
    "        ])\n",
    "\n",
    "    trainset = ImageFolder(train_dir, transform=final_transform)\n",
    "    testset = ImageFolder(val_dir, transform=final_transform)\n",
    "\n",
    "    if subset_size and subset_size < len(trainset):\n",
    "        subset_indices = torch.randperm(len(trainset))[:subset_size].tolist()\n",
    "        trainset = Subset(trainset, subset_indices)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size,\n",
    "                            shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(f\"✓ Loaders ready: {len(train_loader)} train batches\")\n",
    "    return train_loader, test_loader, dataset_mean\n"
   ],
   "id": "3ccddad406245d3b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.139065Z",
     "start_time": "2025-11-01T16:15:59.132375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def load_lfw_data(batch_size=128, img_size=64, min_faces_per_person=20):\n",
    "    \"\"\"\n",
    "    Load Labeled Faces in the Wild dataset with proper resizing\n",
    "\n",
    "    Args:\n",
    "        batch_size: Batch size\n",
    "        img_size: Resize to (img_size, img_size) - actual pixels\n",
    "        min_faces_per_person: Filter people with fewer images\n",
    "    \"\"\"\n",
    "    # Download LFW with original size\n",
    "    lfw_people = fetch_lfw_people(\n",
    "        min_faces_per_person=min_faces_per_person,\n",
    "        resize=1.0,  # Keep original size, we'll resize manually\n",
    "        color=False\n",
    "    )\n",
    "\n",
    "    print(f\"Original LFW shape: {lfw_people.images.shape}\")\n",
    "\n",
    "    # Manually resize to exact dimensions\n",
    "    resized_images = []\n",
    "    for img in lfw_people.images:\n",
    "        # Convert to PIL Image for proper resizing\n",
    "        pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        # Resize to exact target size\n",
    "        pil_img = pil_img.resize((img_size, img_size), Image.LANCZOS)\n",
    "        # Back to normalized array\n",
    "        resized = np.array(pil_img).astype(np.float32) / 255.0\n",
    "        resized_images.append(resized.flatten())\n",
    "\n",
    "    data_flat = np.array(resized_images)\n",
    "    print(f\"Resized LFW shape: {data_flat.shape}\")  # Should be (n_samples, img_size²)\n",
    "\n",
    "    # Convert to torch\n",
    "    data_tensor = torch.FloatTensor(data_flat)\n",
    "\n",
    "    # Compute mean\n",
    "    dataset_mean = data_tensor.mean(dim=0)\n",
    "\n",
    "    # Preprocess\n",
    "    def preprocess(x):\n",
    "        x_centered = x - dataset_mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)\n",
    "        return x_norm\n",
    "\n",
    "    preprocessed_data = torch.stack([preprocess(x) for x in data_tensor])\n",
    "\n",
    "    # Create dataset\n",
    "    class LFWDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return (self.data[idx],)\n",
    "\n",
    "    dataset = LFWDataset(preprocessed_data)\n",
    "\n",
    "    # Split 80/20\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainset, testset = random_split(dataset, [train_size, test_size],\n",
    "                                     generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"LFW Dataset loaded: {len(trainset)} train, {len(testset)} test\")\n",
    "    print(f\"Image size: {img_size}×{img_size}, Input dimension: {img_size**2}\")\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "3c3c819edc1dfd03",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.195936Z",
     "start_time": "2025-11-01T16:15:59.189537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.datasets import fetch_olivetti_faces, fetch_lfw_people\n",
    "from PIL import Image\n",
    "\n",
    "def load_data(dataset_name, batch_size=128, img_size=64, **kwargs):\n",
    "    \"\"\"\n",
    "    Unified data loading function for multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: One of ['mnist', 'olivetti', 'lfw', 'imagenet']\n",
    "        batch_size: Batch size for DataLoader\n",
    "        img_size: Image size for face datasets (default 64)\n",
    "        **kwargs: Additional dataset-specific arguments\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for training\n",
    "        test_loader: DataLoader for testing\n",
    "        dataset_mean: Mean vector used for preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset_name.lower() == 'mnist':\n",
    "        return load_mnist_data(batch_size)\n",
    "\n",
    "    elif dataset_name.lower() == 'olivetti':\n",
    "        train_split = kwargs.get('train_split', 0.8)\n",
    "        return load_olivetti_data(batch_size, train_split)\n",
    "\n",
    "    elif dataset_name.lower() == 'lfw':\n",
    "        min_faces_per_person = kwargs.get('min_faces_per_person', 20)\n",
    "        return load_lfw_data(batch_size, img_size, min_faces_per_person)\n",
    "\n",
    "    elif dataset_name.lower() == 'imagenet':\n",
    "        subset_size = kwargs.get('subset_size', 10000)\n",
    "        data_root = kwargs.get('data_root', './data/imagenet')\n",
    "        return load_imagenet_subset(batch_size, subset_size, img_size, data_root)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}. Choose from ['mnist', 'olivetti', 'lfw', 'imagenet']\")\n"
   ],
   "id": "beab04ad03948608",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training function",
   "id": "50475f90ab2b747d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.248440Z",
     "start_time": "2025-11-01T16:15:59.241613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "def train_sparse_autoencoder(train_loader, num_epochs=50, learning_rate=0.001,\n",
    "                            input_size=784, hidden_size=64, k_top=20,\n",
    "                            JumpReLU=0.1, k_aux=None, k_aux_param=1/32,\n",
    "                            dead_feature_threshold=1000, modelType=\"SAE\",\n",
    "                            dataset_type=\"mnist\"):\n",
    "    \"\"\"\n",
    "    Train sparse autoencoder with support for different datasets\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader for training data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' to handle different unpacking\n",
    "        ... (other args as before)\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if modelType == \"SAE\":\n",
    "        model = SparseAutoencoder(input_size=input_size, hidden_size=hidden_size, k_top=k_top).to(device)\n",
    "    elif modelType == \"SAE_Init_JumpReLU\":\n",
    "        model = SparseAutoencoderInitJumpReLU(input_size=input_size, hidden_size=hidden_size, k_top=k_top, jump_value=JumpReLU).to(device)\n",
    "    elif modelType == \"SAE_JumpReLU\":\n",
    "        model = SparseAutoencoderJumpReLU(input_size=input_size, hidden_size=hidden_size, k_top=k_top, jump_value=JumpReLU).to(device)\n",
    "    elif modelType == \"SAE_Init\":\n",
    "        model = SparseAutoencoderInit(input_size=input_size, hidden_size=hidden_size, k_top=k_top).to(device)\n",
    "    elif modelType == \"SAE_AuxLoss\":\n",
    "        model = SparseAutoencoderAuxLoss(input_size=input_size, hidden_size=hidden_size, k_top=k_top, k_aux=k_aux,\n",
    "                                         k_aux_param=k_aux_param, dead_feature_threshold=dead_feature_threshold).to(device)\n",
    "    elif modelType == \"Complete\":\n",
    "        model = SparseAutoencoderComplete(input_size=input_size, hidden_size=hidden_size, k_top=k_top, k_aux=k_aux,\n",
    "                                         k_aux_param=k_aux_param, dead_feature_threshold=dead_feature_threshold, jump_value=JumpReLU).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid modelType specified.\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                # Olivetti returns single-element tuple: (inputs,)\n",
    "                inputs, = data  # Note the comma - unpacks single element\n",
    "                inputs = inputs.to(device)\n",
    "            elif dataset_type in ['mnist', 'imagenet']:\n",
    "                # MNIST and ImageNet return (inputs, labels)\n",
    "                inputs, _ = data\n",
    "                # No need to reshape - already preprocessed to correct shape\n",
    "                inputs = inputs.to(device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dataset_type: {dataset_type}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            h, outputs = model(inputs)\n",
    "\n",
    "            if modelType == \"SAE_AuxLoss\" or modelType == \"Complete\":\n",
    "                loss, mse_loss, aux_loss = model.compute_loss(inputs, h, outputs)\n",
    "                loss = mse_loss\n",
    "            else:\n",
    "                loss = model.compute_loss(inputs, h, outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp weights to enforce non-negativity\n",
    "            with torch.no_grad():\n",
    "                model.encoder.weight.clamp_(0.0)\n",
    "                model.decoder.weight.clamp_(0.0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model"
   ],
   "id": "ec162a61e1221868",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization functions",
   "id": "e0b92ca01859d5eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.309122Z",
     "start_time": "2025-11-01T16:15:59.295500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def visualize_weights_decoder(model, num_features=64):\n",
    "    \"\"\"\n",
    "    Visualize decoder weights - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    # Auto-detect input size from model\n",
    "    input_size = model.decoder.weight.shape[0]\n",
    "    print(f\"Auto-detected input_size: {input_size}\")\n",
    "\n",
    "    # Determine image shape\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "        dataset_type = 'mnist'\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        # Non-square or unusual size - try square root\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            # Non-square - find factors\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    print(f\"Using image shape: {img_shape}\")\n",
    "\n",
    "    weights = model.decoder.weight.data.cpu().numpy().T\n",
    "    num_features = min(num_features, weights.shape[0])\n",
    "\n",
    "    # Grid dimensions\n",
    "    x_images = int(math.ceil(math.sqrt(num_features)))\n",
    "    y_images = int(math.ceil(num_features / x_images))\n",
    "\n",
    "    plt.figure(figsize=(x_images * 2, y_images * 2))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Decoder Weights ({img_shape[0]}×{img_shape[1]})',\n",
    "                 fontsize=14, y=0.995)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        plt.subplot(y_images, x_images, i + 1)\n",
    "        weight_img = weights[i].reshape(img_shape)\n",
    "\n",
    "        # Normalize\n",
    "        weight_img = (weight_img - weight_img.min()) / (weight_img.max() - weight_img.min() + 1e-8)\n",
    "\n",
    "        plt.imshow(weight_img, cmap='gray', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'F{i}', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_weights_encoder(model, num_features=64):\n",
    "    \"\"\"\n",
    "    Visualize encoder weights - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    # Get weights\n",
    "    if hasattr(model.encoder, 'weight'):\n",
    "        weights = model.encoder.weight.data.cpu().numpy()\n",
    "    elif isinstance(model.encoder, torch.nn.Sequential):\n",
    "        weights = model.encoder[0].weight.data.cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown encoder structure\")\n",
    "\n",
    "    # Auto-detect input size\n",
    "    input_size = weights.shape[1]\n",
    "    print(f\"Auto-detected input_size: {input_size}\")\n",
    "\n",
    "    # Determine image shape\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    print(f\"Using image shape: {img_shape}\")\n",
    "\n",
    "    num_features = min(num_features, weights.shape[0])\n",
    "\n",
    "    x_images = int(math.ceil(math.sqrt(num_features)))\n",
    "    y_images = int(math.ceil(num_features / x_images))\n",
    "\n",
    "    plt.figure(figsize=(x_images * 2, y_images * 2))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Encoder Weights ({img_shape[0]}×{img_shape[1]})',\n",
    "                 fontsize=14, y=0.995)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        plt.subplot(y_images, x_images, i + 1)\n",
    "        weight_img = weights[i].reshape(img_shape)\n",
    "        weight_img = (weight_img - weight_img.min()) / (weight_img.max() - weight_img.min() + 1e-8)\n",
    "        plt.imshow(weight_img, cmap='gray', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'F{i}', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_reconstructions(model, data_loader, num_samples=10, dataset_type='olivetti'):\n",
    "    \"\"\"\n",
    "    Visualize reconstructions - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Get data\n",
    "    data_iter = iter(data_loader)\n",
    "    data = next(data_iter)\n",
    "\n",
    "    if dataset_type == 'olivetti' or len(data) == 1:\n",
    "        inputs, = data\n",
    "    else:\n",
    "        inputs, _ = data\n",
    "\n",
    "    inputs = inputs[:num_samples].to(device)\n",
    "\n",
    "    # Auto-detect dimensions\n",
    "    input_size = inputs.shape[1]\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    # Get reconstructions\n",
    "    with torch.no_grad():\n",
    "        _, reconstructions = model(inputs)\n",
    "\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    reconstructions = reconstructions.cpu().numpy()\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 2, 4))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Reconstructions ({img_shape[0]}×{img_shape[1]})', fontsize=14)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[0, i].imshow(inputs[i].reshape(img_shape), cmap='gray', interpolation='nearest')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Original', fontsize=10)\n",
    "\n",
    "        axes[1, i].imshow(reconstructions[i].reshape(img_shape), cmap='gray', interpolation='nearest')\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Reconstructed', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "c7b1cd1e283aafb6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Functions to count dead neurons and test loss on the dataset given",
   "id": "6f23cd993e61745e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.375871Z",
     "start_time": "2025-11-01T16:15:59.358989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def count_dead_neurons(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Count dead neurons (features that never activate)\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' for proper unpacking\n",
    "\n",
    "    Returns:\n",
    "        num_dead: Number of dead neurons\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dead_neurons = torch.ones(model.hidden_size, dtype=torch.bool).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data  # Single-element tuple\n",
    "            else:  # mnist or imagenet\n",
    "                inputs, _ = data  # (inputs, labels) tuple\n",
    "\n",
    "            inputs = inputs.to(device)  # Already preprocessed, no reshape needed\n",
    "            h, _ = model(inputs)\n",
    "\n",
    "            # A neuron is alive if it activates (h > 0) for any sample\n",
    "            dead_neurons &= (h.sum(dim=0) == 0)\n",
    "\n",
    "    num_dead = dead_neurons.sum().item()\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f'Number of dead neurons in {model_name}: {num_dead} out of {model.hidden_size} '\n",
    "          f'({100*num_dead/model.hidden_size:.2f}%)')\n",
    "    return num_dead\n",
    "\n",
    "\n",
    "def test_loss(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Compute average test loss\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with test data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' for proper unpacking\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: Average loss over test set\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data  # Single-element tuple\n",
    "            else:  # mnist or imagenet\n",
    "                inputs, _ = data  # (inputs, labels) tuple\n",
    "\n",
    "            inputs = inputs.to(device)  # Already preprocessed, no reshape needed\n",
    "            h, outputs = model(inputs)\n",
    "\n",
    "            # Handle different loss outputs\n",
    "            loss_output = model.compute_loss(inputs, h, outputs)\n",
    "            if isinstance(loss_output, tuple):\n",
    "                loss, *_ = loss_output  # Unpack if tuple (e.g., with aux loss)\n",
    "            else:\n",
    "                loss = loss_output\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f'Test Loss for {model_name}: {avg_loss:.6f}')\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def get_activation_statistics(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Get comprehensive statistics about feature activations\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    activation_counts = torch.zeros(model.hidden_size).to(device)\n",
    "    activation_sums = torch.zeros(model.hidden_size).to(device)\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data\n",
    "            else:\n",
    "                inputs, _ = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            h, _ = model(inputs)\n",
    "\n",
    "            # Count how many times each feature activates (h > 0)\n",
    "            activation_counts += (h > 0).sum(dim=0).float()\n",
    "            activation_sums += h.sum(dim=0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    # Move to CPU for analysis\n",
    "    activation_counts = activation_counts.cpu().numpy()\n",
    "    activation_sums = activation_sums.cpu().numpy()\n",
    "\n",
    "    # Compute statistics\n",
    "    activation_freq = activation_counts / total_samples  # Fraction of samples each feature activates on\n",
    "\n",
    "    # FIXED: Only compute mean over ACTIVE features (where count > 0)\n",
    "    active_mask = activation_counts > 0\n",
    "    mean_activation = np.zeros(model.hidden_size)\n",
    "    mean_activation[active_mask] = activation_sums[active_mask] / activation_counts[active_mask]\n",
    "\n",
    "    # Mean strength across ALL active features (not averaged over all samples)\n",
    "    if np.sum(active_mask) > 0:\n",
    "        mean_act_strength_active = np.mean(mean_activation[active_mask])\n",
    "    else:\n",
    "        mean_act_strength_active = 0.0\n",
    "\n",
    "    stats = {\n",
    "        'total_features': model.hidden_size,\n",
    "        'dead_features': np.sum(activation_counts == 0),\n",
    "        'active_features': np.sum(activation_counts > 0),\n",
    "        'mean_activation_frequency': np.mean(activation_freq),\n",
    "        'median_activation_frequency': np.median(activation_freq),\n",
    "        'mean_activation_strength': mean_act_strength_active,  # Corrected calculation\n",
    "        'activation_frequencies': activation_freq,\n",
    "        'activation_strengths': mean_activation,\n",
    "        'activation_counts': activation_counts\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f\"\\n=== Activation Statistics for {model_name} ===\")\n",
    "    print(f\"Total features: {stats['total_features']}\")\n",
    "    print(f\"Dead features: {stats['dead_features']} ({100*stats['dead_features']/stats['total_features']:.2f}%)\")\n",
    "    print(f\"Active features: {stats['active_features']} ({100*stats['active_features']/stats['total_features']:.2f}%)\")\n",
    "    print(f\"Mean activation frequency: {stats['mean_activation_frequency']:.4f}\")\n",
    "    print(f\"Median activation frequency: {stats['median_activation_frequency']:.4f}\")\n",
    "    print(f\"Mean activation strength (when active): {stats['mean_activation_strength']:.6f}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "def plot_activation_histogram(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Plot histogram of feature activation frequencies\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet'\n",
    "    \"\"\"\n",
    "    stats = get_activation_statistics(model, data_loader, dataset_type)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "\n",
    "    # Histogram of activation frequencies\n",
    "    axes[0].hist(stats['activation_frequencies'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Activation Frequency (fraction of samples)')\n",
    "    axes[0].set_ylabel('Number of Features')\n",
    "    axes[0].set_title(f'{model_name}: Feature Activation Frequencies')\n",
    "    axes[0].axvline(stats['mean_activation_frequency'], color='r', linestyle='--',\n",
    "                    label=f'Mean: {stats[\"mean_activation_frequency\"]:.4f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Histogram of activation strengths (excluding dead features)\n",
    "    active_strengths = stats['activation_strengths'][stats['activation_strengths'] > 0]\n",
    "    axes[1].hist(active_strengths, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1].set_xlabel('Mean Activation Strength')\n",
    "    axes[1].set_ylabel('Number of Features')\n",
    "    axes[1].set_title(f'{model_name}: Feature Activation Strengths (Active Features Only)')\n",
    "    axes[1].axvline(stats['mean_activation_strength'], color='r', linestyle='--',\n",
    "                    label=f'Mean: {stats[\"mean_activation_strength\"]:.4f}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "1e6c80537d31d35",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initializing",
   "id": "a25fde095862b2cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.432312Z",
     "start_time": "2025-11-01T16:15:59.429555Z"
    }
   },
   "cell_type": "code",
   "source": "# train_loader, test_loader, mean = load_olivetti_data(batch_size=32)",
   "id": "8105d6e7d4fa8ec0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Base usage",
   "id": "6e3bce16a2613e38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.496797Z",
     "start_time": "2025-11-01T16:15:59.494053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_loader, test_loader, mean = load_data(dataset_name='mnist', batch_size=128)\n",
    "#\n",
    "# modelBase = train_sparse_autoencoder(\n",
    "#     train_loader,\n",
    "#     num_epochs=50,\n",
    "#     learning_rate=0.001,\n",
    "#     input_size=784,\n",
    "#     hidden_size=256,\n",
    "#     k_top=40,\n",
    "#     modelType=\"Complete\",\n",
    "#     dataset_type=\"mnist\"\n",
    "# )\n"
   ],
   "id": "e3bca5d4a7bb234f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.545251Z",
     "start_time": "2025-11-01T16:15:59.542736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# visualize_weights_decoder(modelBase, num_features=256)\n",
    "# count_dead_neurons(modelBase, train_loader, dataset_type='mnist')\n",
    "# test_loss(modelBase, test_loader, dataset_type='mnist')\n",
    "# plot_activation_histogram(modelBase, train_loader, dataset_type='mnist')"
   ],
   "id": "cb2f2d3ae0b69c29",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.608856Z",
     "start_time": "2025-11-01T16:15:59.605879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_loader, test_loader, mean = load_data(dataset_name='imagenet',\n",
    "#                                             batch_size=128,\n",
    "#                                             img_size=64)\n",
    "#\n",
    "# modelImagenet = train_sparse_autoencoder(\n",
    "#     train_loader,\n",
    "#     num_epochs=50,\n",
    "#     learning_rate=0.003,\n",
    "#     input_size=12288,\n",
    "#     hidden_size=2048,\n",
    "#     k_top=64,\n",
    "#     k_aux_param=1/128,\n",
    "#     modelType=\"Complete\",\n",
    "#     dataset_type=\"imagenet\"\n",
    "# )\n"
   ],
   "id": "1059e30a05820489",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.656558Z",
     "start_time": "2025-11-01T16:15:59.654159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# visualize_weights_decoder(modelImagenet, num_features=256)\n",
    "# count_dead_neurons(modelImagenet, train_loader, dataset_type='imagenet')\n",
    "# test_loss(modelImagenet, test_loader, dataset_type='imagenet')\n",
    "# plot_activation_histogram(modelImagenet, train_loader, dataset_type='imagenet')"
   ],
   "id": "760a196f0a67d6b1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TopK Sparsity Analysis",
   "id": "333bad2f014121c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dead neurons",
   "id": "7a523d4271489478"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:59.875615Z",
     "start_time": "2025-11-01T16:15:59.703618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Configuration for comprehensive experiments\n",
    "experiment_configs = {\n",
    "    'mnist': {\n",
    "        'input_size': 784,\n",
    "        'hidden_sizes': [128, 256],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 256,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    'olivetti': {\n",
    "        'input_size': 4096,\n",
    "        'hidden_sizes': [256, 512, 1024],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 32,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    'lfw': {\n",
    "        'input_size': 4096,  # 64x64 images\n",
    "        'hidden_sizes': [512, 1024, 2048],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "}"
   ],
   "id": "d46df9ce4490dac9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:17:11.778441Z",
     "start_time": "2025-11-01T16:15:59.896071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 1: Weight Initialization Comparison\n",
    "# Tests: Random Xavier, Tied Weights, and Baseline\n",
    "# Duration: ~4-6 hours for all datasets\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to safely get activation strength\n",
    "def get_activation_strength_safe(activation_stats):\n",
    "    \"\"\"Safely extract mean activation strength, handling edge cases\"\"\"\n",
    "    if 'mean_activation_strength' in activation_stats:\n",
    "        strength = activation_stats['mean_activation_strength']\n",
    "        # Handle NaN or infinite values\n",
    "        if np.isnan(strength) or np.isinf(strength):\n",
    "            return 0.0\n",
    "        return float(strength)\n",
    "    else:\n",
    "        # If key doesn't exist, compute it manually\n",
    "        activation_strengths = activation_stats.get('activation_strengths', np.array([]))\n",
    "        if len(activation_strengths) > 0 and np.sum(activation_strengths > 0) > 0:\n",
    "            return float(np.mean(activation_strengths[activation_strengths > 0]))\n",
    "        return 0.0\n",
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT 1: Weight Initialization Comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT 1: WEIGHT INITIALIZATION COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "initialization_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    for hidden_size in config['hidden_sizes']:\n",
    "        for k_top in config['k_tops']:\n",
    "            print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "            # Test 3 initialization strategies\n",
    "            init_strategies = ['SAE', 'SAE_Init', 'Complete']\n",
    "\n",
    "            for strategy in init_strategies:\n",
    "                print(f\"  Training {strategy}...\")\n",
    "                set_seeds(42)  # Ensure reproducibility\n",
    "\n",
    "                try:\n",
    "                    # Train model\n",
    "                    model = train_sparse_autoencoder(\n",
    "                        train_loader=train_loader,\n",
    "                        num_epochs=config['num_epochs'],\n",
    "                        learning_rate=config['learning_rate'],\n",
    "                        input_size=config['input_size'],\n",
    "                        hidden_size=hidden_size,\n",
    "                        k_top=k_top,\n",
    "                        modelType=strategy,\n",
    "                        dataset_type=dataset_name,\n",
    "                        k_aux=2*k_top if strategy == 'SAE_Complete' else None,\n",
    "                        k_aux_param=1/32,\n",
    "                        dead_feature_threshold=1000\n",
    "                    )\n",
    "\n",
    "                    # Evaluate\n",
    "                    test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "                    dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "                    activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "                    # Safely extract activation strength\n",
    "                    mean_act_strength = get_activation_strength_safe(activation_stats)\n",
    "\n",
    "                    # Store results\n",
    "                    initialization_results['dataset'].append(dataset_name)\n",
    "                    initialization_results['hidden_size'].append(hidden_size)\n",
    "                    initialization_results['k_top'].append(k_top)\n",
    "                    initialization_results['initialization'].append(strategy)\n",
    "                    initialization_results['test_loss'].append(test_loss_val)\n",
    "                    initialization_results['dead_neurons'].append(dead_neurons_count)\n",
    "                    initialization_results['dead_neuron_pct'].append(\n",
    "                        100 * dead_neurons_count / hidden_size\n",
    "                    )\n",
    "                    initialization_results['active_features'].append(\n",
    "                        activation_stats['active_features']\n",
    "                    )\n",
    "                    initialization_results['mean_activation_freq'].append(\n",
    "                        activation_stats['mean_activation_frequency']\n",
    "                    )\n",
    "                    initialization_results['mean_activation_strength'].append(mean_act_strength)\n",
    "\n",
    "                    print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "                          f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "                    print(f\"    Test loss: {test_loss_val:.6f}\")\n",
    "                    print(f\"    Mean activation strength: {mean_act_strength:.6f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    ERROR training {strategy}: {str(e)}\")\n",
    "                    # Log error but continue with other experiments\n",
    "                    continue\n",
    "\n",
    "# Save results\n",
    "df_init = pd.DataFrame(initialization_results)\n",
    "df_init.to_csv('experiment1_initialization_results.csv', index=False)\n",
    "print(\"\\n✓ Experiment 1 results saved to 'experiment1_initialization_results.csv'\")\n",
    "print(f\"  Total experiments completed: {len(df_init)}\")\n",
    "\n"
   ],
   "id": "a9d98580e76a2ec8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 1: WEIGHT INITIALIZATION COMPARISON\n",
      "================================================================================\n",
      "\n",
      "### Processing MNIST Dataset ###\n",
      "\n",
      "Hidden Size: 128, k_top: 5\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.9188\n",
      "Epoch [2/50], Loss: 0.5331\n",
      "Epoch [3/50], Loss: 0.5171\n",
      "Epoch [4/50], Loss: 0.5109\n",
      "Epoch [5/50], Loss: 0.5064\n",
      "Epoch [6/50], Loss: 0.5047\n",
      "Epoch [7/50], Loss: 0.5041\n",
      "Epoch [8/50], Loss: 0.5038\n",
      "Epoch [9/50], Loss: 0.5037\n",
      "Epoch [10/50], Loss: 0.5033\n",
      "Epoch [11/50], Loss: 0.5030\n",
      "Epoch [12/50], Loss: 0.5028\n",
      "Epoch [13/50], Loss: 0.5028\n",
      "Epoch [14/50], Loss: 0.5025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 69\u001B[39m\n\u001B[32m     65\u001B[39m set_seeds(\u001B[32m42\u001B[39m)  \u001B[38;5;66;03m# Ensure reproducibility\u001B[39;00m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     68\u001B[39m     \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m     model = \u001B[43mtrain_sparse_autoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_epochs\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlearning_rate\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43minput_size\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m        \u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodelType\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdataset_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m        \u001B[49m\u001B[43mk_aux\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m*\u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mSAE_Complete\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m        \u001B[49m\u001B[43mk_aux_param\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m/\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdead_feature_threshold\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\n\u001B[32m     81\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m     \u001B[38;5;66;03m# Evaluate\u001B[39;00m\n\u001B[32m     84\u001B[39m     test_loss_val = test_loss(model, test_loader, dataset_name)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mtrain_sparse_autoencoder\u001B[39m\u001B[34m(train_loader, num_epochs, learning_rate, input_size, hidden_size, k_top, JumpReLU, k_aux, k_aux_param, dead_feature_threshold, modelType, dataset_type)\u001B[39m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[32m     38\u001B[39m     running_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Handle different data loader formats\u001B[39;49;00m\n\u001B[32m     41\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdataset_type\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43molivetti\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlfw\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# Olivetti returns single-element tuple: (inputs,)\u001B[39;49;00m\n\u001B[32m     43\u001B[39m \u001B[43m            \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Note the comma - unpacks single element\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    733\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    735\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    737\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    739\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    740\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    789\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    791\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    792\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torchvision/datasets/mnist.py:146\u001B[39m, in \u001B[36mMNIST.__getitem__\u001B[39m\u001B[34m(self, index)\u001B[39m\n\u001B[32m    143\u001B[39m img = _Image_fromarray(img.numpy(), mode=\u001B[33m\"\u001B[39m\u001B[33mL\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     img = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.target_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    149\u001B[39m     target = \u001B[38;5;28mself\u001B[39m.target_transform(target)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torchvision/transforms/transforms.py:95\u001B[39m, in \u001B[36mCompose.__call__\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transforms:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m         img = \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:17:11.887184765Z",
     "start_time": "2025-10-22T15:07:01.670265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 2: Auxiliary Loss Effects\n",
    "# Tests: SAE with/without auxiliary loss\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPERIMENT 2: AUXILIARY LOSS EFFECTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "auxloss_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    for hidden_size in config['hidden_sizes']:\n",
    "        k_top = config['k_tops'][1]  # Use middle k_top value\n",
    "\n",
    "        print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "        # Test with and without auxiliary loss\n",
    "        for use_aux_loss in [False, True]:\n",
    "            model_type = 'SAE_AuxLoss' if use_aux_loss else 'SAE'\n",
    "            print(f\"  Training {'WITH' if use_aux_loss else 'WITHOUT'} auxiliary loss...\")\n",
    "\n",
    "            set_seeds(42)\n",
    "\n",
    "            # Train model\n",
    "            model = train_sparse_autoencoder(\n",
    "                train_loader=train_loader,\n",
    "                num_epochs=config['num_epochs'],\n",
    "                learning_rate=config['learning_rate'],\n",
    "                input_size=config['input_size'],\n",
    "                hidden_size=hidden_size,\n",
    "                k_top=k_top,\n",
    "                modelType=model_type,\n",
    "                dataset_type=dataset_name,\n",
    "                k_aux=2*k_top if use_aux_loss else None,\n",
    "                k_aux_param=1/32,\n",
    "                dead_feature_threshold=1000\n",
    "            )\n",
    "\n",
    "            # Evaluate\n",
    "            test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "            dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "            activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "            # Store results\n",
    "            auxloss_results['dataset'].append(dataset_name)\n",
    "            auxloss_results['hidden_size'].append(hidden_size)\n",
    "            auxloss_results['k_top'].append(k_top)\n",
    "            auxloss_results['aux_loss'].append('Yes' if use_aux_loss else 'No')\n",
    "            auxloss_results['test_loss'].append(test_loss_val)\n",
    "            auxloss_results['dead_neurons'].append(dead_neurons_count)\n",
    "            auxloss_results['dead_neuron_pct'].append(100 * dead_neurons_count / hidden_size)\n",
    "            auxloss_results['active_features'].append(activation_stats['active_features'])\n",
    "            auxloss_results['mean_activation_freq'].append(\n",
    "                activation_stats['mean_activation_frequency']\n",
    "            )\n",
    "\n",
    "            print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "                  f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "df_aux = pd.DataFrame(auxloss_results)\n",
    "df_aux.to_csv('experiment2_auxiliary_loss_results.csv', index=False)\n",
    "print(\"\\nExperiment 2 results saved to 'experiment2_auxiliary_loss_results.csv'\")\n",
    "\n"
   ],
   "id": "6c449b5b79d65d5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPERIMENT 2: AUXILIARY LOSS EFFECTS\n",
      "================================================================================\n",
      "\n",
      "### Processing MNIST Dataset ###\n",
      "\n",
      "Hidden Size: 128, k_top: 10\n",
      "  Training WITHOUT auxiliary loss...\n",
      "Epoch [1/50], Loss: 0.9370\n",
      "Epoch [2/50], Loss: 0.5011\n",
      "Epoch [3/50], Loss: 0.4658\n",
      "Epoch [4/50], Loss: 0.4542\n",
      "Epoch [5/50], Loss: 0.4495\n",
      "Epoch [6/50], Loss: 0.4475\n",
      "Epoch [7/50], Loss: 0.4462\n",
      "Epoch [8/50], Loss: 0.4449\n",
      "Epoch [9/50], Loss: 0.4433\n",
      "Epoch [10/50], Loss: 0.4422\n",
      "Epoch [11/50], Loss: 0.4415\n",
      "Epoch [12/50], Loss: 0.4408\n",
      "Epoch [13/50], Loss: 0.4402\n",
      "Epoch [14/50], Loss: 0.4394\n",
      "Epoch [15/50], Loss: 0.4387\n",
      "Epoch [16/50], Loss: 0.4379\n",
      "Epoch [17/50], Loss: 0.4372\n",
      "Epoch [18/50], Loss: 0.4369\n",
      "Epoch [19/50], Loss: 0.4364\n",
      "Epoch [20/50], Loss: 0.4361\n",
      "Epoch [21/50], Loss: 0.4359\n",
      "Epoch [22/50], Loss: 0.4357\n",
      "Epoch [23/50], Loss: 0.4355\n",
      "Epoch [24/50], Loss: 0.4352\n",
      "Epoch [25/50], Loss: 0.4350\n",
      "Epoch [26/50], Loss: 0.4348\n",
      "Epoch [27/50], Loss: 0.4345\n",
      "Epoch [28/50], Loss: 0.4342\n",
      "Epoch [29/50], Loss: 0.4341\n",
      "Epoch [30/50], Loss: 0.4340\n",
      "Epoch [31/50], Loss: 0.4339\n",
      "Epoch [32/50], Loss: 0.4340\n",
      "Epoch [33/50], Loss: 0.4340\n",
      "Epoch [34/50], Loss: 0.4341\n",
      "Epoch [35/50], Loss: 0.4341\n",
      "Epoch [36/50], Loss: 0.4339\n",
      "Epoch [37/50], Loss: 0.4339\n",
      "Epoch [38/50], Loss: 0.4339\n",
      "Epoch [39/50], Loss: 0.4338\n",
      "Epoch [40/50], Loss: 0.4337\n",
      "Epoch [41/50], Loss: 0.4337\n",
      "Epoch [42/50], Loss: 0.4337\n",
      "Epoch [43/50], Loss: 0.4336\n",
      "Epoch [44/50], Loss: 0.4335\n",
      "Epoch [45/50], Loss: 0.4334\n",
      "Epoch [46/50], Loss: 0.4335\n",
      "Epoch [47/50], Loss: 0.4334\n",
      "Epoch [48/50], Loss: 0.4334\n",
      "Epoch [49/50], Loss: 0.4333\n",
      "Epoch [50/50], Loss: 0.4334\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.427059\n",
      "Number of dead neurons in Default Sparse Autoencoder: 103 out of 128 (80.47%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 103 (80.47%)\n",
      "Active features: 25 (19.53%)\n",
      "Mean activation frequency: 0.0781\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.153683\n",
      "    Dead neurons: 103/128 (80.47%)\n",
      "  Training WITH auxiliary loss...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[85]\u001B[39m\u001B[32m, line 38\u001B[39m\n\u001B[32m     35\u001B[39m set_seeds(\u001B[32m42\u001B[39m)\n\u001B[32m     37\u001B[39m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m model = \u001B[43mtrain_sparse_autoencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_epochs\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlearning_rate\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43minput_size\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m    \u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodelType\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m    \u001B[49m\u001B[43mk_aux\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m*\u001B[49m\u001B[43mk_top\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43muse_aux_loss\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[43mk_aux_param\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m/\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdead_feature_threshold\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\n\u001B[32m     50\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# Evaluate\u001B[39;00m\n\u001B[32m     53\u001B[39m test_loss_val = test_loss(model, test_loader, dataset_name)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[75]\u001B[39m\u001B[32m, line 57\u001B[39m, in \u001B[36mtrain_sparse_autoencoder\u001B[39m\u001B[34m(train_loader, num_epochs, learning_rate, input_size, hidden_size, k_top, JumpReLU, k_aux, k_aux_param, dead_feature_threshold, modelType, dataset_type)\u001B[39m\n\u001B[32m     54\u001B[39m h, outputs = model(inputs)\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m modelType == \u001B[33m\"\u001B[39m\u001B[33mSAE_AuxLoss\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m modelType == \u001B[33m\"\u001B[39m\u001B[33mComplete\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     loss, mse_loss, aux_loss = model.compute_loss(inputs, h, outputs)\n\u001B[32m     58\u001B[39m     loss = mse_loss\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ML-Research-Training/.venv/lib/python3.13/site-packages/torch/_tensor.py:1186\u001B[39m, in \u001B[36mTensor.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1176\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m   1177\u001B[39m     \u001B[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001B[39;00m\n\u001B[32m   1178\u001B[39m     \u001B[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1183\u001B[39m     \u001B[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001B[39;00m\n\u001B[32m   1184\u001B[39m     \u001B[38;5;66;03m# See gh-54457\u001B[39;00m\n\u001B[32m   1185\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dim() == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1186\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33miteration over a 0-d tensor\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1187\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._C._get_tracing_state():\n\u001B[32m   1188\u001B[39m         warnings.warn(\n\u001B[32m   1189\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mIterating over a tensor might cause the trace to be incorrect. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1190\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mPassing a tensor of different shape won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt change the number of \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1194\u001B[39m             stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m   1195\u001B[39m         )\n",
      "\u001B[31mTypeError\u001B[39m: iteration over a 0-d tensor"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT 3: Combined Effects (Init + AuxLoss)\n",
    "# Tests all combinations\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPERIMENT 3: COMBINED EFFECTS (Initialization + Auxiliary Loss)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "combined_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    hidden_size = config['hidden_sizes'][1]  # Use middle size\n",
    "    k_top = config['k_tops'][1]\n",
    "\n",
    "    print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "    # Test all combinations\n",
    "    model_configs = [\n",
    "        ('SAE', 'None', 'None'),\n",
    "        ('SAE_Init', 'Tied', 'None'),\n",
    "        ('SAE_AuxLoss', 'None', 'AuxLoss'),\n",
    "        ('Complete', 'Tied', 'AuxLoss')\n",
    "    ]\n",
    "\n",
    "    for model_type, init_type, aux_type in model_configs:\n",
    "        print(f\"  Training {model_type}...\")\n",
    "\n",
    "        set_seeds(42)\n",
    "\n",
    "        # Train model\n",
    "        model = train_sparse_autoencoder(\n",
    "            train_loader=train_loader,\n",
    "            num_epochs=config['num_epochs'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            input_size=config['input_size'],\n",
    "            hidden_size=hidden_size,\n",
    "            k_top=k_top,\n",
    "            modelType=model_type,\n",
    "            dataset_type=dataset_name,\n",
    "            k_aux=2*k_top if 'AuxLoss' in aux_type else None,\n",
    "            k_aux_param=1/32,\n",
    "            dead_feature_threshold=1000,\n",
    "            JumpReLU=0.1\n",
    "        )\n",
    "\n",
    "        # Evaluate\n",
    "        test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "        dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "        activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "        # Store results\n",
    "        combined_results['dataset'].append(dataset_name)\n",
    "        combined_results['model_type'].append(model_type)\n",
    "        combined_results['initialization'].append(init_type)\n",
    "        combined_results['auxiliary_loss'].append(aux_type)\n",
    "        combined_results['test_loss'].append(test_loss_val)\n",
    "        combined_results['dead_neurons'].append(dead_neurons_count)\n",
    "        combined_results['dead_neuron_pct'].append(100 * dead_neurons_count / hidden_size)\n",
    "        combined_results['active_features'].append(activation_stats['active_features'])\n",
    "\n",
    "        print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "              f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "df_combined = pd.DataFrame(combined_results)\n",
    "df_combined.to_csv('experiment3_combined_effects_results.csv', index=False)\n",
    "print(\"\\nExperiment 3 results saved to 'experiment3_combined_effects_results.csv'\")\n",
    "\n"
   ],
   "id": "dc01c761022b13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================================\n",
    "# FIGURE GENERATION: Publication-Quality Plots\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING PUBLICATION-QUALITY FIGURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Set style for publication\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Figure 1: Dead Neuron Percentage by Initialization Strategy\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, dataset in enumerate(['mnist', 'olivetti', 'lfw']):\n",
    "    df_subset = df_init[df_init['dataset'] == dataset]\n",
    "\n",
    "    # Group by initialization and hidden size\n",
    "    pivot_data = df_subset.pivot_table(\n",
    "        values='dead_neuron_pct',\n",
    "        index='hidden_size',\n",
    "        columns='initialization',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    pivot_data.plot(kind='bar', ax=axes[idx], width=0.8)\n",
    "    axes[idx].set_title(f'{dataset.upper()} Dataset', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Hidden Size', fontsize=12)\n",
    "    axes[idx].set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "    axes[idx].legend(title='Initialization', fontsize=10)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_dead_neurons_by_initialization.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure1_dead_neurons_by_initialization.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure1_dead_neurons_by_initialization.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 2: Auxiliary Loss Impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: Dead neuron percentage\n",
    "ax = axes[0]\n",
    "df_aux_grouped = df_aux.groupby(['dataset', 'aux_loss'])['dead_neuron_pct'].mean().reset_index()\n",
    "pivot_aux = df_aux_grouped.pivot(index='dataset', columns='aux_loss', values='dead_neuron_pct')\n",
    "pivot_aux.plot(kind='bar', ax=ax, width=0.7, color=['#d62728', '#2ca02c'])\n",
    "ax.set_title('Dead Neuron Percentage\\nWith/Without Auxiliary Loss', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.legend(title='Auxiliary Loss', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel B: Test loss comparison\n",
    "ax = axes[1]\n",
    "df_loss_grouped = df_aux.groupby(['dataset', 'aux_loss'])['test_loss'].mean().reset_index()\n",
    "pivot_loss = df_loss_grouped.pivot(index='dataset', columns='aux_loss', values='test_loss')\n",
    "pivot_loss.plot(kind='bar', ax=ax, width=0.7, color=['#d62728', '#2ca02c'])\n",
    "ax.set_title('Reconstruction Loss\\nWith/Without Auxiliary Loss', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.legend(title='Auxiliary Loss', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2_auxiliary_loss_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure2_auxiliary_loss_effects.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure2_auxiliary_loss_effects.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 3: Combined Effects Summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Panel A: Dead neurons by model type\n",
    "ax = axes[0, 0]\n",
    "df_combined_grouped = df_combined.groupby(['dataset', 'model_type'])['dead_neuron_pct'].mean().reset_index()\n",
    "pivot_combined = df_combined_grouped.pivot(index='dataset', columns='model_type', values='dead_neuron_pct')\n",
    "pivot_combined.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Dead Neuron Percentage by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9, loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel B: Test loss by model type\n",
    "ax = axes[0, 1]\n",
    "df_loss_combined = df_combined.groupby(['dataset', 'model_type'])['test_loss'].mean().reset_index()\n",
    "pivot_loss_combined = df_loss_combined.pivot(index='dataset', columns='model_type', values='test_loss')\n",
    "pivot_loss_combined.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Reconstruction Loss by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9, loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel C: Scatter plot - Dead neurons vs Test loss\n",
    "ax = axes[1, 0]\n",
    "for model_type in df_combined['model_type'].unique():\n",
    "    df_model = df_combined[df_combined['model_type'] == model_type]\n",
    "    ax.scatter(df_model['dead_neuron_pct'], df_model['test_loss'],\n",
    "               label=model_type, s=100, alpha=0.7)\n",
    "ax.set_xlabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.set_title('Dead Neurons vs Reconstruction Performance', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Model Type', fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel D: Active features comparison\n",
    "ax = axes[1, 1]\n",
    "df_active = df_combined.groupby(['dataset', 'model_type'])['active_features'].mean().reset_index()\n",
    "pivot_active = df_active.pivot(index='dataset', columns='model_type', values='active_features')\n",
    "pivot_active.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Active Feature Count by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Number of Active Features', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure3_combined_effects_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure3_combined_effects_summary.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure3_combined_effects_summary.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 4: Activation Statistics Histograms\n",
    "# Compare best vs worst configurations\n",
    "print(\"\\nGenerating activation histograms for best/worst models...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, dataset in enumerate(['mnist', 'olivetti', 'lfw']):\n",
    "    print(f\"  Processing {dataset}...\")\n",
    "\n",
    "    config = experiment_configs[dataset]\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    hidden_size = config['hidden_sizes'][1]\n",
    "    k_top = config['k_tops'][1]\n",
    "\n",
    "    # Train baseline (worst) and complete (best) models\n",
    "    set_seeds(42)\n",
    "    model_baseline = train_sparse_autoencoder(\n",
    "        train_loader, num_epochs=config['num_epochs'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        input_size=config['input_size'], hidden_size=hidden_size,\n",
    "        k_top=k_top, modelType='SAE', dataset_type=dataset\n",
    "    )\n",
    "\n",
    "    set_seeds(42)\n",
    "    model_complete = train_sparse_autoencoder(\n",
    "        train_loader, num_epochs=config['num_epochs'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        input_size=config['input_size'], hidden_size=hidden_size,\n",
    "        k_top=k_top, modelType='Complete', dataset_type=dataset,\n",
    "        k_aux=2*k_top, k_aux_param=1/32, dead_feature_threshold=1000,\n",
    "        JumpReLU=0.1\n",
    "    )\n",
    "\n",
    "    # Get activation statistics\n",
    "    stats_baseline = get_activation_statistics(model_baseline, train_loader, dataset)\n",
    "    stats_complete = get_activation_statistics(model_complete, train_loader, dataset)\n",
    "\n",
    "    # Plot histograms\n",
    "    ax = axes[0, idx]\n",
    "    ax.hist(stats_baseline['activation_frequencies'], bins=50, alpha=0.6,\n",
    "            label='Baseline SAE', color='red', edgecolor='black')\n",
    "    ax.hist(stats_complete['activation_frequencies'], bins=50, alpha=0.6,\n",
    "            label='Complete SAE', color='green', edgecolor='black')\n",
    "    ax.set_xlabel('Activation Frequency', fontsize=11)\n",
    "    ax.set_ylabel('Number of Features', fontsize=11)\n",
    "    ax.set_title(f'{dataset.upper()}: Activation Frequencies', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, idx]\n",
    "    active_base = stats_baseline['activation_strengths'][stats_baseline['activation_strengths'] > 0]\n",
    "    active_complete = stats_complete['activation_strengths'][stats_complete['activation_strengths'] > 0]\n",
    "    ax.hist(active_base, bins=50, alpha=0.6, label='Baseline SAE',\n",
    "            color='red', edgecolor='black')\n",
    "    ax.hist(active_complete, bins=50, alpha=0.6, label='Complete SAE',\n",
    "            color='green', edgecolor='black')\n",
    "    ax.set_xlabel('Mean Activation Strength', fontsize=11)\n",
    "    ax.set_ylabel('Number of Features', fontsize=11)\n",
    "    ax.set_title(f'{dataset.upper()}: Activation Strengths', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure4_activation_histograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure4_activation_histograms.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure4_activation_histograms.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Generate Summary Statistics Table (LaTeX format)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING SUMMARY STATISTICS TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comprehensive summary table\n",
    "summary_stats = []\n",
    "\n",
    "for dataset in ['mnist', 'olivetti', 'lfw']:\n",
    "    for model_type in ['SAE', 'SAE_Init', 'SAE_AuxLoss', 'Complete']:\n",
    "        df_subset = df_combined[\n",
    "            (df_combined['dataset'] == dataset) &\n",
    "            (df_combined['model_type'] == model_type)\n",
    "        ]\n",
    "\n",
    "        if len(df_subset) > 0:\n",
    "            summary_stats.append({\n",
    "                'Dataset': dataset.upper(),\n",
    "                'Model': model_type,\n",
    "                'Dead (%)': f\"{df_subset['dead_neuron_pct'].mean():.2f} ± {df_subset['dead_neuron_pct'].std():.2f}\",\n",
    "                'Test Loss': f\"{df_subset['test_loss'].mean():.6f} ± {df_subset['test_loss'].std():.6f}\",\n",
    "                'Active Features': f\"{df_subset['active_features'].mean():.0f}\"\n",
    "            })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Save as CSV\n",
    "df_summary.to_csv('summary_statistics.csv', index=False)\n",
    "print(\"Saved: summary_statistics.csv\")\n",
    "\n",
    "# Save as LaTeX table\n",
    "latex_table = df_summary.to_latex(index=False, escape=False, column_format='lllll')\n",
    "with open('results/dead neurons/summary_statistics.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "print(\"Saved: summary_statistics.tex\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  - experiment1_initialization_results.csv\")\n",
    "print(\"  - experiment2_auxiliary_loss_results.csv\")\n",
    "print(\"  - experiment3_combined_effects_results.csv\")\n",
    "print(\"  - figure1_dead_neurons_by_initialization.png/pdf\")\n",
    "print(\"  - figure2_auxiliary_loss_effects.png/pdf\")\n",
    "print(\"  - figure3_combined_effects_summary.png/pdf\")\n",
    "print(\"  - figure4_activation_histograms.png/pdf\")\n",
    "print(\"  - summary_statistics.csv\")\n",
    "print(\"  - summary_statistics.tex\")\n",
    "print(\"\\nReady for inclusion in your paper!\")\n"
   ],
   "id": "3cb8fe1099dc1ceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MSE",
   "id": "7c3b77cf80856bb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_top_activating_examples(model, data_loader, dataset_name,\n",
    "                                     feature_indices, top_k=10, save_path=None):\n",
    "    \"\"\"\n",
    "    Show top-k input examples that activate each feature most strongly\n",
    "    This is the standard method used in Anthropic's work\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    # Track max activations for each feature\n",
    "    num_features = len(feature_indices)\n",
    "    top_activations = {idx: {'values': [], 'images': []} for idx in feature_indices}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            if dataset_name in ['olivetti', 'lfw']:\n",
    "                inputs, = data\n",
    "            else:\n",
    "                inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Get feature activations\n",
    "            h, _ = model(inputs)  # (batch, hidden_size)\n",
    "\n",
    "            # For each feature of interest\n",
    "            for feature_idx in feature_indices:\n",
    "                activations = h[:, feature_idx].cpu().numpy()\n",
    "\n",
    "                # Store top-k for this batch\n",
    "                for i, act_val in enumerate(activations):\n",
    "                    if act_val > 0:  # Only store non-zero activations\n",
    "                        top_activations[feature_idx]['values'].append(act_val)\n",
    "                        top_activations[feature_idx]['images'].append(inputs[i].cpu())\n",
    "\n",
    "    # Plot top-k examples for each feature\n",
    "    fig, axes = plt.subplots(num_features, top_k, figsize=(top_k*2, num_features*2))\n",
    "    if num_features == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    for row, feature_idx in enumerate(feature_indices):\n",
    "        # Get top-k activating examples\n",
    "        values = np.array(top_activations[feature_idx]['values'])\n",
    "        images = top_activations[feature_idx]['images']\n",
    "\n",
    "        if len(values) > 0:\n",
    "            top_k_indices = np.argsort(values)[-top_k:][::-1]\n",
    "\n",
    "            for col, img_idx in enumerate(top_k_indices):\n",
    "                img = images[img_idx].squeeze().numpy()\n",
    "\n",
    "                axes[row, col].imshow(img, cmap='gray' if dataset_name == 'mnist' else 'viridis')\n",
    "                axes[row, col].axis('off')\n",
    "                axes[row, col].set_title(f'{values[img_idx]:.2f}', fontsize=8)\n",
    "\n",
    "        axes[row, 0].set_ylabel(f'Feature {feature_idx}', fontsize=10)\n",
    "\n",
    "    plt.suptitle(f'Top Activating Examples: {model.name}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n"
   ],
   "id": "aaddb215be4398a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
