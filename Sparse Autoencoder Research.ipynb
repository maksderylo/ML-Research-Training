{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SAE implementations",
   "id": "c36299e8cc347f22"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.343988Z",
     "start_time": "2025-10-22T11:57:03.339590Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.training = True\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.k_top = k_top\n",
    "        self.name = \"Default Sparse Autoencoder\"\n",
    "\n",
    "        # Encoder maps input to hidden representation\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Decoder maps hidden representation back to input space\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def _topk_mask(self, activations: torch.Tensor) -> torch.Tensor:\n",
    "        # activations: (batch, hidden)\n",
    "        k = max(0, min(self.k_top, activations.size(1)))\n",
    "        _, idx = torch.topk(activations, k, dim=1)\n",
    "        mask = torch.zeros_like(activations)\n",
    "        mask.scatter_(1, idx, 1.0)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        pre_activations = self.encoder(x)\n",
    "        pre_activations = F.relu(pre_activations)\n",
    "        mask = self._topk_mask(pre_activations)\n",
    "        h = pre_activations * mask\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat\n",
    "\n",
    "\n",
    "    def compute_loss(self, x, h, x_hat):\n",
    "        # We compute sum of squares and normalize by batch size\n",
    "        recon_loss = torch.sum((x - x_hat) ** 2) / (x.size(0))\n",
    "\n",
    "        return recon_loss"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.393881Z",
     "start_time": "2025-10-22T11:57:03.390704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderInit(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20):\n",
    "        super(SparseAutoencoderInit, self).__init__(input_size, hidden_size, k_top)\n",
    "\n",
    "        self.name = \"Sparse Autoencoder with just weight initialization\"\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n"
   ],
   "id": "a70c6493dc195d4d",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.450823Z",
     "start_time": "2025-10-22T11:57:03.445056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderJumpReLU(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20, jump_value=0.1):\n",
    "        super(SparseAutoencoderJumpReLU, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Jump ReLU\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        # Apply JumpReLU\n",
    "        h = torch.where(h > self.jump_value, h, torch.zeros_like(h))\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat"
   ],
   "id": "5d8d293203ac3d5",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.505715Z",
     "start_time": "2025-10-22T11:57:03.499695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderInitJumpReLU(SparseAutoencoder):\n",
    "    def __init__(self, input_size=784, hidden_size=64, k_top=20, jump_value=0.1):\n",
    "        super(SparseAutoencoderInitJumpReLU, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Initialization and Jump ReLU\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        # Apply JumpReLU\n",
    "        h = torch.where(h > self.jump_value, h, torch.zeros_like(h))\n",
    "        x_hat = self.decoder(h)\n",
    "        return h, x_hat"
   ],
   "id": "aa80385d49115bf2",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implementing auxiliary loss SAE",
   "id": "b565b8d2503ed656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.564566Z",
     "start_time": "2025-10-22T11:57:03.554973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderAuxLoss(SparseAutoencoder):\n",
    "    def __init__(self, input_size, hidden_size, k_top, k_aux, k_aux_param, dead_feature_threshold):\n",
    "        super(SparseAutoencoderAuxLoss, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with Auxiliary Loss\"\n",
    "        # k_aux is typically 2*k or more to revive dead features\n",
    "        self.k_aux = k_aux if k_aux is not None else 2 * k_top\n",
    "        self.k_aux_param = k_aux_param\n",
    "        # Track dead features: count steps since each feature was last active\n",
    "        self.register_buffer('steps_since_active', torch.zeros(hidden_size))\n",
    "        self.dead_feature_threshold = dead_feature_threshold\n",
    "\n",
    "    # Function to track which features are dead\n",
    "    def _update_dead_features(self, h: torch.Tensor):\n",
    "        # Feature is active if ANY sample in batch activates it\n",
    "        active_mask = (h.abs() > 1e-8).any(dim=0)\n",
    "\n",
    "        # Increment counter for inactive features, reset for active ones\n",
    "        self.steps_since_active += 1\n",
    "        self.steps_since_active[active_mask] = 0\n",
    "\n",
    "    def _get_dead_feature_mask(self) -> torch.Tensor:\n",
    "        \"\"\"Return boolean mask of dead features\"\"\"\n",
    "        return self.steps_since_active > self.dead_feature_threshold\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h_raw = self.encoder(x)\n",
    "        mask = self._topk_mask(h_raw)\n",
    "        h = h_raw * mask\n",
    "        x_hat = self.decoder(h)\n",
    "\n",
    "        # Track dead features during training\n",
    "        if self.training:\n",
    "            self._update_dead_features(h)\n",
    "\n",
    "        return h, x_hat\n",
    "\n",
    "def compute_loss(self, x, h, x_hat):\n",
    "\n",
    "    recon_loss = torch.sum((x - x_hat) ** 2) / x.size(0)\n",
    "\n",
    "    aux_loss = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "    if self.training:\n",
    "        dead_mask = self._get_dead_feature_mask()\n",
    "        n_dead = dead_mask.sum().item()\n",
    "\n",
    "        if n_dead > 0:\n",
    "            recon_error_vec = x - x_hat\n",
    "            h_raw = self.encoder(x)\n",
    "\n",
    "            h_dead = h_raw * dead_mask.float().unsqueeze(0)\n",
    "            k_aux_features = min(self.k_aux, n_dead)\n",
    "            _, idx_aux = torch.topk(h_dead, k_aux_features, dim=1)\n",
    "            mask_aux = torch.zeros_like(h_dead)\n",
    "            mask_aux.scatter_(1, idx_aux, 1.0)\n",
    "\n",
    "            z_aux = h_raw * mask_aux\n",
    "            e_hat = self.decoder(z_aux)\n",
    "\n",
    "            aux_loss = torch.sum((recon_error_vec - e_hat) ** 2) / x.size(0)\n",
    "\n",
    "    total_loss = recon_loss + self.k_aux_param * aux_loss\n",
    "    return total_loss, recon_loss, aux_loss\n",
    "\n"
   ],
   "id": "72f4004d2c87ef37",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Complete with relu, init and aux loss implementation.",
   "id": "bcf91031d67e0628"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.622293Z",
     "start_time": "2025-10-22T11:57:03.613595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class SparseAutoencoderComplete(SparseAutoencoder):\n",
    "    def __init__(self, input_size, hidden_size, k_top, k_aux, k_aux_param, dead_feature_threshold, jump_value):\n",
    "        super(SparseAutoencoderComplete, self).__init__(input_size, hidden_size, k_top)\n",
    "        self.name = \"Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss\"\n",
    "        self.jump_value = jump_value\n",
    "\n",
    "        # k_aux is typically 2*k or more to revive dead features\n",
    "        self.k_aux = k_aux if k_aux is not None else 2 * k_top\n",
    "        self.k_aux_param = k_aux_param\n",
    "        # Track dead features: count steps since each feature was last active\n",
    "        self.register_buffer('steps_since_active', torch.zeros(hidden_size))\n",
    "        self.dead_feature_threshold = dead_feature_threshold\n",
    "\n",
    "        # Initialize encoder weights first with random directions\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
    "        # Initialize the decoder to be the transpose of the encoder weights\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.copy_(self.encoder.weight.t())\n",
    "\n",
    "    # Function to track which features are dead\n",
    "    def _update_dead_features(self, h: torch.Tensor):\n",
    "        # Feature is active if ANY sample in batch activates it\n",
    "        active_mask = (h.abs() > 1e-8).any(dim=0)\n",
    "\n",
    "        # Increment counter for inactive features, reset for active ones\n",
    "        self.steps_since_active += 1\n",
    "        self.steps_since_active[active_mask] = 0\n",
    "\n",
    "    def _get_dead_feature_mask(self) -> torch.Tensor:\n",
    "        \"\"\"Return boolean mask of dead features\"\"\"\n",
    "        return self.steps_since_active > self.dead_feature_threshold\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pre_activations = self.encoder(x)\n",
    "        pre_activations = F.relu(pre_activations)\n",
    "        mask = self._topk_mask(pre_activations)\n",
    "        h = pre_activations * mask\n",
    "        x_hat = self.decoder(h)\n",
    "\n",
    "        # Track dead features during training\n",
    "        if self.training:\n",
    "            self._update_dead_features(h)\n",
    "\n",
    "        return h, x_hat\n",
    "\n",
    "    def compute_loss(self, x, h, x_hat):\n",
    "        # Main reconstruction loss\n",
    "        recon_error = torch.sum((x - x_hat) ** 2)\n",
    "        recon_loss = recon_error / x.size(0)\n",
    "\n",
    "        # Auxiliary loss using dead features only\n",
    "        aux_loss = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "        if self.training:\n",
    "            dead_mask = self._get_dead_feature_mask()  # (hidden_size,)\n",
    "            n_dead = dead_mask.sum().item()\n",
    "\n",
    "            if n_dead > 0:\n",
    "                # Compute reconstruction error: e = x - x_hat\n",
    "                recon_error_vec = x - x_hat  # (batch, input_size)\n",
    "\n",
    "                # Get raw activations again (before TopK masking)\n",
    "                with torch.no_grad():\n",
    "                    h_raw = self.encoder(x)\n",
    "\n",
    "                # Select only dead features\n",
    "                h_dead = h_raw * dead_mask.float().unsqueeze(0)  # (batch, hidden_size)\n",
    "\n",
    "                # Select top-k_aux dead features\n",
    "                k_aux_features = min(self.k_aux, n_dead)\n",
    "                _, idx_aux = torch.topk(h_dead, k_aux_features, dim=1)\n",
    "                mask_aux = torch.zeros_like(h_dead)\n",
    "                mask_aux.scatter_(1, idx_aux, 1.0)\n",
    "\n",
    "                # Sparse activations using only dead features\n",
    "                z_aux = h_raw * mask_aux  # (batch, hidden_size)\n",
    "\n",
    "                # Reconstruct error using dead features\n",
    "                e_hat = self.decoder(z_aux)  # (batch, input_size)\n",
    "\n",
    "                # Auxiliary loss: ||e - e_hat||^2\n",
    "                aux_loss = torch.sum((recon_error_vec - e_hat) ** 2) / self.input_size\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = recon_loss + self.k_aux_param * aux_loss\n",
    "\n",
    "        return total_loss, recon_loss, aux_loss"
   ],
   "id": "6b95f44957f5b99f",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading and Preprocessing",
   "id": "1c8bfa281ef7655d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.675219Z",
     "start_time": "2025-10-22T11:57:03.668324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, Subset\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_mnist_data(batch_size=256):\n",
    "    # First load raw data to compute mean\n",
    "    raw_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to [0,1] and creates tensor\n",
    "    ])\n",
    "\n",
    "    # Load training set to compute mean\n",
    "    trainset_raw = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                              download=True, transform=raw_transform)\n",
    "\n",
    "    # Compute mean over entire training set\n",
    "    train_loader_temp = DataLoader(trainset_raw, batch_size=len(trainset_raw), shuffle=False)\n",
    "    all_data = next(iter(train_loader_temp))[0]\n",
    "    all_data = all_data.view(all_data.size(0), -1)  # Flatten to (N, 784)\n",
    "    dataset_mean = all_data.mean(dim=0)  # Mean across samples, shape (784,)\n",
    "\n",
    "    # Define preprocessing transform with mean subtraction and normalization\n",
    "    def preprocess(x):\n",
    "        x_flat = x.view(-1)  # Flatten from (1, 28, 28) to (784,)\n",
    "        x_centered = x_flat - dataset_mean  # Subtract mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)  # Normalize to unit norm\n",
    "        return x_norm\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(preprocess)\n",
    "    ])\n",
    "\n",
    "    # Load datasets with proper preprocessing\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "9dffec9ed378ec9c",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.725656Z",
     "start_time": "2025-10-22T11:57:03.723548Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b4de654eb035f402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.779220Z",
     "start_time": "2025-10-22T11:57:03.771592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_olivetti_data(batch_size=32, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Load Olivetti Faces dataset (400 images, 64x64 grayscale)\n",
    "    Returns data with shape (N, 4096) after flattening\n",
    "    \"\"\"\n",
    "    # Download Olivetti Faces using sklearn\n",
    "    faces = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
    "    data = faces.data  # Already normalized to [0, 1], shape (400, 4096)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    data_tensor = torch.FloatTensor(data)  # Shape: (400, 4096)\n",
    "\n",
    "    # Compute mean over entire dataset\n",
    "    dataset_mean = data_tensor.mean(dim=0)  # Shape: (4096,)\n",
    "\n",
    "    # Define preprocessing function\n",
    "    def preprocess(x):\n",
    "        x_centered = x - dataset_mean  # Subtract mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)  # Unit norm\n",
    "        return x_norm\n",
    "\n",
    "    # Apply preprocessing to all data\n",
    "    preprocessed_data = torch.stack([preprocess(x) for x in data_tensor])\n",
    "\n",
    "    # Create dataset (no labels needed for autoencoder)\n",
    "    dataset = TensorDataset(preprocessed_data)\n",
    "\n",
    "    # Split into train/test\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainset, testset = random_split(dataset, [train_size, test_size],\n",
    "                                     generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "d600891fa864567",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.827300Z",
     "start_time": "2025-10-22T11:57:03.822480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def load_imagenet_subset(batch_size=128, subset_size=50000, img_size=64,\n",
    "                         data_root='./data/imagenet', use_color=True):\n",
    "    train_dir = os.path.join(data_root, 'train')\n",
    "    val_dir = os.path.join(data_root, 'val_organized')\n",
    "\n",
    "    # Raw transform for mean computation\n",
    "    if use_color:\n",
    "        raw_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        num_channels = 3\n",
    "    else:\n",
    "        raw_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        num_channels = 1\n",
    "\n",
    "    # Compute mean on subset\n",
    "    print(\"Computing dataset mean...\")\n",
    "    trainset_raw = ImageFolder(train_dir, transform=raw_transform)\n",
    "    mean_indices = torch.randperm(len(trainset_raw))[:10000].tolist()\n",
    "    trainset_mean = Subset(trainset_raw, mean_indices)\n",
    "\n",
    "    temp_loader = DataLoader(trainset_mean, batch_size=256,\n",
    "                            num_workers=4, pin_memory=True)\n",
    "\n",
    "    mean_accumulator = None\n",
    "    count = 0\n",
    "    for batch_data, _ in temp_loader:\n",
    "        batch_flat = batch_data.view(batch_data.size(0), -1)\n",
    "        if mean_accumulator is None:\n",
    "            mean_accumulator = batch_flat.sum(dim=0)\n",
    "        else:\n",
    "            mean_accumulator += batch_flat.sum(dim=0)\n",
    "        count += batch_data.size(0)\n",
    "\n",
    "    dataset_mean = mean_accumulator / count\n",
    "    print(f\"✓ Mean computed over {count} images\")\n",
    "\n",
    "    # Preprocessing with mean subtraction\n",
    "    def preprocess(x):\n",
    "        x_flat = x.view(-1)\n",
    "        x_centered = x_flat - dataset_mean\n",
    "        norm = torch.norm(x_centered)\n",
    "        return x_centered / (norm + 1e-8) if norm > 1e-8 else x_centered\n",
    "\n",
    "    if use_color:\n",
    "        final_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(preprocess)\n",
    "        ])\n",
    "    else:\n",
    "        final_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size + 8),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(preprocess)\n",
    "        ])\n",
    "\n",
    "    trainset = ImageFolder(train_dir, transform=final_transform)\n",
    "    testset = ImageFolder(val_dir, transform=final_transform)\n",
    "\n",
    "    if subset_size and subset_size < len(trainset):\n",
    "        subset_indices = torch.randperm(len(trainset))[:subset_size].tolist()\n",
    "        trainset = Subset(trainset, subset_indices)\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size,\n",
    "                            shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    print(f\"✓ Loaders ready: {len(train_loader)} train batches\")\n",
    "    return train_loader, test_loader, dataset_mean\n"
   ],
   "id": "3ccddad406245d3b",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.874806Z",
     "start_time": "2025-10-22T11:57:03.870844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def load_lfw_data(batch_size=128, img_size=64, min_faces_per_person=20):\n",
    "    \"\"\"\n",
    "    Load Labeled Faces in the Wild dataset with proper resizing\n",
    "\n",
    "    Args:\n",
    "        batch_size: Batch size\n",
    "        img_size: Resize to (img_size, img_size) - actual pixels\n",
    "        min_faces_per_person: Filter people with fewer images\n",
    "    \"\"\"\n",
    "    # Download LFW with original size\n",
    "    lfw_people = fetch_lfw_people(\n",
    "        min_faces_per_person=min_faces_per_person,\n",
    "        resize=1.0,  # Keep original size, we'll resize manually\n",
    "        color=False\n",
    "    )\n",
    "\n",
    "    print(f\"Original LFW shape: {lfw_people.images.shape}\")\n",
    "\n",
    "    # Manually resize to exact dimensions\n",
    "    resized_images = []\n",
    "    for img in lfw_people.images:\n",
    "        # Convert to PIL Image for proper resizing\n",
    "        pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        # Resize to exact target size\n",
    "        pil_img = pil_img.resize((img_size, img_size), Image.LANCZOS)\n",
    "        # Back to normalized array\n",
    "        resized = np.array(pil_img).astype(np.float32) / 255.0\n",
    "        resized_images.append(resized.flatten())\n",
    "\n",
    "    data_flat = np.array(resized_images)\n",
    "    print(f\"Resized LFW shape: {data_flat.shape}\")  # Should be (n_samples, img_size²)\n",
    "\n",
    "    # Convert to torch\n",
    "    data_tensor = torch.FloatTensor(data_flat)\n",
    "\n",
    "    # Compute mean\n",
    "    dataset_mean = data_tensor.mean(dim=0)\n",
    "\n",
    "    # Preprocess\n",
    "    def preprocess(x):\n",
    "        x_centered = x - dataset_mean\n",
    "        x_norm = x_centered / (torch.norm(x_centered) + 1e-8)\n",
    "        return x_norm\n",
    "\n",
    "    preprocessed_data = torch.stack([preprocess(x) for x in data_tensor])\n",
    "\n",
    "    # Create dataset\n",
    "    class LFWDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return (self.data[idx],)\n",
    "\n",
    "    dataset = LFWDataset(preprocessed_data)\n",
    "\n",
    "    # Split 80/20\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    trainset, testset = random_split(dataset, [train_size, test_size],\n",
    "                                     generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"LFW Dataset loaded: {len(trainset)} train, {len(testset)} test\")\n",
    "    print(f\"Image size: {img_size}×{img_size}, Input dimension: {img_size**2}\")\n",
    "\n",
    "    return train_loader, test_loader, dataset_mean"
   ],
   "id": "3c3c819edc1dfd03",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.922765Z",
     "start_time": "2025-10-22T11:57:03.919151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.datasets import fetch_olivetti_faces, fetch_lfw_people\n",
    "from PIL import Image\n",
    "\n",
    "def load_data(dataset_name, batch_size=128, img_size=64, **kwargs):\n",
    "    \"\"\"\n",
    "    Unified data loading function for multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: One of ['mnist', 'olivetti', 'lfw', 'imagenet']\n",
    "        batch_size: Batch size for DataLoader\n",
    "        img_size: Image size for face datasets (default 64)\n",
    "        **kwargs: Additional dataset-specific arguments\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for training\n",
    "        test_loader: DataLoader for testing\n",
    "        dataset_mean: Mean vector used for preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset_name.lower() == 'mnist':\n",
    "        return load_mnist_data(batch_size)\n",
    "\n",
    "    elif dataset_name.lower() == 'olivetti':\n",
    "        train_split = kwargs.get('train_split', 0.8)\n",
    "        return load_olivetti_data(batch_size, train_split)\n",
    "\n",
    "    elif dataset_name.lower() == 'lfw':\n",
    "        min_faces_per_person = kwargs.get('min_faces_per_person', 20)\n",
    "        return load_lfw_data(batch_size, img_size, min_faces_per_person)\n",
    "\n",
    "    elif dataset_name.lower() == 'imagenet':\n",
    "        subset_size = kwargs.get('subset_size', 10000)\n",
    "        data_root = kwargs.get('data_root', './data/imagenet')\n",
    "        return load_imagenet_subset(batch_size, subset_size, img_size, data_root)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}. Choose from ['mnist', 'olivetti', 'lfw', 'imagenet']\")\n"
   ],
   "id": "beab04ad03948608",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training function",
   "id": "50475f90ab2b747d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:03.976014Z",
     "start_time": "2025-10-22T11:57:03.969574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "def train_sparse_autoencoder(train_loader, num_epochs=50, learning_rate=0.001,\n",
    "                            input_size=784, hidden_size=64, k_top=20,\n",
    "                            JumpReLU=0.1, k_aux=None, k_aux_param=1/32,\n",
    "                            dead_feature_threshold=1000, modelType=\"SAE\",\n",
    "                            dataset_type=\"mnist\"):\n",
    "    \"\"\"\n",
    "    Train sparse autoencoder with support for different datasets\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader for training data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' to handle different unpacking\n",
    "        ... (other args as before)\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if modelType == \"SAE\":\n",
    "        model = SparseAutoencoder(input_size=input_size, hidden_size=hidden_size, k_top=k_top).to(device)\n",
    "    elif modelType == \"SAE_Init_JumpReLU\":\n",
    "        model = SparseAutoencoderInitJumpReLU(input_size=input_size, hidden_size=hidden_size, k_top=k_top, jump_value=JumpReLU).to(device)\n",
    "    elif modelType == \"SAE_JumpReLU\":\n",
    "        model = SparseAutoencoderJumpReLU(input_size=input_size, hidden_size=hidden_size, k_top=k_top, jump_value=JumpReLU).to(device)\n",
    "    elif modelType == \"SAE_Init\":\n",
    "        model = SparseAutoencoderInit(input_size=input_size, hidden_size=hidden_size, k_top=k_top).to(device)\n",
    "    elif modelType == \"SAE_AuxLoss\":\n",
    "        model = SparseAutoencoderAuxLoss(input_size=input_size, hidden_size=hidden_size, k_top=k_top, k_aux=k_aux,\n",
    "                                         k_aux_param=k_aux_param, dead_feature_threshold=dead_feature_threshold).to(device)\n",
    "    elif modelType == \"Complete\":\n",
    "        model = SparseAutoencoderComplete(input_size=input_size, hidden_size=hidden_size, k_top=k_top, k_aux=k_aux,\n",
    "                                         k_aux_param=k_aux_param, dead_feature_threshold=dead_feature_threshold, jump_value=JumpReLU).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid modelType specified.\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                # Olivetti returns single-element tuple: (inputs,)\n",
    "                inputs, = data  # Note the comma - unpacks single element\n",
    "                inputs = inputs.to(device)\n",
    "            elif dataset_type in ['mnist', 'imagenet']:\n",
    "                # MNIST and ImageNet return (inputs, labels)\n",
    "                inputs, _ = data\n",
    "                # No need to reshape - already preprocessed to correct shape\n",
    "                inputs = inputs.to(device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dataset_type: {dataset_type}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            h, outputs = model(inputs)\n",
    "\n",
    "            if modelType == \"SAE_AuxLoss\" or modelType == \"Complete\":\n",
    "                loss, mse_loss, aux_loss = model.compute_loss(inputs, h, outputs)\n",
    "                loss = mse_loss\n",
    "            else:\n",
    "                loss = model.compute_loss(inputs, h, outputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp weights to enforce non-negativity\n",
    "            with torch.no_grad():\n",
    "                model.encoder.weight.clamp_(0.0)\n",
    "                model.decoder.weight.clamp_(0.0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model"
   ],
   "id": "ec162a61e1221868",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization functions",
   "id": "e0b92ca01859d5eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.028184Z",
     "start_time": "2025-10-22T11:57:04.019942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def visualize_weights_decoder(model, num_features=64):\n",
    "    \"\"\"\n",
    "    Visualize decoder weights - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    # Auto-detect input size from model\n",
    "    input_size = model.decoder.weight.shape[0]\n",
    "    print(f\"Auto-detected input_size: {input_size}\")\n",
    "\n",
    "    # Determine image shape\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "        dataset_type = 'mnist'\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        # Non-square or unusual size - try square root\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            # Non-square - find factors\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    print(f\"Using image shape: {img_shape}\")\n",
    "\n",
    "    weights = model.decoder.weight.data.cpu().numpy().T\n",
    "    num_features = min(num_features, weights.shape[0])\n",
    "\n",
    "    # Grid dimensions\n",
    "    x_images = int(math.ceil(math.sqrt(num_features)))\n",
    "    y_images = int(math.ceil(num_features / x_images))\n",
    "\n",
    "    plt.figure(figsize=(x_images * 2, y_images * 2))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Decoder Weights ({img_shape[0]}×{img_shape[1]})',\n",
    "                 fontsize=14, y=0.995)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        plt.subplot(y_images, x_images, i + 1)\n",
    "        weight_img = weights[i].reshape(img_shape)\n",
    "\n",
    "        # Normalize\n",
    "        weight_img = (weight_img - weight_img.min()) / (weight_img.max() - weight_img.min() + 1e-8)\n",
    "\n",
    "        plt.imshow(weight_img, cmap='gray', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'F{i}', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_weights_encoder(model, num_features=64):\n",
    "    \"\"\"\n",
    "    Visualize encoder weights - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    # Get weights\n",
    "    if hasattr(model.encoder, 'weight'):\n",
    "        weights = model.encoder.weight.data.cpu().numpy()\n",
    "    elif isinstance(model.encoder, torch.nn.Sequential):\n",
    "        weights = model.encoder[0].weight.data.cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown encoder structure\")\n",
    "\n",
    "    # Auto-detect input size\n",
    "    input_size = weights.shape[1]\n",
    "    print(f\"Auto-detected input_size: {input_size}\")\n",
    "\n",
    "    # Determine image shape\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    print(f\"Using image shape: {img_shape}\")\n",
    "\n",
    "    num_features = min(num_features, weights.shape[0])\n",
    "\n",
    "    x_images = int(math.ceil(math.sqrt(num_features)))\n",
    "    y_images = int(math.ceil(num_features / x_images))\n",
    "\n",
    "    plt.figure(figsize=(x_images * 2, y_images * 2))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Encoder Weights ({img_shape[0]}×{img_shape[1]})',\n",
    "                 fontsize=14, y=0.995)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        plt.subplot(y_images, x_images, i + 1)\n",
    "        weight_img = weights[i].reshape(img_shape)\n",
    "        weight_img = (weight_img - weight_img.min()) / (weight_img.max() - weight_img.min() + 1e-8)\n",
    "        plt.imshow(weight_img, cmap='gray', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'F{i}', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_reconstructions(model, data_loader, num_samples=10, dataset_type='olivetti'):\n",
    "    \"\"\"\n",
    "    Visualize reconstructions - AUTO-DETECTS dimensions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Get data\n",
    "    data_iter = iter(data_loader)\n",
    "    data = next(data_iter)\n",
    "\n",
    "    if dataset_type == 'olivetti' or len(data) == 1:\n",
    "        inputs, = data\n",
    "    else:\n",
    "        inputs, _ = data\n",
    "\n",
    "    inputs = inputs[:num_samples].to(device)\n",
    "\n",
    "    # Auto-detect dimensions\n",
    "    input_size = inputs.shape[1]\n",
    "    if input_size == 784:\n",
    "        img_shape = (28, 28)\n",
    "    elif input_size == 4096:\n",
    "        img_shape = (64, 64)\n",
    "    else:\n",
    "        side = int(np.sqrt(input_size))\n",
    "        if side * side == input_size:\n",
    "            img_shape = (side, side)\n",
    "        else:\n",
    "            for h in range(int(np.sqrt(input_size)), 0, -1):\n",
    "                if input_size % h == 0:\n",
    "                    w = input_size // h\n",
    "                    img_shape = (h, w)\n",
    "                    break\n",
    "\n",
    "    # Get reconstructions\n",
    "    with torch.no_grad():\n",
    "        _, reconstructions = model(inputs)\n",
    "\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    reconstructions = reconstructions.cpu().numpy()\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 2, 4))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    plt.suptitle(f'{model_name} Reconstructions ({img_shape[0]}×{img_shape[1]})', fontsize=14)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[0, i].imshow(inputs[i].reshape(img_shape), cmap='gray', interpolation='nearest')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Original', fontsize=10)\n",
    "\n",
    "        axes[1, i].imshow(reconstructions[i].reshape(img_shape), cmap='gray', interpolation='nearest')\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Reconstructed', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "c7b1cd1e283aafb6",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Functions to count dead neurons and test loss on the dataset given",
   "id": "6f23cd993e61745e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.086779Z",
     "start_time": "2025-10-22T11:57:04.076648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def count_dead_neurons(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Count dead neurons (features that never activate)\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' for proper unpacking\n",
    "\n",
    "    Returns:\n",
    "        num_dead: Number of dead neurons\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dead_neurons = torch.ones(model.hidden_size, dtype=torch.bool).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data  # Single-element tuple\n",
    "            else:  # mnist or imagenet\n",
    "                inputs, _ = data  # (inputs, labels) tuple\n",
    "\n",
    "            inputs = inputs.to(device)  # Already preprocessed, no reshape needed\n",
    "            h, _ = model(inputs)\n",
    "\n",
    "            # A neuron is alive if it activates (h > 0) for any sample\n",
    "            dead_neurons &= (h.sum(dim=0) == 0)\n",
    "\n",
    "    num_dead = dead_neurons.sum().item()\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f'Number of dead neurons in {model_name}: {num_dead} out of {model.hidden_size} '\n",
    "          f'({100*num_dead/model.hidden_size:.2f}%)')\n",
    "    return num_dead\n",
    "\n",
    "\n",
    "def test_loss(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Compute average test loss\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with test data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet' for proper unpacking\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: Average loss over test set\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data  # Single-element tuple\n",
    "            else:  # mnist or imagenet\n",
    "                inputs, _ = data  # (inputs, labels) tuple\n",
    "\n",
    "            inputs = inputs.to(device)  # Already preprocessed, no reshape needed\n",
    "            h, outputs = model(inputs)\n",
    "\n",
    "            # Handle different loss outputs\n",
    "            loss_output = model.compute_loss(inputs, h, outputs)\n",
    "            if isinstance(loss_output, tuple):\n",
    "                loss, *_ = loss_output  # Unpack if tuple (e.g., with aux loss)\n",
    "            else:\n",
    "                loss = loss_output\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f'Test Loss for {model_name}: {avg_loss:.6f}')\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def get_activation_statistics(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Get comprehensive statistics about feature activations\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    activation_counts = torch.zeros(model.hidden_size).to(device)\n",
    "    activation_sums = torch.zeros(model.hidden_size).to(device)\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Handle different data loader formats\n",
    "            if dataset_type in ['olivetti', 'lfw']:\n",
    "                inputs, = data\n",
    "            else:\n",
    "                inputs, _ = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            h, _ = model(inputs)\n",
    "\n",
    "            # Count how many times each feature activates (h > 0)\n",
    "            activation_counts += (h > 0).sum(dim=0).float()\n",
    "            activation_sums += h.sum(dim=0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    # Move to CPU for analysis\n",
    "    activation_counts = activation_counts.cpu().numpy()\n",
    "    activation_sums = activation_sums.cpu().numpy()\n",
    "\n",
    "    # Compute statistics\n",
    "    activation_freq = activation_counts / total_samples  # Fraction of samples each feature activates on\n",
    "\n",
    "    # FIXED: Only compute mean over ACTIVE features (where count > 0)\n",
    "    active_mask = activation_counts > 0\n",
    "    mean_activation = np.zeros(model.hidden_size)\n",
    "    mean_activation[active_mask] = activation_sums[active_mask] / activation_counts[active_mask]\n",
    "\n",
    "    # Mean strength across ALL active features (not averaged over all samples)\n",
    "    if np.sum(active_mask) > 0:\n",
    "        mean_act_strength_active = np.mean(mean_activation[active_mask])\n",
    "    else:\n",
    "        mean_act_strength_active = 0.0\n",
    "\n",
    "    stats = {\n",
    "        'total_features': model.hidden_size,\n",
    "        'dead_features': np.sum(activation_counts == 0),\n",
    "        'active_features': np.sum(activation_counts > 0),\n",
    "        'mean_activation_frequency': np.mean(activation_freq),\n",
    "        'median_activation_frequency': np.median(activation_freq),\n",
    "        'mean_activation_strength': mean_act_strength_active,  # Corrected calculation\n",
    "        'activation_frequencies': activation_freq,\n",
    "        'activation_strengths': mean_activation,\n",
    "        'activation_counts': activation_counts\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "    print(f\"\\n=== Activation Statistics for {model_name} ===\")\n",
    "    print(f\"Total features: {stats['total_features']}\")\n",
    "    print(f\"Dead features: {stats['dead_features']} ({100*stats['dead_features']/stats['total_features']:.2f}%)\")\n",
    "    print(f\"Active features: {stats['active_features']} ({100*stats['active_features']/stats['total_features']:.2f}%)\")\n",
    "    print(f\"Mean activation frequency: {stats['mean_activation_frequency']:.4f}\")\n",
    "    print(f\"Median activation frequency: {stats['median_activation_frequency']:.4f}\")\n",
    "    print(f\"Mean activation strength (when active): {stats['mean_activation_strength']:.6f}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "def plot_activation_histogram(model, data_loader, dataset_type='mnist'):\n",
    "    \"\"\"\n",
    "    Plot histogram of feature activation frequencies\n",
    "\n",
    "    Args:\n",
    "        model: Trained SAE model\n",
    "        data_loader: DataLoader with data\n",
    "        dataset_type: 'mnist', 'olivetti', or 'imagenet'\n",
    "    \"\"\"\n",
    "    stats = get_activation_statistics(model, data_loader, dataset_type)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    model_name = getattr(model, 'name', 'SAE')\n",
    "\n",
    "    # Histogram of activation frequencies\n",
    "    axes[0].hist(stats['activation_frequencies'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Activation Frequency (fraction of samples)')\n",
    "    axes[0].set_ylabel('Number of Features')\n",
    "    axes[0].set_title(f'{model_name}: Feature Activation Frequencies')\n",
    "    axes[0].axvline(stats['mean_activation_frequency'], color='r', linestyle='--',\n",
    "                    label=f'Mean: {stats[\"mean_activation_frequency\"]:.4f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Histogram of activation strengths (excluding dead features)\n",
    "    active_strengths = stats['activation_strengths'][stats['activation_strengths'] > 0]\n",
    "    axes[1].hist(active_strengths, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1].set_xlabel('Mean Activation Strength')\n",
    "    axes[1].set_ylabel('Number of Features')\n",
    "    axes[1].set_title(f'{model_name}: Feature Activation Strengths (Active Features Only)')\n",
    "    axes[1].axvline(stats['mean_activation_strength'], color='r', linestyle='--',\n",
    "                    label=f'Mean: {stats[\"mean_activation_strength\"]:.4f}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "1e6c80537d31d35",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initializing",
   "id": "a25fde095862b2cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.140316Z",
     "start_time": "2025-10-22T11:57:04.136754Z"
    }
   },
   "cell_type": "code",
   "source": "# train_loader, test_loader, mean = load_olivetti_data(batch_size=32)",
   "id": "8105d6e7d4fa8ec0",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Base usage",
   "id": "6e3bce16a2613e38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.195556Z",
     "start_time": "2025-10-22T11:57:04.191771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_loader, test_loader, mean = load_data(dataset_name='mnist', batch_size=128)\n",
    "#\n",
    "# modelBase = train_sparse_autoencoder(\n",
    "#     train_loader,\n",
    "#     num_epochs=50,\n",
    "#     learning_rate=0.001,\n",
    "#     input_size=784,\n",
    "#     hidden_size=256,\n",
    "#     k_top=40,\n",
    "#     modelType=\"Complete\",\n",
    "#     dataset_type=\"mnist\"\n",
    "# )\n"
   ],
   "id": "e3bca5d4a7bb234f",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.247382Z",
     "start_time": "2025-10-22T11:57:04.243552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# visualize_weights_decoder(modelBase, num_features=256)\n",
    "# count_dead_neurons(modelBase, train_loader, dataset_type='mnist')\n",
    "# test_loss(modelBase, test_loader, dataset_type='mnist')\n",
    "# plot_activation_histogram(modelBase, train_loader, dataset_type='mnist')"
   ],
   "id": "cb2f2d3ae0b69c29",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.299317Z",
     "start_time": "2025-10-22T11:57:04.295900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_loader, test_loader, mean = load_data(dataset_name='imagenet',\n",
    "#                                             batch_size=128,\n",
    "#                                             img_size=64)\n",
    "#\n",
    "# modelImagenet = train_sparse_autoencoder(\n",
    "#     train_loader,\n",
    "#     num_epochs=50,\n",
    "#     learning_rate=0.003,\n",
    "#     input_size=12288,\n",
    "#     hidden_size=2048,\n",
    "#     k_top=64,\n",
    "#     k_aux_param=1/128,\n",
    "#     modelType=\"Complete\",\n",
    "#     dataset_type=\"imagenet\"\n",
    "# )\n"
   ],
   "id": "1059e30a05820489",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.350511Z",
     "start_time": "2025-10-22T11:57:04.347420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# visualize_weights_decoder(modelImagenet, num_features=256)\n",
    "# count_dead_neurons(modelImagenet, train_loader, dataset_type='imagenet')\n",
    "# test_loss(modelImagenet, test_loader, dataset_type='imagenet')\n",
    "# plot_activation_histogram(modelImagenet, train_loader, dataset_type='imagenet')"
   ],
   "id": "760a196f0a67d6b1",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TopK Sparsity Analysis",
   "id": "333bad2f014121c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dead neurons",
   "id": "7a523d4271489478"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T11:57:04.408719Z",
     "start_time": "2025-10-22T11:57:04.399998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Configuration for comprehensive experiments\n",
    "experiment_configs = {\n",
    "    'mnist': {\n",
    "        'input_size': 784,\n",
    "        'hidden_sizes': [128, 256],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 256,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    'olivetti': {\n",
    "        'input_size': 4096,\n",
    "        'hidden_sizes': [256, 512, 1024],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 32,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    'lfw': {\n",
    "        'input_size': 4096,  # 64x64 images\n",
    "        'hidden_sizes': [512, 1024, 2048],\n",
    "        'k_tops': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "}"
   ],
   "id": "d46df9ce4490dac9",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-22T11:57:04.457709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 1: Weight Initialization Comparison\n",
    "# Tests: Random Xavier, Tied Weights, and Baseline\n",
    "# Duration: ~4-6 hours for all datasets\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to safely get activation strength\n",
    "def get_activation_strength_safe(activation_stats):\n",
    "    \"\"\"Safely extract mean activation strength, handling edge cases\"\"\"\n",
    "    if 'mean_activation_strength' in activation_stats:\n",
    "        strength = activation_stats['mean_activation_strength']\n",
    "        # Handle NaN or infinite values\n",
    "        if np.isnan(strength) or np.isinf(strength):\n",
    "            return 0.0\n",
    "        return float(strength)\n",
    "    else:\n",
    "        # If key doesn't exist, compute it manually\n",
    "        activation_strengths = activation_stats.get('activation_strengths', np.array([]))\n",
    "        if len(activation_strengths) > 0 and np.sum(activation_strengths > 0) > 0:\n",
    "            return float(np.mean(activation_strengths[activation_strengths > 0]))\n",
    "        return 0.0\n",
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT 1: Weight Initialization Comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT 1: WEIGHT INITIALIZATION COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "initialization_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    for hidden_size in config['hidden_sizes']:\n",
    "        for k_top in config['k_tops']:\n",
    "            print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "            # Test 3 initialization strategies\n",
    "            init_strategies = ['SAE', 'SAE_Init', 'Complete']\n",
    "\n",
    "            for strategy in init_strategies:\n",
    "                print(f\"  Training {strategy}...\")\n",
    "                set_seeds(42)  # Ensure reproducibility\n",
    "\n",
    "                try:\n",
    "                    # Train model\n",
    "                    model = train_sparse_autoencoder(\n",
    "                        train_loader=train_loader,\n",
    "                        num_epochs=config['num_epochs'],\n",
    "                        learning_rate=config['learning_rate'],\n",
    "                        input_size=config['input_size'],\n",
    "                        hidden_size=hidden_size,\n",
    "                        k_top=k_top,\n",
    "                        modelType=strategy,\n",
    "                        dataset_type=dataset_name,\n",
    "                        k_aux=2*k_top if strategy == 'SAE_Complete' else None,\n",
    "                        k_aux_param=1/32,\n",
    "                        dead_feature_threshold=1000\n",
    "                    )\n",
    "\n",
    "                    # Evaluate\n",
    "                    test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "                    dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "                    activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "                    # Safely extract activation strength\n",
    "                    mean_act_strength = get_activation_strength_safe(activation_stats)\n",
    "\n",
    "                    # Store results\n",
    "                    initialization_results['dataset'].append(dataset_name)\n",
    "                    initialization_results['hidden_size'].append(hidden_size)\n",
    "                    initialization_results['k_top'].append(k_top)\n",
    "                    initialization_results['initialization'].append(strategy)\n",
    "                    initialization_results['test_loss'].append(test_loss_val)\n",
    "                    initialization_results['dead_neurons'].append(dead_neurons_count)\n",
    "                    initialization_results['dead_neuron_pct'].append(\n",
    "                        100 * dead_neurons_count / hidden_size\n",
    "                    )\n",
    "                    initialization_results['active_features'].append(\n",
    "                        activation_stats['active_features']\n",
    "                    )\n",
    "                    initialization_results['mean_activation_freq'].append(\n",
    "                        activation_stats['mean_activation_frequency']\n",
    "                    )\n",
    "                    initialization_results['mean_activation_strength'].append(mean_act_strength)\n",
    "\n",
    "                    print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "                          f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "                    print(f\"    Test loss: {test_loss_val:.6f}\")\n",
    "                    print(f\"    Mean activation strength: {mean_act_strength:.6f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    ERROR training {strategy}: {str(e)}\")\n",
    "                    # Log error but continue with other experiments\n",
    "                    continue\n",
    "\n",
    "# Save results\n",
    "df_init = pd.DataFrame(initialization_results)\n",
    "df_init.to_csv('experiment1_initialization_results.csv', index=False)\n",
    "print(\"\\n✓ Experiment 1 results saved to 'experiment1_initialization_results.csv'\")\n",
    "print(f\"  Total experiments completed: {len(df_init)}\")\n",
    "\n"
   ],
   "id": "a9d98580e76a2ec8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 1: WEIGHT INITIALIZATION COMPARISON\n",
      "================================================================================\n",
      "\n",
      "### Processing MNIST Dataset ###\n",
      "\n",
      "Hidden Size: 128, k_top: 5\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.9188\n",
      "Epoch [2/50], Loss: 0.5331\n",
      "Epoch [3/50], Loss: 0.5171\n",
      "Epoch [4/50], Loss: 0.5109\n",
      "Epoch [5/50], Loss: 0.5064\n",
      "Epoch [6/50], Loss: 0.5047\n",
      "Epoch [7/50], Loss: 0.5041\n",
      "Epoch [8/50], Loss: 0.5038\n",
      "Epoch [9/50], Loss: 0.5037\n",
      "Epoch [10/50], Loss: 0.5033\n",
      "Epoch [11/50], Loss: 0.5030\n",
      "Epoch [12/50], Loss: 0.5028\n",
      "Epoch [13/50], Loss: 0.5028\n",
      "Epoch [14/50], Loss: 0.5025\n",
      "Epoch [15/50], Loss: 0.5025\n",
      "Epoch [16/50], Loss: 0.5023\n",
      "Epoch [17/50], Loss: 0.5019\n",
      "Epoch [18/50], Loss: 0.5016\n",
      "Epoch [19/50], Loss: 0.5014\n",
      "Epoch [20/50], Loss: 0.5011\n",
      "Epoch [21/50], Loss: 0.5008\n",
      "Epoch [22/50], Loss: 0.5006\n",
      "Epoch [23/50], Loss: 0.5003\n",
      "Epoch [24/50], Loss: 0.5003\n",
      "Epoch [25/50], Loss: 0.5003\n",
      "Epoch [26/50], Loss: 0.5002\n",
      "Epoch [27/50], Loss: 0.5003\n",
      "Epoch [28/50], Loss: 0.5003\n",
      "Epoch [29/50], Loss: 0.5003\n",
      "Epoch [30/50], Loss: 0.5001\n",
      "Epoch [31/50], Loss: 0.5002\n",
      "Epoch [32/50], Loss: 0.5001\n",
      "Epoch [33/50], Loss: 0.5000\n",
      "Epoch [34/50], Loss: 0.5000\n",
      "Epoch [35/50], Loss: 0.5001\n",
      "Epoch [36/50], Loss: 0.5000\n",
      "Epoch [37/50], Loss: 0.4999\n",
      "Epoch [38/50], Loss: 0.5001\n",
      "Epoch [39/50], Loss: 0.5001\n",
      "Epoch [40/50], Loss: 0.4999\n",
      "Epoch [41/50], Loss: 0.5001\n",
      "Epoch [42/50], Loss: 0.5002\n",
      "Epoch [43/50], Loss: 0.5002\n",
      "Epoch [44/50], Loss: 0.5001\n",
      "Epoch [45/50], Loss: 0.5002\n",
      "Epoch [46/50], Loss: 0.5002\n",
      "Epoch [47/50], Loss: 0.5003\n",
      "Epoch [48/50], Loss: 0.5003\n",
      "Epoch [49/50], Loss: 0.5002\n",
      "Epoch [50/50], Loss: 0.5002\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.494612\n",
      "Number of dead neurons in Default Sparse Autoencoder: 103 out of 128 (80.47%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 103 (80.47%)\n",
      "Active features: 25 (19.53%)\n",
      "Mean activation frequency: 0.0391\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.205965\n",
      "    Dead neurons: 103/128 (80.47%)\n",
      "    Test loss: 0.494612\n",
      "    Mean activation strength: 0.205965\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8276\n",
      "Epoch [2/50], Loss: 0.4684\n",
      "Epoch [3/50], Loss: 0.4488\n",
      "Epoch [4/50], Loss: 0.4414\n",
      "Epoch [5/50], Loss: 0.4376\n",
      "Epoch [6/50], Loss: 0.4352\n",
      "Epoch [7/50], Loss: 0.4337\n",
      "Epoch [8/50], Loss: 0.4327\n",
      "Epoch [9/50], Loss: 0.4320\n",
      "Epoch [10/50], Loss: 0.4317\n",
      "Epoch [11/50], Loss: 0.4312\n",
      "Epoch [12/50], Loss: 0.4310\n",
      "Epoch [13/50], Loss: 0.4306\n",
      "Epoch [14/50], Loss: 0.4304\n",
      "Epoch [15/50], Loss: 0.4302\n",
      "Epoch [16/50], Loss: 0.4298\n",
      "Epoch [17/50], Loss: 0.4294\n",
      "Epoch [18/50], Loss: 0.4294\n",
      "Epoch [19/50], Loss: 0.4292\n",
      "Epoch [20/50], Loss: 0.4291\n",
      "Epoch [21/50], Loss: 0.4286\n",
      "Epoch [22/50], Loss: 0.4285\n",
      "Epoch [23/50], Loss: 0.4281\n",
      "Epoch [24/50], Loss: 0.4280\n",
      "Epoch [25/50], Loss: 0.4278\n",
      "Epoch [26/50], Loss: 0.4277\n",
      "Epoch [27/50], Loss: 0.4278\n",
      "Epoch [28/50], Loss: 0.4277\n",
      "Epoch [29/50], Loss: 0.4276\n",
      "Epoch [30/50], Loss: 0.4276\n",
      "Epoch [31/50], Loss: 0.4275\n",
      "Epoch [32/50], Loss: 0.4275\n",
      "Epoch [33/50], Loss: 0.4276\n",
      "Epoch [34/50], Loss: 0.4275\n",
      "Epoch [35/50], Loss: 0.4275\n",
      "Epoch [36/50], Loss: 0.4276\n",
      "Epoch [37/50], Loss: 0.4276\n",
      "Epoch [38/50], Loss: 0.4276\n",
      "Epoch [39/50], Loss: 0.4275\n",
      "Epoch [40/50], Loss: 0.4275\n",
      "Epoch [41/50], Loss: 0.4275\n",
      "Epoch [42/50], Loss: 0.4273\n",
      "Epoch [43/50], Loss: 0.4274\n",
      "Epoch [44/50], Loss: 0.4273\n",
      "Epoch [45/50], Loss: 0.4273\n",
      "Epoch [46/50], Loss: 0.4274\n",
      "Epoch [47/50], Loss: 0.4273\n",
      "Epoch [48/50], Loss: 0.4272\n",
      "Epoch [49/50], Loss: 0.4271\n",
      "Epoch [50/50], Loss: 0.4273\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.423191\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 77 out of 128 (60.16%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 77 (60.16%)\n",
      "Active features: 51 (39.84%)\n",
      "Mean activation frequency: 0.0391\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.230859\n",
      "    Dead neurons: 77/128 (60.16%)\n",
      "    Test loss: 0.423191\n",
      "    Mean activation strength: 0.230859\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2698\n",
      "Epoch [2/50], Loss: 0.1523\n",
      "Epoch [3/50], Loss: 0.1460\n",
      "Epoch [4/50], Loss: 0.1437\n",
      "Epoch [5/50], Loss: 0.1425\n",
      "Epoch [6/50], Loss: 0.1417\n",
      "Epoch [7/50], Loss: 0.1412\n",
      "Epoch [8/50], Loss: 0.1410\n",
      "Epoch [9/50], Loss: 0.1407\n",
      "Epoch [10/50], Loss: 0.1406\n",
      "Epoch [11/50], Loss: 0.1404\n",
      "Epoch [12/50], Loss: 0.1404\n",
      "Epoch [13/50], Loss: 0.1403\n",
      "Epoch [14/50], Loss: 0.1402\n",
      "Epoch [15/50], Loss: 0.1401\n",
      "Epoch [16/50], Loss: 0.1399\n",
      "Epoch [17/50], Loss: 0.1398\n",
      "Epoch [18/50], Loss: 0.1397\n",
      "Epoch [19/50], Loss: 0.1397\n",
      "Epoch [20/50], Loss: 0.1395\n",
      "Epoch [21/50], Loss: 0.1395\n",
      "Epoch [22/50], Loss: 0.1394\n",
      "Epoch [23/50], Loss: 0.1393\n",
      "Epoch [24/50], Loss: 0.1392\n",
      "Epoch [25/50], Loss: 0.1392\n",
      "Epoch [26/50], Loss: 0.1392\n",
      "Epoch [27/50], Loss: 0.1391\n",
      "Epoch [28/50], Loss: 0.1390\n",
      "Epoch [29/50], Loss: 0.1390\n",
      "Epoch [30/50], Loss: 0.1389\n",
      "Epoch [31/50], Loss: 0.1389\n",
      "Epoch [32/50], Loss: 0.1389\n",
      "Epoch [33/50], Loss: 0.1389\n",
      "Epoch [34/50], Loss: 0.1389\n",
      "Epoch [35/50], Loss: 0.1389\n",
      "Epoch [36/50], Loss: 0.1389\n",
      "Epoch [37/50], Loss: 0.1388\n",
      "Epoch [38/50], Loss: 0.1389\n",
      "Epoch [39/50], Loss: 0.1388\n",
      "Epoch [40/50], Loss: 0.1389\n",
      "Epoch [41/50], Loss: 0.1388\n",
      "Epoch [42/50], Loss: 0.1388\n",
      "Epoch [43/50], Loss: 0.1387\n",
      "Epoch [44/50], Loss: 0.1387\n",
      "Epoch [45/50], Loss: 0.1387\n",
      "Epoch [46/50], Loss: 0.1388\n",
      "Epoch [47/50], Loss: 0.1387\n",
      "Epoch [48/50], Loss: 0.1387\n",
      "Epoch [49/50], Loss: 0.1387\n",
      "Epoch [50/50], Loss: 0.1387\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.135053\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 77 out of 128 (60.16%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 77 (60.16%)\n",
      "Active features: 51 (39.84%)\n",
      "Mean activation frequency: 0.0391\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.232987\n",
      "    Dead neurons: 77/128 (60.16%)\n",
      "    Test loss: 0.135053\n",
      "    Mean activation strength: 0.232987\n",
      "\n",
      "Hidden Size: 128, k_top: 10\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.9370\n",
      "Epoch [2/50], Loss: 0.5011\n",
      "Epoch [3/50], Loss: 0.4658\n",
      "Epoch [4/50], Loss: 0.4542\n",
      "Epoch [5/50], Loss: 0.4495\n",
      "Epoch [6/50], Loss: 0.4475\n",
      "Epoch [7/50], Loss: 0.4462\n",
      "Epoch [8/50], Loss: 0.4449\n",
      "Epoch [9/50], Loss: 0.4433\n",
      "Epoch [10/50], Loss: 0.4422\n",
      "Epoch [11/50], Loss: 0.4415\n",
      "Epoch [12/50], Loss: 0.4408\n",
      "Epoch [13/50], Loss: 0.4402\n",
      "Epoch [14/50], Loss: 0.4394\n",
      "Epoch [15/50], Loss: 0.4387\n",
      "Epoch [16/50], Loss: 0.4379\n",
      "Epoch [17/50], Loss: 0.4372\n",
      "Epoch [18/50], Loss: 0.4369\n",
      "Epoch [19/50], Loss: 0.4364\n",
      "Epoch [20/50], Loss: 0.4361\n",
      "Epoch [21/50], Loss: 0.4359\n",
      "Epoch [22/50], Loss: 0.4357\n",
      "Epoch [23/50], Loss: 0.4355\n",
      "Epoch [24/50], Loss: 0.4352\n",
      "Epoch [25/50], Loss: 0.4350\n",
      "Epoch [26/50], Loss: 0.4348\n",
      "Epoch [27/50], Loss: 0.4345\n",
      "Epoch [28/50], Loss: 0.4342\n",
      "Epoch [29/50], Loss: 0.4341\n",
      "Epoch [30/50], Loss: 0.4340\n",
      "Epoch [31/50], Loss: 0.4339\n",
      "Epoch [32/50], Loss: 0.4340\n",
      "Epoch [33/50], Loss: 0.4340\n",
      "Epoch [34/50], Loss: 0.4341\n",
      "Epoch [35/50], Loss: 0.4341\n",
      "Epoch [36/50], Loss: 0.4339\n",
      "Epoch [37/50], Loss: 0.4339\n",
      "Epoch [38/50], Loss: 0.4339\n",
      "Epoch [39/50], Loss: 0.4338\n",
      "Epoch [40/50], Loss: 0.4337\n",
      "Epoch [41/50], Loss: 0.4337\n",
      "Epoch [42/50], Loss: 0.4337\n",
      "Epoch [43/50], Loss: 0.4336\n",
      "Epoch [44/50], Loss: 0.4335\n",
      "Epoch [45/50], Loss: 0.4334\n",
      "Epoch [46/50], Loss: 0.4335\n",
      "Epoch [47/50], Loss: 0.4334\n",
      "Epoch [48/50], Loss: 0.4334\n",
      "Epoch [49/50], Loss: 0.4333\n",
      "Epoch [50/50], Loss: 0.4334\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.427059\n",
      "Number of dead neurons in Default Sparse Autoencoder: 103 out of 128 (80.47%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 103 (80.47%)\n",
      "Active features: 25 (19.53%)\n",
      "Mean activation frequency: 0.0781\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.153683\n",
      "    Dead neurons: 103/128 (80.47%)\n",
      "    Test loss: 0.427059\n",
      "    Mean activation strength: 0.153683\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.7793\n",
      "Epoch [2/50], Loss: 0.3920\n",
      "Epoch [3/50], Loss: 0.3638\n",
      "Epoch [4/50], Loss: 0.3531\n",
      "Epoch [5/50], Loss: 0.3480\n",
      "Epoch [6/50], Loss: 0.3449\n",
      "Epoch [7/50], Loss: 0.3427\n",
      "Epoch [8/50], Loss: 0.3409\n",
      "Epoch [9/50], Loss: 0.3397\n",
      "Epoch [10/50], Loss: 0.3390\n",
      "Epoch [11/50], Loss: 0.3382\n",
      "Epoch [12/50], Loss: 0.3377\n",
      "Epoch [13/50], Loss: 0.3372\n",
      "Epoch [14/50], Loss: 0.3367\n",
      "Epoch [15/50], Loss: 0.3365\n",
      "Epoch [16/50], Loss: 0.3361\n",
      "Epoch [17/50], Loss: 0.3359\n",
      "Epoch [18/50], Loss: 0.3360\n",
      "Epoch [19/50], Loss: 0.3361\n",
      "Epoch [20/50], Loss: 0.3363\n",
      "Epoch [21/50], Loss: 0.3363\n",
      "Epoch [22/50], Loss: 0.3364\n",
      "Epoch [23/50], Loss: 0.3364\n",
      "Epoch [24/50], Loss: 0.3364\n",
      "Epoch [25/50], Loss: 0.3363\n",
      "Epoch [26/50], Loss: 0.3357\n",
      "Epoch [27/50], Loss: 0.3357\n",
      "Epoch [28/50], Loss: 0.3356\n",
      "Epoch [29/50], Loss: 0.3355\n",
      "Epoch [30/50], Loss: 0.3355\n",
      "Epoch [31/50], Loss: 0.3355\n",
      "Epoch [32/50], Loss: 0.3356\n",
      "Epoch [33/50], Loss: 0.3355\n",
      "Epoch [34/50], Loss: 0.3356\n",
      "Epoch [35/50], Loss: 0.3356\n",
      "Epoch [36/50], Loss: 0.3356\n",
      "Epoch [37/50], Loss: 0.3357\n",
      "Epoch [38/50], Loss: 0.3358\n",
      "Epoch [39/50], Loss: 0.3358\n",
      "Epoch [40/50], Loss: 0.3358\n",
      "Epoch [41/50], Loss: 0.3357\n",
      "Epoch [42/50], Loss: 0.3358\n",
      "Epoch [43/50], Loss: 0.3371\n",
      "Epoch [44/50], Loss: 0.3369\n",
      "Epoch [45/50], Loss: 0.3370\n",
      "Epoch [46/50], Loss: 0.3370\n",
      "Epoch [47/50], Loss: 0.3373\n",
      "Epoch [48/50], Loss: 0.3370\n",
      "Epoch [49/50], Loss: 0.3373\n",
      "Epoch [50/50], Loss: 0.3370\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.333827\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 53 out of 128 (41.41%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 53 (41.41%)\n",
      "Active features: 75 (58.59%)\n",
      "Mean activation frequency: 0.0781\n",
      "Median activation frequency: 0.0677\n",
      "Mean activation strength (when active): 0.170654\n",
      "    Dead neurons: 53/128 (41.41%)\n",
      "    Test loss: 0.333827\n",
      "    Mean activation strength: 0.170654\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2541\n",
      "Epoch [2/50], Loss: 0.1276\n",
      "Epoch [3/50], Loss: 0.1184\n",
      "Epoch [4/50], Loss: 0.1147\n",
      "Epoch [5/50], Loss: 0.1129\n",
      "Epoch [6/50], Loss: 0.1119\n",
      "Epoch [7/50], Loss: 0.1112\n",
      "Epoch [8/50], Loss: 0.1107\n",
      "Epoch [9/50], Loss: 0.1104\n",
      "Epoch [10/50], Loss: 0.1102\n",
      "Epoch [11/50], Loss: 0.1100\n",
      "Epoch [12/50], Loss: 0.1099\n",
      "Epoch [13/50], Loss: 0.1097\n",
      "Epoch [14/50], Loss: 0.1096\n",
      "Epoch [15/50], Loss: 0.1096\n",
      "Epoch [16/50], Loss: 0.1095\n",
      "Epoch [17/50], Loss: 0.1094\n",
      "Epoch [18/50], Loss: 0.1093\n",
      "Epoch [19/50], Loss: 0.1093\n",
      "Epoch [20/50], Loss: 0.1093\n",
      "Epoch [21/50], Loss: 0.1092\n",
      "Epoch [22/50], Loss: 0.1092\n",
      "Epoch [23/50], Loss: 0.1092\n",
      "Epoch [24/50], Loss: 0.1091\n",
      "Epoch [25/50], Loss: 0.1091\n",
      "Epoch [26/50], Loss: 0.1091\n",
      "Epoch [27/50], Loss: 0.1091\n",
      "Epoch [28/50], Loss: 0.1091\n",
      "Epoch [29/50], Loss: 0.1091\n",
      "Epoch [30/50], Loss: 0.1091\n",
      "Epoch [31/50], Loss: 0.1091\n",
      "Epoch [32/50], Loss: 0.1091\n",
      "Epoch [33/50], Loss: 0.1091\n",
      "Epoch [34/50], Loss: 0.1092\n",
      "Epoch [35/50], Loss: 0.1092\n",
      "Epoch [36/50], Loss: 0.1092\n",
      "Epoch [37/50], Loss: 0.1093\n",
      "Epoch [38/50], Loss: 0.1091\n",
      "Epoch [39/50], Loss: 0.1091\n",
      "Epoch [40/50], Loss: 0.1091\n",
      "Epoch [41/50], Loss: 0.1092\n",
      "Epoch [42/50], Loss: 0.1091\n",
      "Epoch [43/50], Loss: 0.1090\n",
      "Epoch [44/50], Loss: 0.1091\n",
      "Epoch [45/50], Loss: 0.1091\n",
      "Epoch [46/50], Loss: 0.1089\n",
      "Epoch [47/50], Loss: 0.1090\n",
      "Epoch [48/50], Loss: 0.1090\n",
      "Epoch [49/50], Loss: 0.1088\n",
      "Epoch [50/50], Loss: 0.1087\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.105228\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 51 out of 128 (39.84%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 51 (39.84%)\n",
      "Active features: 77 (60.16%)\n",
      "Mean activation frequency: 0.0781\n",
      "Median activation frequency: 0.0721\n",
      "Mean activation strength (when active): 0.169001\n",
      "    Dead neurons: 51/128 (39.84%)\n",
      "    Test loss: 0.105228\n",
      "    Mean activation strength: 0.169001\n",
      "\n",
      "Hidden Size: 128, k_top: 20\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.9979\n",
      "Epoch [2/50], Loss: 0.4736\n",
      "Epoch [3/50], Loss: 0.3846\n",
      "Epoch [4/50], Loss: 0.3621\n",
      "Epoch [5/50], Loss: 0.3526\n",
      "Epoch [6/50], Loss: 0.3490\n",
      "Epoch [7/50], Loss: 0.3477\n",
      "Epoch [8/50], Loss: 0.3468\n",
      "Epoch [9/50], Loss: 0.3459\n",
      "Epoch [10/50], Loss: 0.3450\n",
      "Epoch [11/50], Loss: 0.3441\n",
      "Epoch [12/50], Loss: 0.3432\n",
      "Epoch [13/50], Loss: 0.3424\n",
      "Epoch [14/50], Loss: 0.3419\n",
      "Epoch [15/50], Loss: 0.3418\n",
      "Epoch [16/50], Loss: 0.3416\n",
      "Epoch [17/50], Loss: 0.3414\n",
      "Epoch [18/50], Loss: 0.3413\n",
      "Epoch [19/50], Loss: 0.3411\n",
      "Epoch [20/50], Loss: 0.3411\n",
      "Epoch [21/50], Loss: 0.3410\n",
      "Epoch [22/50], Loss: 0.3410\n",
      "Epoch [23/50], Loss: 0.3408\n",
      "Epoch [24/50], Loss: 0.3408\n",
      "Epoch [25/50], Loss: 0.3407\n",
      "Epoch [26/50], Loss: 0.3406\n",
      "Epoch [27/50], Loss: 0.3405\n",
      "Epoch [28/50], Loss: 0.3405\n",
      "Epoch [29/50], Loss: 0.3404\n",
      "Epoch [30/50], Loss: 0.3403\n",
      "Epoch [31/50], Loss: 0.3402\n",
      "Epoch [32/50], Loss: 0.3402\n",
      "Epoch [33/50], Loss: 0.3402\n",
      "Epoch [34/50], Loss: 0.3402\n",
      "Epoch [35/50], Loss: 0.3402\n",
      "Epoch [36/50], Loss: 0.3400\n",
      "Epoch [37/50], Loss: 0.3400\n",
      "Epoch [38/50], Loss: 0.3401\n",
      "Epoch [39/50], Loss: 0.3401\n",
      "Epoch [40/50], Loss: 0.3400\n",
      "Epoch [41/50], Loss: 0.3400\n",
      "Epoch [42/50], Loss: 0.3400\n",
      "Epoch [43/50], Loss: 0.3400\n",
      "Epoch [44/50], Loss: 0.3400\n",
      "Epoch [45/50], Loss: 0.3399\n",
      "Epoch [46/50], Loss: 0.3400\n",
      "Epoch [47/50], Loss: 0.3400\n",
      "Epoch [48/50], Loss: 0.3400\n",
      "Epoch [49/50], Loss: 0.3399\n",
      "Epoch [50/50], Loss: 0.3399\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.331554\n",
      "Number of dead neurons in Default Sparse Autoencoder: 96 out of 128 (75.00%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 96 (75.00%)\n",
      "Active features: 32 (25.00%)\n",
      "Mean activation frequency: 0.1561\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.119793\n",
      "    Dead neurons: 96/128 (75.00%)\n",
      "    Test loss: 0.331554\n",
      "    Mean activation strength: 0.119793\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.7493\n",
      "Epoch [2/50], Loss: 0.3231\n",
      "Epoch [3/50], Loss: 0.2846\n",
      "Epoch [4/50], Loss: 0.2719\n",
      "Epoch [5/50], Loss: 0.2670\n",
      "Epoch [6/50], Loss: 0.2638\n",
      "Epoch [7/50], Loss: 0.2609\n",
      "Epoch [8/50], Loss: 0.2588\n",
      "Epoch [9/50], Loss: 0.2576\n",
      "Epoch [10/50], Loss: 0.2568\n",
      "Epoch [11/50], Loss: 0.2557\n",
      "Epoch [12/50], Loss: 0.2549\n",
      "Epoch [13/50], Loss: 0.2542\n",
      "Epoch [14/50], Loss: 0.2537\n",
      "Epoch [15/50], Loss: 0.2529\n",
      "Epoch [16/50], Loss: 0.2523\n",
      "Epoch [17/50], Loss: 0.2521\n",
      "Epoch [18/50], Loss: 0.2520\n",
      "Epoch [19/50], Loss: 0.2518\n",
      "Epoch [20/50], Loss: 0.2516\n",
      "Epoch [21/50], Loss: 0.2516\n",
      "Epoch [22/50], Loss: 0.2514\n",
      "Epoch [23/50], Loss: 0.2512\n",
      "Epoch [24/50], Loss: 0.2512\n",
      "Epoch [25/50], Loss: 0.2511\n",
      "Epoch [26/50], Loss: 0.2510\n",
      "Epoch [27/50], Loss: 0.2509\n",
      "Epoch [28/50], Loss: 0.2500\n",
      "Epoch [29/50], Loss: 0.2499\n",
      "Epoch [30/50], Loss: 0.2499\n",
      "Epoch [31/50], Loss: 0.2498\n",
      "Epoch [32/50], Loss: 0.2499\n",
      "Epoch [33/50], Loss: 0.2498\n",
      "Epoch [34/50], Loss: 0.2498\n",
      "Epoch [35/50], Loss: 0.2498\n",
      "Epoch [36/50], Loss: 0.2499\n",
      "Epoch [37/50], Loss: 0.2499\n",
      "Epoch [38/50], Loss: 0.2494\n",
      "Epoch [39/50], Loss: 0.2493\n",
      "Epoch [40/50], Loss: 0.2492\n",
      "Epoch [41/50], Loss: 0.2492\n",
      "Epoch [42/50], Loss: 0.2491\n",
      "Epoch [43/50], Loss: 0.2490\n",
      "Epoch [44/50], Loss: 0.2490\n",
      "Epoch [45/50], Loss: 0.2490\n",
      "Epoch [46/50], Loss: 0.2489\n",
      "Epoch [47/50], Loss: 0.2495\n",
      "Epoch [48/50], Loss: 0.2489\n",
      "Epoch [49/50], Loss: 0.2489\n",
      "Epoch [50/50], Loss: 0.2490\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.245686\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 33 out of 128 (25.78%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 33 (25.78%)\n",
      "Active features: 95 (74.22%)\n",
      "Mean activation frequency: 0.1562\n",
      "Median activation frequency: 0.1298\n",
      "Mean activation strength (when active): 0.126509\n",
      "    Dead neurons: 33/128 (25.78%)\n",
      "    Test loss: 0.245686\n",
      "    Mean activation strength: 0.126509\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2446\n",
      "Epoch [2/50], Loss: 0.1056\n",
      "Epoch [3/50], Loss: 0.0926\n",
      "Epoch [4/50], Loss: 0.0884\n",
      "Epoch [5/50], Loss: 0.0866\n",
      "Epoch [6/50], Loss: 0.0853\n",
      "Epoch [7/50], Loss: 0.0842\n",
      "Epoch [8/50], Loss: 0.0835\n",
      "Epoch [9/50], Loss: 0.0831\n",
      "Epoch [10/50], Loss: 0.0827\n",
      "Epoch [11/50], Loss: 0.0825\n",
      "Epoch [12/50], Loss: 0.0823\n",
      "Epoch [13/50], Loss: 0.0823\n",
      "Epoch [14/50], Loss: 0.0822\n",
      "Epoch [15/50], Loss: 0.0822\n",
      "Epoch [16/50], Loss: 0.0822\n",
      "Epoch [17/50], Loss: 0.0822\n",
      "Epoch [18/50], Loss: 0.0821\n",
      "Epoch [19/50], Loss: 0.0821\n",
      "Epoch [20/50], Loss: 0.0821\n",
      "Epoch [21/50], Loss: 0.0821\n",
      "Epoch [22/50], Loss: 0.0820\n",
      "Epoch [23/50], Loss: 0.0820\n",
      "Epoch [24/50], Loss: 0.0820\n",
      "Epoch [25/50], Loss: 0.0819\n",
      "Epoch [26/50], Loss: 0.0819\n",
      "Epoch [27/50], Loss: 0.0819\n",
      "Epoch [28/50], Loss: 0.0819\n",
      "Epoch [29/50], Loss: 0.0819\n",
      "Epoch [30/50], Loss: 0.0819\n",
      "Epoch [31/50], Loss: 0.0818\n",
      "Epoch [32/50], Loss: 0.0818\n",
      "Epoch [33/50], Loss: 0.0818\n",
      "Epoch [34/50], Loss: 0.0817\n",
      "Epoch [35/50], Loss: 0.0814\n",
      "Epoch [36/50], Loss: 0.0814\n",
      "Epoch [37/50], Loss: 0.0813\n",
      "Epoch [38/50], Loss: 0.0813\n",
      "Epoch [39/50], Loss: 0.0812\n",
      "Epoch [40/50], Loss: 0.0812\n",
      "Epoch [41/50], Loss: 0.0811\n",
      "Epoch [42/50], Loss: 0.0809\n",
      "Epoch [43/50], Loss: 0.0808\n",
      "Epoch [44/50], Loss: 0.0807\n",
      "Epoch [45/50], Loss: 0.0806\n",
      "Epoch [46/50], Loss: 0.0806\n",
      "Epoch [47/50], Loss: 0.0806\n",
      "Epoch [48/50], Loss: 0.0806\n",
      "Epoch [49/50], Loss: 0.0806\n",
      "Epoch [50/50], Loss: 0.0806\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.077991\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 37 out of 128 (28.91%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 37 (28.91%)\n",
      "Active features: 91 (71.09%)\n",
      "Mean activation frequency: 0.1562\n",
      "Median activation frequency: 0.1232\n",
      "Mean activation strength (when active): 0.126917\n",
      "    Dead neurons: 37/128 (28.91%)\n",
      "    Test loss: 0.077991\n",
      "    Mean activation strength: 0.126917\n",
      "\n",
      "Hidden Size: 128, k_top: 30\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.0442\n",
      "Epoch [2/50], Loss: 0.4873\n",
      "Epoch [3/50], Loss: 0.3736\n",
      "Epoch [4/50], Loss: 0.3358\n",
      "Epoch [5/50], Loss: 0.3172\n",
      "Epoch [6/50], Loss: 0.3117\n",
      "Epoch [7/50], Loss: 0.3094\n",
      "Epoch [8/50], Loss: 0.3080\n",
      "Epoch [9/50], Loss: 0.3066\n",
      "Epoch [10/50], Loss: 0.3053\n",
      "Epoch [11/50], Loss: 0.3044\n",
      "Epoch [12/50], Loss: 0.3038\n",
      "Epoch [13/50], Loss: 0.3035\n",
      "Epoch [14/50], Loss: 0.3033\n",
      "Epoch [15/50], Loss: 0.3032\n",
      "Epoch [16/50], Loss: 0.3031\n",
      "Epoch [17/50], Loss: 0.3029\n",
      "Epoch [18/50], Loss: 0.3029\n",
      "Epoch [19/50], Loss: 0.3028\n",
      "Epoch [20/50], Loss: 0.3027\n",
      "Epoch [21/50], Loss: 0.3027\n",
      "Epoch [22/50], Loss: 0.3027\n",
      "Epoch [23/50], Loss: 0.3026\n",
      "Epoch [24/50], Loss: 0.3025\n",
      "Epoch [25/50], Loss: 0.3025\n",
      "Epoch [26/50], Loss: 0.3025\n",
      "Epoch [27/50], Loss: 0.3024\n",
      "Epoch [28/50], Loss: 0.3023\n",
      "Epoch [29/50], Loss: 0.3023\n",
      "Epoch [30/50], Loss: 0.3022\n",
      "Epoch [31/50], Loss: 0.3021\n",
      "Epoch [32/50], Loss: 0.3021\n",
      "Epoch [33/50], Loss: 0.3020\n",
      "Epoch [34/50], Loss: 0.3020\n",
      "Epoch [35/50], Loss: 0.3020\n",
      "Epoch [36/50], Loss: 0.3019\n",
      "Epoch [37/50], Loss: 0.3019\n",
      "Epoch [38/50], Loss: 0.3019\n",
      "Epoch [39/50], Loss: 0.3019\n",
      "Epoch [40/50], Loss: 0.3019\n",
      "Epoch [41/50], Loss: 0.3019\n",
      "Epoch [42/50], Loss: 0.3020\n",
      "Epoch [43/50], Loss: 0.3019\n",
      "Epoch [44/50], Loss: 0.3019\n",
      "Epoch [45/50], Loss: 0.3019\n",
      "Epoch [46/50], Loss: 0.3019\n",
      "Epoch [47/50], Loss: 0.3019\n",
      "Epoch [48/50], Loss: 0.3019\n",
      "Epoch [49/50], Loss: 0.3019\n",
      "Epoch [50/50], Loss: 0.3019\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.293191\n",
      "Number of dead neurons in Default Sparse Autoencoder: 90 out of 128 (70.31%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 90 (70.31%)\n",
      "Active features: 38 (29.69%)\n",
      "Mean activation frequency: 0.2303\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.099548\n",
      "    Dead neurons: 90/128 (70.31%)\n",
      "    Test loss: 0.293191\n",
      "    Mean activation strength: 0.099548\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.7583\n",
      "Epoch [2/50], Loss: 0.2909\n",
      "Epoch [3/50], Loss: 0.2414\n",
      "Epoch [4/50], Loss: 0.2212\n",
      "Epoch [5/50], Loss: 0.2115\n",
      "Epoch [6/50], Loss: 0.2054\n",
      "Epoch [7/50], Loss: 0.2026\n",
      "Epoch [8/50], Loss: 0.2006\n",
      "Epoch [9/50], Loss: 0.1992\n",
      "Epoch [10/50], Loss: 0.1983\n",
      "Epoch [11/50], Loss: 0.1969\n",
      "Epoch [12/50], Loss: 0.1957\n",
      "Epoch [13/50], Loss: 0.1948\n",
      "Epoch [14/50], Loss: 0.1941\n",
      "Epoch [15/50], Loss: 0.1937\n",
      "Epoch [16/50], Loss: 0.1933\n",
      "Epoch [17/50], Loss: 0.1930\n",
      "Epoch [18/50], Loss: 0.1928\n",
      "Epoch [19/50], Loss: 0.1926\n",
      "Epoch [20/50], Loss: 0.1924\n",
      "Epoch [21/50], Loss: 0.1922\n",
      "Epoch [22/50], Loss: 0.1919\n",
      "Epoch [23/50], Loss: 0.1914\n",
      "Epoch [24/50], Loss: 0.1909\n",
      "Epoch [25/50], Loss: 0.1905\n",
      "Epoch [26/50], Loss: 0.1902\n",
      "Epoch [27/50], Loss: 0.1901\n",
      "Epoch [28/50], Loss: 0.1899\n",
      "Epoch [29/50], Loss: 0.1896\n",
      "Epoch [30/50], Loss: 0.1895\n",
      "Epoch [31/50], Loss: 0.1894\n",
      "Epoch [32/50], Loss: 0.1894\n",
      "Epoch [33/50], Loss: 0.1893\n",
      "Epoch [34/50], Loss: 0.1894\n",
      "Epoch [35/50], Loss: 0.1893\n",
      "Epoch [36/50], Loss: 0.1892\n",
      "Epoch [37/50], Loss: 0.1888\n",
      "Epoch [38/50], Loss: 0.1883\n",
      "Epoch [39/50], Loss: 0.1881\n",
      "Epoch [40/50], Loss: 0.1880\n",
      "Epoch [41/50], Loss: 0.1880\n",
      "Epoch [42/50], Loss: 0.1879\n",
      "Epoch [43/50], Loss: 0.1879\n",
      "Epoch [44/50], Loss: 0.1878\n",
      "Epoch [45/50], Loss: 0.1878\n",
      "Epoch [46/50], Loss: 0.1878\n",
      "Epoch [47/50], Loss: 0.1878\n",
      "Epoch [48/50], Loss: 0.1877\n",
      "Epoch [49/50], Loss: 0.1877\n",
      "Epoch [50/50], Loss: 0.1877\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.184372\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 31 out of 128 (24.22%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 31 (24.22%)\n",
      "Active features: 97 (75.78%)\n",
      "Mean activation frequency: 0.2343\n",
      "Median activation frequency: 0.2125\n",
      "Mean activation strength (when active): 0.110270\n",
      "    Dead neurons: 31/128 (24.22%)\n",
      "    Test loss: 0.184372\n",
      "    Mean activation strength: 0.110270\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2473\n",
      "Epoch [2/50], Loss: 0.0947\n",
      "Epoch [3/50], Loss: 0.0782\n",
      "Epoch [4/50], Loss: 0.0715\n",
      "Epoch [5/50], Loss: 0.0686\n",
      "Epoch [6/50], Loss: 0.0670\n",
      "Epoch [7/50], Loss: 0.0657\n",
      "Epoch [8/50], Loss: 0.0650\n",
      "Epoch [9/50], Loss: 0.0645\n",
      "Epoch [10/50], Loss: 0.0640\n",
      "Epoch [11/50], Loss: 0.0638\n",
      "Epoch [12/50], Loss: 0.0636\n",
      "Epoch [13/50], Loss: 0.0634\n",
      "Epoch [14/50], Loss: 0.0632\n",
      "Epoch [15/50], Loss: 0.0632\n",
      "Epoch [16/50], Loss: 0.0631\n",
      "Epoch [17/50], Loss: 0.0630\n",
      "Epoch [18/50], Loss: 0.0630\n",
      "Epoch [19/50], Loss: 0.0630\n",
      "Epoch [20/50], Loss: 0.0630\n",
      "Epoch [21/50], Loss: 0.0629\n",
      "Epoch [22/50], Loss: 0.0629\n",
      "Epoch [23/50], Loss: 0.0629\n",
      "Epoch [24/50], Loss: 0.0628\n",
      "Epoch [25/50], Loss: 0.0627\n",
      "Epoch [26/50], Loss: 0.0626\n",
      "Epoch [27/50], Loss: 0.0625\n",
      "Epoch [28/50], Loss: 0.0625\n",
      "Epoch [29/50], Loss: 0.0625\n",
      "Epoch [30/50], Loss: 0.0624\n",
      "Epoch [31/50], Loss: 0.0622\n",
      "Epoch [32/50], Loss: 0.0622\n",
      "Epoch [33/50], Loss: 0.0622\n",
      "Epoch [34/50], Loss: 0.0622\n",
      "Epoch [35/50], Loss: 0.0621\n",
      "Epoch [36/50], Loss: 0.0621\n",
      "Epoch [37/50], Loss: 0.0621\n",
      "Epoch [38/50], Loss: 0.0621\n",
      "Epoch [39/50], Loss: 0.0621\n",
      "Epoch [40/50], Loss: 0.0620\n",
      "Epoch [41/50], Loss: 0.0620\n",
      "Epoch [42/50], Loss: 0.0620\n",
      "Epoch [43/50], Loss: 0.0620\n",
      "Epoch [44/50], Loss: 0.0620\n",
      "Epoch [45/50], Loss: 0.0619\n",
      "Epoch [46/50], Loss: 0.0619\n",
      "Epoch [47/50], Loss: 0.0619\n",
      "Epoch [48/50], Loss: 0.0619\n",
      "Epoch [49/50], Loss: 0.0618\n",
      "Epoch [50/50], Loss: 0.0618\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.059474\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 35 out of 128 (27.34%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 35 (27.34%)\n",
      "Active features: 93 (72.66%)\n",
      "Mean activation frequency: 0.2343\n",
      "Median activation frequency: 0.2193\n",
      "Mean activation strength (when active): 0.109159\n",
      "    Dead neurons: 35/128 (27.34%)\n",
      "    Test loss: 0.059474\n",
      "    Mean activation strength: 0.109159\n",
      "\n",
      "Hidden Size: 128, k_top: 40\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.0807\n",
      "Epoch [2/50], Loss: 0.5141\n",
      "Epoch [3/50], Loss: 0.3977\n",
      "Epoch [4/50], Loss: 0.3525\n",
      "Epoch [5/50], Loss: 0.3302\n",
      "Epoch [6/50], Loss: 0.3174\n",
      "Epoch [7/50], Loss: 0.3123\n",
      "Epoch [8/50], Loss: 0.3055\n",
      "Epoch [9/50], Loss: 0.3013\n",
      "Epoch [10/50], Loss: 0.2988\n",
      "Epoch [11/50], Loss: 0.2978\n",
      "Epoch [12/50], Loss: 0.2968\n",
      "Epoch [13/50], Loss: 0.2961\n",
      "Epoch [14/50], Loss: 0.2956\n",
      "Epoch [15/50], Loss: 0.2953\n",
      "Epoch [16/50], Loss: 0.2949\n",
      "Epoch [17/50], Loss: 0.2945\n",
      "Epoch [18/50], Loss: 0.2924\n",
      "Epoch [19/50], Loss: 0.2903\n",
      "Epoch [20/50], Loss: 0.2892\n",
      "Epoch [21/50], Loss: 0.2873\n",
      "Epoch [22/50], Loss: 0.2868\n",
      "Epoch [23/50], Loss: 0.2862\n",
      "Epoch [24/50], Loss: 0.2858\n",
      "Epoch [25/50], Loss: 0.2856\n",
      "Epoch [26/50], Loss: 0.2854\n",
      "Epoch [27/50], Loss: 0.2852\n",
      "Epoch [28/50], Loss: 0.2851\n",
      "Epoch [29/50], Loss: 0.2849\n",
      "Epoch [30/50], Loss: 0.2847\n",
      "Epoch [31/50], Loss: 0.2844\n",
      "Epoch [32/50], Loss: 0.2842\n",
      "Epoch [33/50], Loss: 0.2839\n",
      "Epoch [34/50], Loss: 0.2836\n",
      "Epoch [35/50], Loss: 0.2833\n",
      "Epoch [36/50], Loss: 0.2829\n",
      "Epoch [37/50], Loss: 0.2827\n",
      "Epoch [38/50], Loss: 0.2825\n",
      "Epoch [39/50], Loss: 0.2824\n",
      "Epoch [40/50], Loss: 0.2822\n",
      "Epoch [41/50], Loss: 0.2821\n",
      "Epoch [42/50], Loss: 0.2820\n",
      "Epoch [43/50], Loss: 0.2819\n",
      "Epoch [44/50], Loss: 0.2818\n",
      "Epoch [45/50], Loss: 0.2817\n",
      "Epoch [46/50], Loss: 0.2817\n",
      "Epoch [47/50], Loss: 0.2817\n",
      "Epoch [48/50], Loss: 0.2816\n",
      "Epoch [49/50], Loss: 0.2816\n",
      "Epoch [50/50], Loss: 0.2816\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.273405\n",
      "Number of dead neurons in Default Sparse Autoencoder: 86 out of 128 (67.19%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 86 (67.19%)\n",
      "Active features: 42 (32.81%)\n",
      "Mean activation frequency: 0.2385\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.093397\n",
      "    Dead neurons: 86/128 (67.19%)\n",
      "    Test loss: 0.273405\n",
      "    Mean activation strength: 0.093397\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.7890\n",
      "Epoch [2/50], Loss: 0.2852\n",
      "Epoch [3/50], Loss: 0.2141\n",
      "Epoch [4/50], Loss: 0.1914\n",
      "Epoch [5/50], Loss: 0.1819\n",
      "Epoch [6/50], Loss: 0.1775\n",
      "Epoch [7/50], Loss: 0.1745\n",
      "Epoch [8/50], Loss: 0.1719\n",
      "Epoch [9/50], Loss: 0.1707\n",
      "Epoch [10/50], Loss: 0.1701\n",
      "Epoch [11/50], Loss: 0.1697\n",
      "Epoch [12/50], Loss: 0.1694\n",
      "Epoch [13/50], Loss: 0.1692\n",
      "Epoch [14/50], Loss: 0.1685\n",
      "Epoch [15/50], Loss: 0.1679\n",
      "Epoch [16/50], Loss: 0.1675\n",
      "Epoch [17/50], Loss: 0.1673\n",
      "Epoch [18/50], Loss: 0.1670\n",
      "Epoch [19/50], Loss: 0.1669\n",
      "Epoch [20/50], Loss: 0.1667\n",
      "Epoch [21/50], Loss: 0.1666\n",
      "Epoch [22/50], Loss: 0.1665\n",
      "Epoch [23/50], Loss: 0.1664\n",
      "Epoch [24/50], Loss: 0.1663\n",
      "Epoch [25/50], Loss: 0.1662\n",
      "Epoch [26/50], Loss: 0.1661\n",
      "Epoch [27/50], Loss: 0.1653\n",
      "Epoch [28/50], Loss: 0.1650\n",
      "Epoch [29/50], Loss: 0.1644\n",
      "Epoch [30/50], Loss: 0.1641\n",
      "Epoch [31/50], Loss: 0.1639\n",
      "Epoch [32/50], Loss: 0.1638\n",
      "Epoch [33/50], Loss: 0.1638\n",
      "Epoch [34/50], Loss: 0.1636\n",
      "Epoch [35/50], Loss: 0.1629\n",
      "Epoch [36/50], Loss: 0.1628\n",
      "Epoch [37/50], Loss: 0.1628\n",
      "Epoch [38/50], Loss: 0.1628\n",
      "Epoch [39/50], Loss: 0.1627\n",
      "Epoch [40/50], Loss: 0.1626\n",
      "Epoch [41/50], Loss: 0.1626\n",
      "Epoch [42/50], Loss: 0.1626\n",
      "Epoch [43/50], Loss: 0.1625\n",
      "Epoch [44/50], Loss: 0.1622\n",
      "Epoch [45/50], Loss: 0.1621\n",
      "Epoch [46/50], Loss: 0.1622\n",
      "Epoch [47/50], Loss: 0.1621\n",
      "Epoch [48/50], Loss: 0.1617\n",
      "Epoch [49/50], Loss: 0.1615\n",
      "Epoch [50/50], Loss: 0.1614\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.158203\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 36 out of 128 (28.12%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 36 (28.12%)\n",
      "Active features: 92 (71.88%)\n",
      "Mean activation frequency: 0.3118\n",
      "Median activation frequency: 0.3701\n",
      "Mean activation strength (when active): 0.101025\n",
      "    Dead neurons: 36/128 (28.12%)\n",
      "    Test loss: 0.158203\n",
      "    Mean activation strength: 0.101025\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2576\n",
      "Epoch [2/50], Loss: 0.0936\n",
      "Epoch [3/50], Loss: 0.0697\n",
      "Epoch [4/50], Loss: 0.0626\n",
      "Epoch [5/50], Loss: 0.0598\n",
      "Epoch [6/50], Loss: 0.0582\n",
      "Epoch [7/50], Loss: 0.0571\n",
      "Epoch [8/50], Loss: 0.0565\n",
      "Epoch [9/50], Loss: 0.0560\n",
      "Epoch [10/50], Loss: 0.0555\n",
      "Epoch [11/50], Loss: 0.0554\n",
      "Epoch [12/50], Loss: 0.0552\n",
      "Epoch [13/50], Loss: 0.0551\n",
      "Epoch [14/50], Loss: 0.0549\n",
      "Epoch [15/50], Loss: 0.0547\n",
      "Epoch [16/50], Loss: 0.0546\n",
      "Epoch [17/50], Loss: 0.0546\n",
      "Epoch [18/50], Loss: 0.0546\n",
      "Epoch [19/50], Loss: 0.0545\n",
      "Epoch [20/50], Loss: 0.0545\n",
      "Epoch [21/50], Loss: 0.0545\n",
      "Epoch [22/50], Loss: 0.0544\n",
      "Epoch [23/50], Loss: 0.0544\n",
      "Epoch [24/50], Loss: 0.0544\n",
      "Epoch [25/50], Loss: 0.0544\n",
      "Epoch [26/50], Loss: 0.0544\n",
      "Epoch [27/50], Loss: 0.0544\n",
      "Epoch [28/50], Loss: 0.0543\n",
      "Epoch [29/50], Loss: 0.0543\n",
      "Epoch [30/50], Loss: 0.0543\n",
      "Epoch [31/50], Loss: 0.0543\n",
      "Epoch [32/50], Loss: 0.0543\n",
      "Epoch [33/50], Loss: 0.0543\n",
      "Epoch [34/50], Loss: 0.0543\n",
      "Epoch [35/50], Loss: 0.0542\n",
      "Epoch [36/50], Loss: 0.0542\n",
      "Epoch [37/50], Loss: 0.0542\n",
      "Epoch [38/50], Loss: 0.0542\n",
      "Epoch [39/50], Loss: 0.0542\n",
      "Epoch [40/50], Loss: 0.0542\n",
      "Epoch [41/50], Loss: 0.0541\n",
      "Epoch [42/50], Loss: 0.0541\n",
      "Epoch [43/50], Loss: 0.0540\n",
      "Epoch [44/50], Loss: 0.0540\n",
      "Epoch [45/50], Loss: 0.0540\n",
      "Epoch [46/50], Loss: 0.0540\n",
      "Epoch [47/50], Loss: 0.0540\n",
      "Epoch [48/50], Loss: 0.0540\n",
      "Epoch [49/50], Loss: 0.0540\n",
      "Epoch [50/50], Loss: 0.0540\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.051618\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 40 out of 128 (31.25%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 40 (31.25%)\n",
      "Active features: 88 (68.75%)\n",
      "Mean activation frequency: 0.3115\n",
      "Median activation frequency: 0.3789\n",
      "Mean activation strength (when active): 0.101596\n",
      "    Dead neurons: 40/128 (31.25%)\n",
      "    Test loss: 0.051618\n",
      "    Mean activation strength: 0.101596\n",
      "\n",
      "Hidden Size: 128, k_top: 50\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.1146\n",
      "Epoch [2/50], Loss: 0.5333\n",
      "Epoch [3/50], Loss: 0.4132\n",
      "Epoch [4/50], Loss: 0.3611\n",
      "Epoch [5/50], Loss: 0.3366\n",
      "Epoch [6/50], Loss: 0.3253\n",
      "Epoch [7/50], Loss: 0.3201\n",
      "Epoch [8/50], Loss: 0.3173\n",
      "Epoch [9/50], Loss: 0.3153\n",
      "Epoch [10/50], Loss: 0.3139\n",
      "Epoch [11/50], Loss: 0.3102\n",
      "Epoch [12/50], Loss: 0.3080\n",
      "Epoch [13/50], Loss: 0.3034\n",
      "Epoch [14/50], Loss: 0.2998\n",
      "Epoch [15/50], Loss: 0.2974\n",
      "Epoch [16/50], Loss: 0.2937\n",
      "Epoch [17/50], Loss: 0.2927\n",
      "Epoch [18/50], Loss: 0.2921\n",
      "Epoch [19/50], Loss: 0.2891\n",
      "Epoch [20/50], Loss: 0.2880\n",
      "Epoch [21/50], Loss: 0.2871\n",
      "Epoch [22/50], Loss: 0.2838\n",
      "Epoch [23/50], Loss: 0.2811\n",
      "Epoch [24/50], Loss: 0.2802\n",
      "Epoch [25/50], Loss: 0.2799\n",
      "Epoch [26/50], Loss: 0.2796\n",
      "Epoch [27/50], Loss: 0.2794\n",
      "Epoch [28/50], Loss: 0.2793\n",
      "Epoch [29/50], Loss: 0.2792\n",
      "Epoch [30/50], Loss: 0.2790\n",
      "Epoch [31/50], Loss: 0.2788\n",
      "Epoch [32/50], Loss: 0.2788\n",
      "Epoch [33/50], Loss: 0.2786\n",
      "Epoch [34/50], Loss: 0.2785\n",
      "Epoch [35/50], Loss: 0.2784\n",
      "Epoch [36/50], Loss: 0.2782\n",
      "Epoch [37/50], Loss: 0.2782\n",
      "Epoch [38/50], Loss: 0.2781\n",
      "Epoch [39/50], Loss: 0.2780\n",
      "Epoch [40/50], Loss: 0.2778\n",
      "Epoch [41/50], Loss: 0.2778\n",
      "Epoch [42/50], Loss: 0.2777\n",
      "Epoch [43/50], Loss: 0.2776\n",
      "Epoch [44/50], Loss: 0.2776\n",
      "Epoch [45/50], Loss: 0.2775\n",
      "Epoch [46/50], Loss: 0.2774\n",
      "Epoch [47/50], Loss: 0.2774\n",
      "Epoch [48/50], Loss: 0.2773\n",
      "Epoch [49/50], Loss: 0.2773\n",
      "Epoch [50/50], Loss: 0.2773\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.269356\n",
      "Number of dead neurons in Default Sparse Autoencoder: 85 out of 128 (66.41%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 85 (66.41%)\n",
      "Active features: 43 (33.59%)\n",
      "Mean activation frequency: 0.2424\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.091459\n",
      "    Dead neurons: 85/128 (66.41%)\n",
      "    Test loss: 0.269356\n",
      "    Mean activation strength: 0.091459\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8155\n",
      "Epoch [2/50], Loss: 0.2944\n",
      "Epoch [3/50], Loss: 0.2130\n",
      "Epoch [4/50], Loss: 0.1889\n",
      "Epoch [5/50], Loss: 0.1798\n",
      "Epoch [6/50], Loss: 0.1732\n",
      "Epoch [7/50], Loss: 0.1697\n",
      "Epoch [8/50], Loss: 0.1671\n",
      "Epoch [9/50], Loss: 0.1653\n",
      "Epoch [10/50], Loss: 0.1634\n",
      "Epoch [11/50], Loss: 0.1625\n",
      "Epoch [12/50], Loss: 0.1619\n",
      "Epoch [13/50], Loss: 0.1614\n",
      "Epoch [14/50], Loss: 0.1602\n",
      "Epoch [15/50], Loss: 0.1579\n",
      "Epoch [16/50], Loss: 0.1570\n",
      "Epoch [17/50], Loss: 0.1566\n",
      "Epoch [18/50], Loss: 0.1563\n",
      "Epoch [19/50], Loss: 0.1561\n",
      "Epoch [20/50], Loss: 0.1559\n",
      "Epoch [21/50], Loss: 0.1557\n",
      "Epoch [22/50], Loss: 0.1555\n",
      "Epoch [23/50], Loss: 0.1554\n",
      "Epoch [24/50], Loss: 0.1552\n",
      "Epoch [25/50], Loss: 0.1551\n",
      "Epoch [26/50], Loss: 0.1551\n",
      "Epoch [27/50], Loss: 0.1550\n",
      "Epoch [28/50], Loss: 0.1549\n",
      "Epoch [29/50], Loss: 0.1549\n",
      "Epoch [30/50], Loss: 0.1548\n",
      "Epoch [31/50], Loss: 0.1547\n",
      "Epoch [32/50], Loss: 0.1547\n",
      "Epoch [33/50], Loss: 0.1546\n",
      "Epoch [34/50], Loss: 0.1546\n",
      "Epoch [35/50], Loss: 0.1545\n",
      "Epoch [36/50], Loss: 0.1544\n",
      "Epoch [37/50], Loss: 0.1537\n",
      "Epoch [38/50], Loss: 0.1536\n",
      "Epoch [39/50], Loss: 0.1534\n",
      "Epoch [40/50], Loss: 0.1533\n",
      "Epoch [41/50], Loss: 0.1526\n",
      "Epoch [42/50], Loss: 0.1524\n",
      "Epoch [43/50], Loss: 0.1524\n",
      "Epoch [44/50], Loss: 0.1523\n",
      "Epoch [45/50], Loss: 0.1522\n",
      "Epoch [46/50], Loss: 0.1522\n",
      "Epoch [47/50], Loss: 0.1522\n",
      "Epoch [48/50], Loss: 0.1521\n",
      "Epoch [49/50], Loss: 0.1521\n",
      "Epoch [50/50], Loss: 0.1520\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.147479\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 34 out of 128 (26.56%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 34 (26.56%)\n",
      "Active features: 94 (73.44%)\n",
      "Mean activation frequency: 0.3853\n",
      "Median activation frequency: 0.4821\n",
      "Mean activation strength (when active): 0.093071\n",
      "    Dead neurons: 34/128 (26.56%)\n",
      "    Test loss: 0.147479\n",
      "    Mean activation strength: 0.093071\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2663\n",
      "Epoch [2/50], Loss: 0.0970\n",
      "Epoch [3/50], Loss: 0.0708\n",
      "Epoch [4/50], Loss: 0.0616\n",
      "Epoch [5/50], Loss: 0.0576\n",
      "Epoch [6/50], Loss: 0.0560\n",
      "Epoch [7/50], Loss: 0.0550\n",
      "Epoch [8/50], Loss: 0.0542\n",
      "Epoch [9/50], Loss: 0.0532\n",
      "Epoch [10/50], Loss: 0.0528\n",
      "Epoch [11/50], Loss: 0.0526\n",
      "Epoch [12/50], Loss: 0.0525\n",
      "Epoch [13/50], Loss: 0.0524\n",
      "Epoch [14/50], Loss: 0.0523\n",
      "Epoch [15/50], Loss: 0.0522\n",
      "Epoch [16/50], Loss: 0.0521\n",
      "Epoch [17/50], Loss: 0.0520\n",
      "Epoch [18/50], Loss: 0.0520\n",
      "Epoch [19/50], Loss: 0.0519\n",
      "Epoch [20/50], Loss: 0.0518\n",
      "Epoch [21/50], Loss: 0.0518\n",
      "Epoch [22/50], Loss: 0.0517\n",
      "Epoch [23/50], Loss: 0.0516\n",
      "Epoch [24/50], Loss: 0.0516\n",
      "Epoch [25/50], Loss: 0.0514\n",
      "Epoch [26/50], Loss: 0.0512\n",
      "Epoch [27/50], Loss: 0.0510\n",
      "Epoch [28/50], Loss: 0.0509\n",
      "Epoch [29/50], Loss: 0.0509\n",
      "Epoch [30/50], Loss: 0.0508\n",
      "Epoch [31/50], Loss: 0.0508\n",
      "Epoch [32/50], Loss: 0.0508\n",
      "Epoch [33/50], Loss: 0.0506\n",
      "Epoch [34/50], Loss: 0.0503\n",
      "Epoch [35/50], Loss: 0.0501\n",
      "Epoch [36/50], Loss: 0.0501\n",
      "Epoch [37/50], Loss: 0.0501\n",
      "Epoch [38/50], Loss: 0.0500\n",
      "Epoch [39/50], Loss: 0.0500\n",
      "Epoch [40/50], Loss: 0.0500\n",
      "Epoch [41/50], Loss: 0.0500\n",
      "Epoch [42/50], Loss: 0.0500\n",
      "Epoch [43/50], Loss: 0.0499\n",
      "Epoch [44/50], Loss: 0.0499\n",
      "Epoch [45/50], Loss: 0.0499\n",
      "Epoch [46/50], Loss: 0.0499\n",
      "Epoch [47/50], Loss: 0.0499\n",
      "Epoch [48/50], Loss: 0.0499\n",
      "Epoch [49/50], Loss: 0.0499\n",
      "Epoch [50/50], Loss: 0.0499\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.047599\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 34 out of 128 (26.56%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 34 (26.56%)\n",
      "Active features: 94 (73.44%)\n",
      "Mean activation frequency: 0.3836\n",
      "Median activation frequency: 0.4678\n",
      "Mean activation strength (when active): 0.092750\n",
      "    Dead neurons: 34/128 (26.56%)\n",
      "    Test loss: 0.047599\n",
      "    Mean activation strength: 0.092750\n",
      "\n",
      "Hidden Size: 128, k_top: 60\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.1385\n",
      "Epoch [2/50], Loss: 0.5441\n",
      "Epoch [3/50], Loss: 0.4249\n",
      "Epoch [4/50], Loss: 0.3762\n",
      "Epoch [5/50], Loss: 0.3481\n",
      "Epoch [6/50], Loss: 0.3385\n",
      "Epoch [7/50], Loss: 0.3350\n",
      "Epoch [8/50], Loss: 0.3313\n",
      "Epoch [9/50], Loss: 0.3223\n",
      "Epoch [10/50], Loss: 0.3160\n",
      "Epoch [11/50], Loss: 0.3128\n",
      "Epoch [12/50], Loss: 0.3106\n",
      "Epoch [13/50], Loss: 0.3075\n",
      "Epoch [14/50], Loss: 0.3038\n",
      "Epoch [15/50], Loss: 0.3009\n",
      "Epoch [16/50], Loss: 0.2988\n",
      "Epoch [17/50], Loss: 0.2960\n",
      "Epoch [18/50], Loss: 0.2910\n",
      "Epoch [19/50], Loss: 0.2892\n",
      "Epoch [20/50], Loss: 0.2883\n",
      "Epoch [21/50], Loss: 0.2854\n",
      "Epoch [22/50], Loss: 0.2799\n",
      "Epoch [23/50], Loss: 0.2777\n",
      "Epoch [24/50], Loss: 0.2770\n",
      "Epoch [25/50], Loss: 0.2765\n",
      "Epoch [26/50], Loss: 0.2761\n",
      "Epoch [27/50], Loss: 0.2758\n",
      "Epoch [28/50], Loss: 0.2754\n",
      "Epoch [29/50], Loss: 0.2752\n",
      "Epoch [30/50], Loss: 0.2749\n",
      "Epoch [31/50], Loss: 0.2746\n",
      "Epoch [32/50], Loss: 0.2745\n",
      "Epoch [33/50], Loss: 0.2743\n",
      "Epoch [34/50], Loss: 0.2741\n",
      "Epoch [35/50], Loss: 0.2740\n",
      "Epoch [36/50], Loss: 0.2738\n",
      "Epoch [37/50], Loss: 0.2737\n",
      "Epoch [38/50], Loss: 0.2737\n",
      "Epoch [39/50], Loss: 0.2737\n",
      "Epoch [40/50], Loss: 0.2736\n",
      "Epoch [41/50], Loss: 0.2736\n",
      "Epoch [42/50], Loss: 0.2735\n",
      "Epoch [43/50], Loss: 0.2734\n",
      "Epoch [44/50], Loss: 0.2734\n",
      "Epoch [45/50], Loss: 0.2733\n",
      "Epoch [46/50], Loss: 0.2732\n",
      "Epoch [47/50], Loss: 0.2732\n",
      "Epoch [48/50], Loss: 0.2731\n",
      "Epoch [49/50], Loss: 0.2730\n",
      "Epoch [50/50], Loss: 0.2730\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.264890\n",
      "Number of dead neurons in Default Sparse Autoencoder: 84 out of 128 (65.62%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 84 (65.62%)\n",
      "Active features: 44 (34.38%)\n",
      "Mean activation frequency: 0.2473\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.090405\n",
      "    Dead neurons: 84/128 (65.62%)\n",
      "    Test loss: 0.264890\n",
      "    Mean activation strength: 0.090405\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8325\n",
      "Epoch [2/50], Loss: 0.2896\n",
      "Epoch [3/50], Loss: 0.2052\n",
      "Epoch [4/50], Loss: 0.1807\n",
      "Epoch [5/50], Loss: 0.1697\n",
      "Epoch [6/50], Loss: 0.1621\n",
      "Epoch [7/50], Loss: 0.1581\n",
      "Epoch [8/50], Loss: 0.1549\n",
      "Epoch [9/50], Loss: 0.1531\n",
      "Epoch [10/50], Loss: 0.1517\n",
      "Epoch [11/50], Loss: 0.1508\n",
      "Epoch [12/50], Loss: 0.1501\n",
      "Epoch [13/50], Loss: 0.1496\n",
      "Epoch [14/50], Loss: 0.1491\n",
      "Epoch [15/50], Loss: 0.1487\n",
      "Epoch [16/50], Loss: 0.1483\n",
      "Epoch [17/50], Loss: 0.1473\n",
      "Epoch [18/50], Loss: 0.1463\n",
      "Epoch [19/50], Loss: 0.1459\n",
      "Epoch [20/50], Loss: 0.1455\n",
      "Epoch [21/50], Loss: 0.1452\n",
      "Epoch [22/50], Loss: 0.1450\n",
      "Epoch [23/50], Loss: 0.1448\n",
      "Epoch [24/50], Loss: 0.1446\n",
      "Epoch [25/50], Loss: 0.1438\n",
      "Epoch [26/50], Loss: 0.1434\n",
      "Epoch [27/50], Loss: 0.1432\n",
      "Epoch [28/50], Loss: 0.1430\n",
      "Epoch [29/50], Loss: 0.1428\n",
      "Epoch [30/50], Loss: 0.1427\n",
      "Epoch [31/50], Loss: 0.1425\n",
      "Epoch [32/50], Loss: 0.1424\n",
      "Epoch [33/50], Loss: 0.1423\n",
      "Epoch [34/50], Loss: 0.1422\n",
      "Epoch [35/50], Loss: 0.1421\n",
      "Epoch [36/50], Loss: 0.1420\n",
      "Epoch [37/50], Loss: 0.1420\n",
      "Epoch [38/50], Loss: 0.1419\n",
      "Epoch [39/50], Loss: 0.1418\n",
      "Epoch [40/50], Loss: 0.1418\n",
      "Epoch [41/50], Loss: 0.1417\n",
      "Epoch [42/50], Loss: 0.1417\n",
      "Epoch [43/50], Loss: 0.1416\n",
      "Epoch [44/50], Loss: 0.1416\n",
      "Epoch [45/50], Loss: 0.1415\n",
      "Epoch [46/50], Loss: 0.1415\n",
      "Epoch [47/50], Loss: 0.1415\n",
      "Epoch [48/50], Loss: 0.1414\n",
      "Epoch [49/50], Loss: 0.1414\n",
      "Epoch [50/50], Loss: 0.1413\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.137035\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 28 out of 128 (21.88%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 28 (21.88%)\n",
      "Active features: 100 (78.12%)\n",
      "Mean activation frequency: 0.4427\n",
      "Median activation frequency: 0.5095\n",
      "Mean activation strength (when active): 0.088563\n",
      "    Dead neurons: 28/128 (21.88%)\n",
      "    Test loss: 0.137035\n",
      "    Mean activation strength: 0.088563\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2715\n",
      "Epoch [2/50], Loss: 0.0946\n",
      "Epoch [3/50], Loss: 0.0670\n",
      "Epoch [4/50], Loss: 0.0588\n",
      "Epoch [5/50], Loss: 0.0551\n",
      "Epoch [6/50], Loss: 0.0528\n",
      "Epoch [7/50], Loss: 0.0512\n",
      "Epoch [8/50], Loss: 0.0503\n",
      "Epoch [9/50], Loss: 0.0496\n",
      "Epoch [10/50], Loss: 0.0491\n",
      "Epoch [11/50], Loss: 0.0489\n",
      "Epoch [12/50], Loss: 0.0487\n",
      "Epoch [13/50], Loss: 0.0485\n",
      "Epoch [14/50], Loss: 0.0484\n",
      "Epoch [15/50], Loss: 0.0483\n",
      "Epoch [16/50], Loss: 0.0482\n",
      "Epoch [17/50], Loss: 0.0481\n",
      "Epoch [18/50], Loss: 0.0481\n",
      "Epoch [19/50], Loss: 0.0480\n",
      "Epoch [20/50], Loss: 0.0480\n",
      "Epoch [21/50], Loss: 0.0479\n",
      "Epoch [22/50], Loss: 0.0479\n",
      "Epoch [23/50], Loss: 0.0479\n",
      "Epoch [24/50], Loss: 0.0478\n",
      "Epoch [25/50], Loss: 0.0478\n",
      "Epoch [26/50], Loss: 0.0478\n",
      "Epoch [27/50], Loss: 0.0477\n",
      "Epoch [28/50], Loss: 0.0477\n",
      "Epoch [29/50], Loss: 0.0477\n",
      "Epoch [30/50], Loss: 0.0477\n",
      "Epoch [31/50], Loss: 0.0477\n",
      "Epoch [32/50], Loss: 0.0476\n",
      "Epoch [33/50], Loss: 0.0476\n",
      "Epoch [34/50], Loss: 0.0476\n",
      "Epoch [35/50], Loss: 0.0476\n",
      "Epoch [36/50], Loss: 0.0476\n",
      "Epoch [37/50], Loss: 0.0476\n",
      "Epoch [38/50], Loss: 0.0476\n",
      "Epoch [39/50], Loss: 0.0475\n",
      "Epoch [40/50], Loss: 0.0475\n",
      "Epoch [41/50], Loss: 0.0475\n",
      "Epoch [42/50], Loss: 0.0473\n",
      "Epoch [43/50], Loss: 0.0472\n",
      "Epoch [44/50], Loss: 0.0471\n",
      "Epoch [45/50], Loss: 0.0471\n",
      "Epoch [46/50], Loss: 0.0471\n",
      "Epoch [47/50], Loss: 0.0471\n",
      "Epoch [48/50], Loss: 0.0471\n",
      "Epoch [49/50], Loss: 0.0471\n",
      "Epoch [50/50], Loss: 0.0471\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.044900\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 31 out of 128 (24.22%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 31 (24.22%)\n",
      "Active features: 97 (75.78%)\n",
      "Mean activation frequency: 0.4458\n",
      "Median activation frequency: 0.5219\n",
      "Mean activation strength (when active): 0.089189\n",
      "    Dead neurons: 31/128 (24.22%)\n",
      "    Test loss: 0.044900\n",
      "    Mean activation strength: 0.089189\n",
      "\n",
      "Hidden Size: 128, k_top: 70\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.1592\n",
      "Epoch [2/50], Loss: 0.5555\n",
      "Epoch [3/50], Loss: 0.4278\n",
      "Epoch [4/50], Loss: 0.3783\n",
      "Epoch [5/50], Loss: 0.3554\n",
      "Epoch [6/50], Loss: 0.3411\n",
      "Epoch [7/50], Loss: 0.3325\n",
      "Epoch [8/50], Loss: 0.3276\n",
      "Epoch [9/50], Loss: 0.3233\n",
      "Epoch [10/50], Loss: 0.3206\n",
      "Epoch [11/50], Loss: 0.3156\n",
      "Epoch [12/50], Loss: 0.3114\n",
      "Epoch [13/50], Loss: 0.3052\n",
      "Epoch [14/50], Loss: 0.2998\n",
      "Epoch [15/50], Loss: 0.2973\n",
      "Epoch [16/50], Loss: 0.2939\n",
      "Epoch [17/50], Loss: 0.2864\n",
      "Epoch [18/50], Loss: 0.2808\n",
      "Epoch [19/50], Loss: 0.2783\n",
      "Epoch [20/50], Loss: 0.2751\n",
      "Epoch [21/50], Loss: 0.2729\n",
      "Epoch [22/50], Loss: 0.2703\n",
      "Epoch [23/50], Loss: 0.2677\n",
      "Epoch [24/50], Loss: 0.2669\n",
      "Epoch [25/50], Loss: 0.2665\n",
      "Epoch [26/50], Loss: 0.2661\n",
      "Epoch [27/50], Loss: 0.2658\n",
      "Epoch [28/50], Loss: 0.2656\n",
      "Epoch [29/50], Loss: 0.2655\n",
      "Epoch [30/50], Loss: 0.2654\n",
      "Epoch [31/50], Loss: 0.2652\n",
      "Epoch [32/50], Loss: 0.2652\n",
      "Epoch [33/50], Loss: 0.2652\n",
      "Epoch [34/50], Loss: 0.2651\n",
      "Epoch [35/50], Loss: 0.2651\n",
      "Epoch [36/50], Loss: 0.2650\n",
      "Epoch [37/50], Loss: 0.2649\n",
      "Epoch [38/50], Loss: 0.2649\n",
      "Epoch [39/50], Loss: 0.2649\n",
      "Epoch [40/50], Loss: 0.2649\n",
      "Epoch [41/50], Loss: 0.2649\n",
      "Epoch [42/50], Loss: 0.2648\n",
      "Epoch [43/50], Loss: 0.2647\n",
      "Epoch [44/50], Loss: 0.2647\n",
      "Epoch [45/50], Loss: 0.2646\n",
      "Epoch [46/50], Loss: 0.2646\n",
      "Epoch [47/50], Loss: 0.2645\n",
      "Epoch [48/50], Loss: 0.2644\n",
      "Epoch [49/50], Loss: 0.2642\n",
      "Epoch [50/50], Loss: 0.2641\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.256739\n",
      "Number of dead neurons in Default Sparse Autoencoder: 82 out of 128 (64.06%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 82 (64.06%)\n",
      "Active features: 46 (35.94%)\n",
      "Mean activation frequency: 0.2537\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.088835\n",
      "    Dead neurons: 82/128 (64.06%)\n",
      "    Test loss: 0.256739\n",
      "    Mean activation strength: 0.088835\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8607\n",
      "Epoch [2/50], Loss: 0.3043\n",
      "Epoch [3/50], Loss: 0.2156\n",
      "Epoch [4/50], Loss: 0.1916\n",
      "Epoch [5/50], Loss: 0.1825\n",
      "Epoch [6/50], Loss: 0.1779\n",
      "Epoch [7/50], Loss: 0.1748\n",
      "Epoch [8/50], Loss: 0.1727\n",
      "Epoch [9/50], Loss: 0.1714\n",
      "Epoch [10/50], Loss: 0.1698\n",
      "Epoch [11/50], Loss: 0.1682\n",
      "Epoch [12/50], Loss: 0.1677\n",
      "Epoch [13/50], Loss: 0.1673\n",
      "Epoch [14/50], Loss: 0.1670\n",
      "Epoch [15/50], Loss: 0.1668\n",
      "Epoch [16/50], Loss: 0.1665\n",
      "Epoch [17/50], Loss: 0.1664\n",
      "Epoch [18/50], Loss: 0.1663\n",
      "Epoch [19/50], Loss: 0.1662\n",
      "Epoch [20/50], Loss: 0.1661\n",
      "Epoch [21/50], Loss: 0.1660\n",
      "Epoch [22/50], Loss: 0.1659\n",
      "Epoch [23/50], Loss: 0.1659\n",
      "Epoch [24/50], Loss: 0.1658\n",
      "Epoch [25/50], Loss: 0.1658\n",
      "Epoch [26/50], Loss: 0.1657\n",
      "Epoch [27/50], Loss: 0.1657\n",
      "Epoch [28/50], Loss: 0.1656\n",
      "Epoch [29/50], Loss: 0.1655\n",
      "Epoch [30/50], Loss: 0.1655\n",
      "Epoch [31/50], Loss: 0.1654\n",
      "Epoch [32/50], Loss: 0.1654\n",
      "Epoch [33/50], Loss: 0.1653\n",
      "Epoch [34/50], Loss: 0.1653\n",
      "Epoch [35/50], Loss: 0.1653\n",
      "Epoch [36/50], Loss: 0.1652\n",
      "Epoch [37/50], Loss: 0.1652\n",
      "Epoch [38/50], Loss: 0.1651\n",
      "Epoch [39/50], Loss: 0.1650\n",
      "Epoch [40/50], Loss: 0.1649\n",
      "Epoch [41/50], Loss: 0.1649\n",
      "Epoch [42/50], Loss: 0.1648\n",
      "Epoch [43/50], Loss: 0.1648\n",
      "Epoch [44/50], Loss: 0.1648\n",
      "Epoch [45/50], Loss: 0.1647\n",
      "Epoch [46/50], Loss: 0.1648\n",
      "Epoch [47/50], Loss: 0.1648\n",
      "Epoch [48/50], Loss: 0.1647\n",
      "Epoch [49/50], Loss: 0.1647\n",
      "Epoch [50/50], Loss: 0.1647\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.159149\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 44 out of 128 (34.38%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 44 (34.38%)\n",
      "Active features: 84 (65.62%)\n",
      "Mean activation frequency: 0.3813\n",
      "Median activation frequency: 0.3748\n",
      "Mean activation strength (when active): 0.095269\n",
      "    Dead neurons: 44/128 (34.38%)\n",
      "    Test loss: 0.159149\n",
      "    Mean activation strength: 0.095269\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2808\n",
      "Epoch [2/50], Loss: 0.0994\n",
      "Epoch [3/50], Loss: 0.0705\n",
      "Epoch [4/50], Loss: 0.0625\n",
      "Epoch [5/50], Loss: 0.0593\n",
      "Epoch [6/50], Loss: 0.0578\n",
      "Epoch [7/50], Loss: 0.0567\n",
      "Epoch [8/50], Loss: 0.0560\n",
      "Epoch [9/50], Loss: 0.0555\n",
      "Epoch [10/50], Loss: 0.0547\n",
      "Epoch [11/50], Loss: 0.0544\n",
      "Epoch [12/50], Loss: 0.0543\n",
      "Epoch [13/50], Loss: 0.0542\n",
      "Epoch [14/50], Loss: 0.0541\n",
      "Epoch [15/50], Loss: 0.0540\n",
      "Epoch [16/50], Loss: 0.0540\n",
      "Epoch [17/50], Loss: 0.0539\n",
      "Epoch [18/50], Loss: 0.0539\n",
      "Epoch [19/50], Loss: 0.0539\n",
      "Epoch [20/50], Loss: 0.0539\n",
      "Epoch [21/50], Loss: 0.0538\n",
      "Epoch [22/50], Loss: 0.0538\n",
      "Epoch [23/50], Loss: 0.0538\n",
      "Epoch [24/50], Loss: 0.0538\n",
      "Epoch [25/50], Loss: 0.0538\n",
      "Epoch [26/50], Loss: 0.0538\n",
      "Epoch [27/50], Loss: 0.0537\n",
      "Epoch [28/50], Loss: 0.0537\n",
      "Epoch [29/50], Loss: 0.0537\n",
      "Epoch [30/50], Loss: 0.0537\n",
      "Epoch [31/50], Loss: 0.0537\n",
      "Epoch [32/50], Loss: 0.0537\n",
      "Epoch [33/50], Loss: 0.0536\n",
      "Epoch [34/50], Loss: 0.0533\n",
      "Epoch [35/50], Loss: 0.0533\n",
      "Epoch [36/50], Loss: 0.0532\n",
      "Epoch [37/50], Loss: 0.0532\n",
      "Epoch [38/50], Loss: 0.0532\n",
      "Epoch [39/50], Loss: 0.0532\n",
      "Epoch [40/50], Loss: 0.0531\n",
      "Epoch [41/50], Loss: 0.0528\n",
      "Epoch [42/50], Loss: 0.0526\n",
      "Epoch [43/50], Loss: 0.0526\n",
      "Epoch [44/50], Loss: 0.0525\n",
      "Epoch [45/50], Loss: 0.0525\n",
      "Epoch [46/50], Loss: 0.0525\n",
      "Epoch [47/50], Loss: 0.0525\n",
      "Epoch [48/50], Loss: 0.0525\n",
      "Epoch [49/50], Loss: 0.0525\n",
      "Epoch [50/50], Loss: 0.0524\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.049832\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 42 out of 128 (32.81%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 42 (32.81%)\n",
      "Active features: 86 (67.19%)\n",
      "Mean activation frequency: 0.3966\n",
      "Median activation frequency: 0.4128\n",
      "Mean activation strength (when active): 0.093792\n",
      "    Dead neurons: 42/128 (32.81%)\n",
      "    Test loss: 0.049832\n",
      "    Mean activation strength: 0.093792\n",
      "\n",
      "Hidden Size: 128, k_top: 80\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.1770\n",
      "Epoch [2/50], Loss: 0.5651\n",
      "Epoch [3/50], Loss: 0.4325\n",
      "Epoch [4/50], Loss: 0.3808\n",
      "Epoch [5/50], Loss: 0.3558\n",
      "Epoch [6/50], Loss: 0.3403\n",
      "Epoch [7/50], Loss: 0.3325\n",
      "Epoch [8/50], Loss: 0.3264\n",
      "Epoch [9/50], Loss: 0.3192\n",
      "Epoch [10/50], Loss: 0.3120\n",
      "Epoch [11/50], Loss: 0.3092\n",
      "Epoch [12/50], Loss: 0.3070\n",
      "Epoch [13/50], Loss: 0.3028\n",
      "Epoch [14/50], Loss: 0.2986\n",
      "Epoch [15/50], Loss: 0.2966\n",
      "Epoch [16/50], Loss: 0.2935\n",
      "Epoch [17/50], Loss: 0.2921\n",
      "Epoch [18/50], Loss: 0.2911\n",
      "Epoch [19/50], Loss: 0.2887\n",
      "Epoch [20/50], Loss: 0.2833\n",
      "Epoch [21/50], Loss: 0.2799\n",
      "Epoch [22/50], Loss: 0.2782\n",
      "Epoch [23/50], Loss: 0.2769\n",
      "Epoch [24/50], Loss: 0.2760\n",
      "Epoch [25/50], Loss: 0.2753\n",
      "Epoch [26/50], Loss: 0.2748\n",
      "Epoch [27/50], Loss: 0.2744\n",
      "Epoch [28/50], Loss: 0.2742\n",
      "Epoch [29/50], Loss: 0.2740\n",
      "Epoch [30/50], Loss: 0.2737\n",
      "Epoch [31/50], Loss: 0.2735\n",
      "Epoch [32/50], Loss: 0.2734\n",
      "Epoch [33/50], Loss: 0.2733\n",
      "Epoch [34/50], Loss: 0.2732\n",
      "Epoch [35/50], Loss: 0.2732\n",
      "Epoch [36/50], Loss: 0.2730\n",
      "Epoch [37/50], Loss: 0.2730\n",
      "Epoch [38/50], Loss: 0.2730\n",
      "Epoch [39/50], Loss: 0.2730\n",
      "Epoch [40/50], Loss: 0.2729\n",
      "Epoch [41/50], Loss: 0.2729\n",
      "Epoch [42/50], Loss: 0.2729\n",
      "Epoch [43/50], Loss: 0.2728\n",
      "Epoch [44/50], Loss: 0.2728\n",
      "Epoch [45/50], Loss: 0.2727\n",
      "Epoch [46/50], Loss: 0.2727\n",
      "Epoch [47/50], Loss: 0.2727\n",
      "Epoch [48/50], Loss: 0.2727\n",
      "Epoch [49/50], Loss: 0.2726\n",
      "Epoch [50/50], Loss: 0.2726\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.264653\n",
      "Number of dead neurons in Default Sparse Autoencoder: 84 out of 128 (65.62%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 84 (65.62%)\n",
      "Active features: 44 (34.38%)\n",
      "Mean activation frequency: 0.2474\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.089598\n",
      "    Dead neurons: 84/128 (65.62%)\n",
      "    Test loss: 0.264653\n",
      "    Mean activation strength: 0.089598\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8799\n",
      "Epoch [2/50], Loss: 0.3209\n",
      "Epoch [3/50], Loss: 0.2331\n",
      "Epoch [4/50], Loss: 0.2096\n",
      "Epoch [5/50], Loss: 0.1997\n",
      "Epoch [6/50], Loss: 0.1945\n",
      "Epoch [7/50], Loss: 0.1912\n",
      "Epoch [8/50], Loss: 0.1892\n",
      "Epoch [9/50], Loss: 0.1881\n",
      "Epoch [10/50], Loss: 0.1873\n",
      "Epoch [11/50], Loss: 0.1866\n",
      "Epoch [12/50], Loss: 0.1861\n",
      "Epoch [13/50], Loss: 0.1857\n",
      "Epoch [14/50], Loss: 0.1844\n",
      "Epoch [15/50], Loss: 0.1835\n",
      "Epoch [16/50], Loss: 0.1829\n",
      "Epoch [17/50], Loss: 0.1825\n",
      "Epoch [18/50], Loss: 0.1821\n",
      "Epoch [19/50], Loss: 0.1818\n",
      "Epoch [20/50], Loss: 0.1814\n",
      "Epoch [21/50], Loss: 0.1811\n",
      "Epoch [22/50], Loss: 0.1809\n",
      "Epoch [23/50], Loss: 0.1799\n",
      "Epoch [24/50], Loss: 0.1791\n",
      "Epoch [25/50], Loss: 0.1788\n",
      "Epoch [26/50], Loss: 0.1786\n",
      "Epoch [27/50], Loss: 0.1786\n",
      "Epoch [28/50], Loss: 0.1784\n",
      "Epoch [29/50], Loss: 0.1783\n",
      "Epoch [30/50], Loss: 0.1782\n",
      "Epoch [31/50], Loss: 0.1781\n",
      "Epoch [32/50], Loss: 0.1781\n",
      "Epoch [33/50], Loss: 0.1780\n",
      "Epoch [34/50], Loss: 0.1780\n",
      "Epoch [35/50], Loss: 0.1778\n",
      "Epoch [36/50], Loss: 0.1778\n",
      "Epoch [37/50], Loss: 0.1778\n",
      "Epoch [38/50], Loss: 0.1777\n",
      "Epoch [39/50], Loss: 0.1776\n",
      "Epoch [40/50], Loss: 0.1776\n",
      "Epoch [41/50], Loss: 0.1775\n",
      "Epoch [42/50], Loss: 0.1775\n",
      "Epoch [43/50], Loss: 0.1775\n",
      "Epoch [44/50], Loss: 0.1774\n",
      "Epoch [45/50], Loss: 0.1774\n",
      "Epoch [46/50], Loss: 0.1774\n",
      "Epoch [47/50], Loss: 0.1774\n",
      "Epoch [48/50], Loss: 0.1773\n",
      "Epoch [49/50], Loss: 0.1773\n",
      "Epoch [50/50], Loss: 0.1773\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.171702\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 52 out of 128 (40.62%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 52 (40.62%)\n",
      "Active features: 76 (59.38%)\n",
      "Mean activation frequency: 0.3577\n",
      "Median activation frequency: 0.3122\n",
      "Mean activation strength (when active): 0.098143\n",
      "    Dead neurons: 52/128 (40.62%)\n",
      "    Test loss: 0.171702\n",
      "    Mean activation strength: 0.098143\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2869\n",
      "Epoch [2/50], Loss: 0.1046\n",
      "Epoch [3/50], Loss: 0.0759\n",
      "Epoch [4/50], Loss: 0.0683\n",
      "Epoch [5/50], Loss: 0.0650\n",
      "Epoch [6/50], Loss: 0.0633\n",
      "Epoch [7/50], Loss: 0.0623\n",
      "Epoch [8/50], Loss: 0.0616\n",
      "Epoch [9/50], Loss: 0.0612\n",
      "Epoch [10/50], Loss: 0.0610\n",
      "Epoch [11/50], Loss: 0.0608\n",
      "Epoch [12/50], Loss: 0.0606\n",
      "Epoch [13/50], Loss: 0.0604\n",
      "Epoch [14/50], Loss: 0.0601\n",
      "Epoch [15/50], Loss: 0.0597\n",
      "Epoch [16/50], Loss: 0.0596\n",
      "Epoch [17/50], Loss: 0.0594\n",
      "Epoch [18/50], Loss: 0.0593\n",
      "Epoch [19/50], Loss: 0.0592\n",
      "Epoch [20/50], Loss: 0.0591\n",
      "Epoch [21/50], Loss: 0.0590\n",
      "Epoch [22/50], Loss: 0.0589\n",
      "Epoch [23/50], Loss: 0.0587\n",
      "Epoch [24/50], Loss: 0.0584\n",
      "Epoch [25/50], Loss: 0.0583\n",
      "Epoch [26/50], Loss: 0.0582\n",
      "Epoch [27/50], Loss: 0.0581\n",
      "Epoch [28/50], Loss: 0.0581\n",
      "Epoch [29/50], Loss: 0.0581\n",
      "Epoch [30/50], Loss: 0.0580\n",
      "Epoch [31/50], Loss: 0.0580\n",
      "Epoch [32/50], Loss: 0.0580\n",
      "Epoch [33/50], Loss: 0.0580\n",
      "Epoch [34/50], Loss: 0.0579\n",
      "Epoch [35/50], Loss: 0.0579\n",
      "Epoch [36/50], Loss: 0.0579\n",
      "Epoch [37/50], Loss: 0.0579\n",
      "Epoch [38/50], Loss: 0.0579\n",
      "Epoch [39/50], Loss: 0.0579\n",
      "Epoch [40/50], Loss: 0.0578\n",
      "Epoch [41/50], Loss: 0.0578\n",
      "Epoch [42/50], Loss: 0.0578\n",
      "Epoch [43/50], Loss: 0.0578\n",
      "Epoch [44/50], Loss: 0.0578\n",
      "Epoch [45/50], Loss: 0.0578\n",
      "Epoch [46/50], Loss: 0.0578\n",
      "Epoch [47/50], Loss: 0.0578\n",
      "Epoch [48/50], Loss: 0.0578\n",
      "Epoch [49/50], Loss: 0.0578\n",
      "Epoch [50/50], Loss: 0.0577\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.054980\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 52 out of 128 (40.62%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 52 (40.62%)\n",
      "Active features: 76 (59.38%)\n",
      "Mean activation frequency: 0.3578\n",
      "Median activation frequency: 0.3116\n",
      "Mean activation strength (when active): 0.098150\n",
      "    Dead neurons: 52/128 (40.62%)\n",
      "    Test loss: 0.054980\n",
      "    Mean activation strength: 0.098150\n",
      "\n",
      "Hidden Size: 128, k_top: 90\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.1919\n",
      "Epoch [2/50], Loss: 0.5721\n",
      "Epoch [3/50], Loss: 0.4362\n",
      "Epoch [4/50], Loss: 0.3812\n",
      "Epoch [5/50], Loss: 0.3575\n",
      "Epoch [6/50], Loss: 0.3419\n",
      "Epoch [7/50], Loss: 0.3308\n",
      "Epoch [8/50], Loss: 0.3211\n",
      "Epoch [9/50], Loss: 0.3129\n",
      "Epoch [10/50], Loss: 0.3061\n",
      "Epoch [11/50], Loss: 0.2998\n",
      "Epoch [12/50], Loss: 0.2965\n",
      "Epoch [13/50], Loss: 0.2945\n",
      "Epoch [14/50], Loss: 0.2931\n",
      "Epoch [15/50], Loss: 0.2923\n",
      "Epoch [16/50], Loss: 0.2916\n",
      "Epoch [17/50], Loss: 0.2911\n",
      "Epoch [18/50], Loss: 0.2907\n",
      "Epoch [19/50], Loss: 0.2893\n",
      "Epoch [20/50], Loss: 0.2879\n",
      "Epoch [21/50], Loss: 0.2873\n",
      "Epoch [22/50], Loss: 0.2855\n",
      "Epoch [23/50], Loss: 0.2821\n",
      "Epoch [24/50], Loss: 0.2806\n",
      "Epoch [25/50], Loss: 0.2768\n",
      "Epoch [26/50], Loss: 0.2733\n",
      "Epoch [27/50], Loss: 0.2721\n",
      "Epoch [28/50], Loss: 0.2714\n",
      "Epoch [29/50], Loss: 0.2709\n",
      "Epoch [30/50], Loss: 0.2704\n",
      "Epoch [31/50], Loss: 0.2700\n",
      "Epoch [32/50], Loss: 0.2698\n",
      "Epoch [33/50], Loss: 0.2696\n",
      "Epoch [34/50], Loss: 0.2694\n",
      "Epoch [35/50], Loss: 0.2693\n",
      "Epoch [36/50], Loss: 0.2691\n",
      "Epoch [37/50], Loss: 0.2689\n",
      "Epoch [38/50], Loss: 0.2689\n",
      "Epoch [39/50], Loss: 0.2688\n",
      "Epoch [40/50], Loss: 0.2687\n",
      "Epoch [41/50], Loss: 0.2686\n",
      "Epoch [42/50], Loss: 0.2686\n",
      "Epoch [43/50], Loss: 0.2685\n",
      "Epoch [44/50], Loss: 0.2685\n",
      "Epoch [45/50], Loss: 0.2684\n",
      "Epoch [46/50], Loss: 0.2684\n",
      "Epoch [47/50], Loss: 0.2684\n",
      "Epoch [48/50], Loss: 0.2683\n",
      "Epoch [49/50], Loss: 0.2683\n",
      "Epoch [50/50], Loss: 0.2683\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.260292\n",
      "Number of dead neurons in Default Sparse Autoencoder: 83 out of 128 (64.84%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 83 (64.84%)\n",
      "Active features: 45 (35.16%)\n",
      "Mean activation frequency: 0.2523\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.088653\n",
      "    Dead neurons: 83/128 (64.84%)\n",
      "    Test loss: 0.260292\n",
      "    Mean activation strength: 0.088653\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8923\n",
      "Epoch [2/50], Loss: 0.3353\n",
      "Epoch [3/50], Loss: 0.2463\n",
      "Epoch [4/50], Loss: 0.2191\n",
      "Epoch [5/50], Loss: 0.2079\n",
      "Epoch [6/50], Loss: 0.2027\n",
      "Epoch [7/50], Loss: 0.1989\n",
      "Epoch [8/50], Loss: 0.1961\n",
      "Epoch [9/50], Loss: 0.1945\n",
      "Epoch [10/50], Loss: 0.1935\n",
      "Epoch [11/50], Loss: 0.1928\n",
      "Epoch [12/50], Loss: 0.1923\n",
      "Epoch [13/50], Loss: 0.1919\n",
      "Epoch [14/50], Loss: 0.1916\n",
      "Epoch [15/50], Loss: 0.1912\n",
      "Epoch [16/50], Loss: 0.1910\n",
      "Epoch [17/50], Loss: 0.1908\n",
      "Epoch [18/50], Loss: 0.1906\n",
      "Epoch [19/50], Loss: 0.1904\n",
      "Epoch [20/50], Loss: 0.1903\n",
      "Epoch [21/50], Loss: 0.1901\n",
      "Epoch [22/50], Loss: 0.1900\n",
      "Epoch [23/50], Loss: 0.1899\n",
      "Epoch [24/50], Loss: 0.1898\n",
      "Epoch [25/50], Loss: 0.1897\n",
      "Epoch [26/50], Loss: 0.1896\n",
      "Epoch [27/50], Loss: 0.1895\n",
      "Epoch [28/50], Loss: 0.1894\n",
      "Epoch [29/50], Loss: 0.1893\n",
      "Epoch [30/50], Loss: 0.1893\n",
      "Epoch [31/50], Loss: 0.1891\n",
      "Epoch [32/50], Loss: 0.1891\n",
      "Epoch [33/50], Loss: 0.1889\n",
      "Epoch [34/50], Loss: 0.1889\n",
      "Epoch [35/50], Loss: 0.1888\n",
      "Epoch [36/50], Loss: 0.1888\n",
      "Epoch [37/50], Loss: 0.1888\n",
      "Epoch [38/50], Loss: 0.1887\n",
      "Epoch [39/50], Loss: 0.1887\n",
      "Epoch [40/50], Loss: 0.1887\n",
      "Epoch [41/50], Loss: 0.1886\n",
      "Epoch [42/50], Loss: 0.1886\n",
      "Epoch [43/50], Loss: 0.1886\n",
      "Epoch [44/50], Loss: 0.1886\n",
      "Epoch [45/50], Loss: 0.1885\n",
      "Epoch [46/50], Loss: 0.1885\n",
      "Epoch [47/50], Loss: 0.1886\n",
      "Epoch [48/50], Loss: 0.1886\n",
      "Epoch [49/50], Loss: 0.1886\n",
      "Epoch [50/50], Loss: 0.1885\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.181819\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 57 out of 128 (44.53%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 57 (44.53%)\n",
      "Active features: 71 (55.47%)\n",
      "Mean activation frequency: 0.3388\n",
      "Median activation frequency: 0.2864\n",
      "Mean activation strength (when active): 0.100144\n",
      "    Dead neurons: 57/128 (44.53%)\n",
      "    Test loss: 0.181819\n",
      "    Mean activation strength: 0.100144\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2910\n",
      "Epoch [2/50], Loss: 0.1093\n",
      "Epoch [3/50], Loss: 0.0803\n",
      "Epoch [4/50], Loss: 0.0713\n",
      "Epoch [5/50], Loss: 0.0678\n",
      "Epoch [6/50], Loss: 0.0662\n",
      "Epoch [7/50], Loss: 0.0651\n",
      "Epoch [8/50], Loss: 0.0644\n",
      "Epoch [9/50], Loss: 0.0638\n",
      "Epoch [10/50], Loss: 0.0635\n",
      "Epoch [11/50], Loss: 0.0632\n",
      "Epoch [12/50], Loss: 0.0630\n",
      "Epoch [13/50], Loss: 0.0628\n",
      "Epoch [14/50], Loss: 0.0627\n",
      "Epoch [15/50], Loss: 0.0626\n",
      "Epoch [16/50], Loss: 0.0624\n",
      "Epoch [17/50], Loss: 0.0623\n",
      "Epoch [18/50], Loss: 0.0622\n",
      "Epoch [19/50], Loss: 0.0622\n",
      "Epoch [20/50], Loss: 0.0621\n",
      "Epoch [21/50], Loss: 0.0620\n",
      "Epoch [22/50], Loss: 0.0620\n",
      "Epoch [23/50], Loss: 0.0619\n",
      "Epoch [24/50], Loss: 0.0619\n",
      "Epoch [25/50], Loss: 0.0618\n",
      "Epoch [26/50], Loss: 0.0617\n",
      "Epoch [27/50], Loss: 0.0617\n",
      "Epoch [28/50], Loss: 0.0616\n",
      "Epoch [29/50], Loss: 0.0616\n",
      "Epoch [30/50], Loss: 0.0615\n",
      "Epoch [31/50], Loss: 0.0614\n",
      "Epoch [32/50], Loss: 0.0614\n",
      "Epoch [33/50], Loss: 0.0613\n",
      "Epoch [34/50], Loss: 0.0613\n",
      "Epoch [35/50], Loss: 0.0613\n",
      "Epoch [36/50], Loss: 0.0613\n",
      "Epoch [37/50], Loss: 0.0612\n",
      "Epoch [38/50], Loss: 0.0612\n",
      "Epoch [39/50], Loss: 0.0612\n",
      "Epoch [40/50], Loss: 0.0612\n",
      "Epoch [41/50], Loss: 0.0612\n",
      "Epoch [42/50], Loss: 0.0612\n",
      "Epoch [43/50], Loss: 0.0612\n",
      "Epoch [44/50], Loss: 0.0611\n",
      "Epoch [45/50], Loss: 0.0611\n",
      "Epoch [46/50], Loss: 0.0611\n",
      "Epoch [47/50], Loss: 0.0611\n",
      "Epoch [48/50], Loss: 0.0611\n",
      "Epoch [49/50], Loss: 0.0611\n",
      "Epoch [50/50], Loss: 0.0611\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.058045\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 57 out of 128 (44.53%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 57 (44.53%)\n",
      "Active features: 71 (55.47%)\n",
      "Mean activation frequency: 0.3404\n",
      "Median activation frequency: 0.2861\n",
      "Mean activation strength (when active): 0.100221\n",
      "    Dead neurons: 57/128 (44.53%)\n",
      "    Test loss: 0.058045\n",
      "    Mean activation strength: 0.100221\n",
      "\n",
      "Hidden Size: 128, k_top: 100\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.2042\n",
      "Epoch [2/50], Loss: 0.5782\n",
      "Epoch [3/50], Loss: 0.4404\n",
      "Epoch [4/50], Loss: 0.3830\n",
      "Epoch [5/50], Loss: 0.3567\n",
      "Epoch [6/50], Loss: 0.3448\n",
      "Epoch [7/50], Loss: 0.3395\n",
      "Epoch [8/50], Loss: 0.3335\n",
      "Epoch [9/50], Loss: 0.3252\n",
      "Epoch [10/50], Loss: 0.3152\n",
      "Epoch [11/50], Loss: 0.3041\n",
      "Epoch [12/50], Loss: 0.2999\n",
      "Epoch [13/50], Loss: 0.2978\n",
      "Epoch [14/50], Loss: 0.2931\n",
      "Epoch [15/50], Loss: 0.2900\n",
      "Epoch [16/50], Loss: 0.2887\n",
      "Epoch [17/50], Loss: 0.2879\n",
      "Epoch [18/50], Loss: 0.2873\n",
      "Epoch [19/50], Loss: 0.2867\n",
      "Epoch [20/50], Loss: 0.2864\n",
      "Epoch [21/50], Loss: 0.2861\n",
      "Epoch [22/50], Loss: 0.2848\n",
      "Epoch [23/50], Loss: 0.2809\n",
      "Epoch [24/50], Loss: 0.2799\n",
      "Epoch [25/50], Loss: 0.2797\n",
      "Epoch [26/50], Loss: 0.2795\n",
      "Epoch [27/50], Loss: 0.2793\n",
      "Epoch [28/50], Loss: 0.2791\n",
      "Epoch [29/50], Loss: 0.2790\n",
      "Epoch [30/50], Loss: 0.2788\n",
      "Epoch [31/50], Loss: 0.2786\n",
      "Epoch [32/50], Loss: 0.2785\n",
      "Epoch [33/50], Loss: 0.2784\n",
      "Epoch [34/50], Loss: 0.2784\n",
      "Epoch [35/50], Loss: 0.2783\n",
      "Epoch [36/50], Loss: 0.2781\n",
      "Epoch [37/50], Loss: 0.2781\n",
      "Epoch [38/50], Loss: 0.2780\n",
      "Epoch [39/50], Loss: 0.2780\n",
      "Epoch [40/50], Loss: 0.2779\n",
      "Epoch [41/50], Loss: 0.2778\n",
      "Epoch [42/50], Loss: 0.2778\n",
      "Epoch [43/50], Loss: 0.2776\n",
      "Epoch [44/50], Loss: 0.2776\n",
      "Epoch [45/50], Loss: 0.2775\n",
      "Epoch [46/50], Loss: 0.2774\n",
      "Epoch [47/50], Loss: 0.2773\n",
      "Epoch [48/50], Loss: 0.2773\n",
      "Epoch [49/50], Loss: 0.2772\n",
      "Epoch [50/50], Loss: 0.2772\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.269374\n",
      "Number of dead neurons in Default Sparse Autoencoder: 85 out of 128 (66.41%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 85 (66.41%)\n",
      "Active features: 43 (33.59%)\n",
      "Mean activation frequency: 0.2420\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.090159\n",
      "    Dead neurons: 85/128 (66.41%)\n",
      "    Test loss: 0.269374\n",
      "    Mean activation strength: 0.090159\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.8979\n",
      "Epoch [2/50], Loss: 0.3408\n",
      "Epoch [3/50], Loss: 0.2495\n",
      "Epoch [4/50], Loss: 0.2235\n",
      "Epoch [5/50], Loss: 0.2143\n",
      "Epoch [6/50], Loss: 0.2095\n",
      "Epoch [7/50], Loss: 0.2057\n",
      "Epoch [8/50], Loss: 0.2033\n",
      "Epoch [9/50], Loss: 0.2019\n",
      "Epoch [10/50], Loss: 0.2008\n",
      "Epoch [11/50], Loss: 0.2000\n",
      "Epoch [12/50], Loss: 0.1993\n",
      "Epoch [13/50], Loss: 0.1981\n",
      "Epoch [14/50], Loss: 0.1966\n",
      "Epoch [15/50], Loss: 0.1960\n",
      "Epoch [16/50], Loss: 0.1952\n",
      "Epoch [17/50], Loss: 0.1941\n",
      "Epoch [18/50], Loss: 0.1936\n",
      "Epoch [19/50], Loss: 0.1932\n",
      "Epoch [20/50], Loss: 0.1928\n",
      "Epoch [21/50], Loss: 0.1924\n",
      "Epoch [22/50], Loss: 0.1921\n",
      "Epoch [23/50], Loss: 0.1918\n",
      "Epoch [24/50], Loss: 0.1916\n",
      "Epoch [25/50], Loss: 0.1915\n",
      "Epoch [26/50], Loss: 0.1914\n",
      "Epoch [27/50], Loss: 0.1913\n",
      "Epoch [28/50], Loss: 0.1912\n",
      "Epoch [29/50], Loss: 0.1911\n",
      "Epoch [30/50], Loss: 0.1909\n",
      "Epoch [31/50], Loss: 0.1908\n",
      "Epoch [32/50], Loss: 0.1908\n",
      "Epoch [33/50], Loss: 0.1907\n",
      "Epoch [34/50], Loss: 0.1907\n",
      "Epoch [35/50], Loss: 0.1906\n",
      "Epoch [36/50], Loss: 0.1905\n",
      "Epoch [37/50], Loss: 0.1905\n",
      "Epoch [38/50], Loss: 0.1904\n",
      "Epoch [39/50], Loss: 0.1903\n",
      "Epoch [40/50], Loss: 0.1903\n",
      "Epoch [41/50], Loss: 0.1902\n",
      "Epoch [42/50], Loss: 0.1902\n",
      "Epoch [43/50], Loss: 0.1902\n",
      "Epoch [44/50], Loss: 0.1901\n",
      "Epoch [45/50], Loss: 0.1900\n",
      "Epoch [46/50], Loss: 0.1900\n",
      "Epoch [47/50], Loss: 0.1900\n",
      "Epoch [48/50], Loss: 0.1900\n",
      "Epoch [49/50], Loss: 0.1900\n",
      "Epoch [50/50], Loss: 0.1899\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.183733\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 58 out of 128 (45.31%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 58 (45.31%)\n",
      "Active features: 70 (54.69%)\n",
      "Mean activation frequency: 0.3416\n",
      "Median activation frequency: 0.2796\n",
      "Mean activation strength (when active): 0.100068\n",
      "    Dead neurons: 58/128 (45.31%)\n",
      "    Test loss: 0.183733\n",
      "    Mean activation strength: 0.100068\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2928\n",
      "Epoch [2/50], Loss: 0.1111\n",
      "Epoch [3/50], Loss: 0.0813\n",
      "Epoch [4/50], Loss: 0.0729\n",
      "Epoch [5/50], Loss: 0.0698\n",
      "Epoch [6/50], Loss: 0.0683\n",
      "Epoch [7/50], Loss: 0.0671\n",
      "Epoch [8/50], Loss: 0.0662\n",
      "Epoch [9/50], Loss: 0.0658\n",
      "Epoch [10/50], Loss: 0.0654\n",
      "Epoch [11/50], Loss: 0.0651\n",
      "Epoch [12/50], Loss: 0.0649\n",
      "Epoch [13/50], Loss: 0.0647\n",
      "Epoch [14/50], Loss: 0.0646\n",
      "Epoch [15/50], Loss: 0.0643\n",
      "Epoch [16/50], Loss: 0.0638\n",
      "Epoch [17/50], Loss: 0.0636\n",
      "Epoch [18/50], Loss: 0.0632\n",
      "Epoch [19/50], Loss: 0.0630\n",
      "Epoch [20/50], Loss: 0.0629\n",
      "Epoch [21/50], Loss: 0.0628\n",
      "Epoch [22/50], Loss: 0.0627\n",
      "Epoch [23/50], Loss: 0.0626\n",
      "Epoch [24/50], Loss: 0.0625\n",
      "Epoch [25/50], Loss: 0.0624\n",
      "Epoch [26/50], Loss: 0.0624\n",
      "Epoch [27/50], Loss: 0.0623\n",
      "Epoch [28/50], Loss: 0.0623\n",
      "Epoch [29/50], Loss: 0.0622\n",
      "Epoch [30/50], Loss: 0.0622\n",
      "Epoch [31/50], Loss: 0.0622\n",
      "Epoch [32/50], Loss: 0.0621\n",
      "Epoch [33/50], Loss: 0.0621\n",
      "Epoch [34/50], Loss: 0.0621\n",
      "Epoch [35/50], Loss: 0.0621\n",
      "Epoch [36/50], Loss: 0.0621\n",
      "Epoch [37/50], Loss: 0.0621\n",
      "Epoch [38/50], Loss: 0.0620\n",
      "Epoch [39/50], Loss: 0.0620\n",
      "Epoch [40/50], Loss: 0.0620\n",
      "Epoch [41/50], Loss: 0.0620\n",
      "Epoch [42/50], Loss: 0.0620\n",
      "Epoch [43/50], Loss: 0.0620\n",
      "Epoch [44/50], Loss: 0.0619\n",
      "Epoch [45/50], Loss: 0.0619\n",
      "Epoch [46/50], Loss: 0.0619\n",
      "Epoch [47/50], Loss: 0.0619\n",
      "Epoch [48/50], Loss: 0.0619\n",
      "Epoch [49/50], Loss: 0.0619\n",
      "Epoch [50/50], Loss: 0.0619\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.058873\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 58 out of 128 (45.31%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 58 (45.31%)\n",
      "Active features: 70 (54.69%)\n",
      "Mean activation frequency: 0.3388\n",
      "Median activation frequency: 0.2785\n",
      "Mean activation strength (when active): 0.100508\n",
      "    Dead neurons: 58/128 (45.31%)\n",
      "    Test loss: 0.058873\n",
      "    Mean activation strength: 0.100508\n",
      "\n",
      "Hidden Size: 128, k_top: 110\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.2140\n",
      "Epoch [2/50], Loss: 0.5829\n",
      "Epoch [3/50], Loss: 0.4421\n",
      "Epoch [4/50], Loss: 0.3833\n",
      "Epoch [5/50], Loss: 0.3570\n",
      "Epoch [6/50], Loss: 0.3451\n",
      "Epoch [7/50], Loss: 0.3393\n",
      "Epoch [8/50], Loss: 0.3321\n",
      "Epoch [9/50], Loss: 0.3226\n",
      "Epoch [10/50], Loss: 0.3172\n",
      "Epoch [11/50], Loss: 0.3119\n",
      "Epoch [12/50], Loss: 0.3085\n",
      "Epoch [13/50], Loss: 0.3060\n",
      "Epoch [14/50], Loss: 0.3045\n",
      "Epoch [15/50], Loss: 0.3013\n",
      "Epoch [16/50], Loss: 0.2960\n",
      "Epoch [17/50], Loss: 0.2935\n",
      "Epoch [18/50], Loss: 0.2907\n",
      "Epoch [19/50], Loss: 0.2897\n",
      "Epoch [20/50], Loss: 0.2890\n",
      "Epoch [21/50], Loss: 0.2883\n",
      "Epoch [22/50], Loss: 0.2866\n",
      "Epoch [23/50], Loss: 0.2847\n",
      "Epoch [24/50], Loss: 0.2834\n",
      "Epoch [25/50], Loss: 0.2823\n",
      "Epoch [26/50], Loss: 0.2814\n",
      "Epoch [27/50], Loss: 0.2808\n",
      "Epoch [28/50], Loss: 0.2804\n",
      "Epoch [29/50], Loss: 0.2802\n",
      "Epoch [30/50], Loss: 0.2798\n",
      "Epoch [31/50], Loss: 0.2796\n",
      "Epoch [32/50], Loss: 0.2795\n",
      "Epoch [33/50], Loss: 0.2793\n",
      "Epoch [34/50], Loss: 0.2793\n",
      "Epoch [35/50], Loss: 0.2792\n",
      "Epoch [36/50], Loss: 0.2791\n",
      "Epoch [37/50], Loss: 0.2790\n",
      "Epoch [38/50], Loss: 0.2789\n",
      "Epoch [39/50], Loss: 0.2789\n",
      "Epoch [40/50], Loss: 0.2788\n",
      "Epoch [41/50], Loss: 0.2788\n",
      "Epoch [42/50], Loss: 0.2788\n",
      "Epoch [43/50], Loss: 0.2787\n",
      "Epoch [44/50], Loss: 0.2787\n",
      "Epoch [45/50], Loss: 0.2787\n",
      "Epoch [46/50], Loss: 0.2787\n",
      "Epoch [47/50], Loss: 0.2787\n",
      "Epoch [48/50], Loss: 0.2787\n",
      "Epoch [49/50], Loss: 0.2786\n",
      "Epoch [50/50], Loss: 0.2786\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.270375\n",
      "Number of dead neurons in Default Sparse Autoencoder: 85 out of 128 (66.41%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 85 (66.41%)\n",
      "Active features: 43 (33.59%)\n",
      "Mean activation frequency: 0.2464\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.088918\n",
      "    Dead neurons: 85/128 (66.41%)\n",
      "    Test loss: 0.270375\n",
      "    Mean activation strength: 0.088918\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.9006\n",
      "Epoch [2/50], Loss: 0.3424\n",
      "Epoch [3/50], Loss: 0.2502\n",
      "Epoch [4/50], Loss: 0.2257\n",
      "Epoch [5/50], Loss: 0.2147\n",
      "Epoch [6/50], Loss: 0.2093\n",
      "Epoch [7/50], Loss: 0.2060\n",
      "Epoch [8/50], Loss: 0.2035\n",
      "Epoch [9/50], Loss: 0.2017\n",
      "Epoch [10/50], Loss: 0.2005\n",
      "Epoch [11/50], Loss: 0.1996\n",
      "Epoch [12/50], Loss: 0.1990\n",
      "Epoch [13/50], Loss: 0.1986\n",
      "Epoch [14/50], Loss: 0.1982\n",
      "Epoch [15/50], Loss: 0.1976\n",
      "Epoch [16/50], Loss: 0.1960\n",
      "Epoch [17/50], Loss: 0.1957\n",
      "Epoch [18/50], Loss: 0.1954\n",
      "Epoch [19/50], Loss: 0.1952\n",
      "Epoch [20/50], Loss: 0.1951\n",
      "Epoch [21/50], Loss: 0.1949\n",
      "Epoch [22/50], Loss: 0.1948\n",
      "Epoch [23/50], Loss: 0.1946\n",
      "Epoch [24/50], Loss: 0.1945\n",
      "Epoch [25/50], Loss: 0.1944\n",
      "Epoch [26/50], Loss: 0.1942\n",
      "Epoch [27/50], Loss: 0.1941\n",
      "Epoch [28/50], Loss: 0.1940\n",
      "Epoch [29/50], Loss: 0.1938\n",
      "Epoch [30/50], Loss: 0.1937\n",
      "Epoch [31/50], Loss: 0.1936\n",
      "Epoch [32/50], Loss: 0.1935\n",
      "Epoch [33/50], Loss: 0.1935\n",
      "Epoch [34/50], Loss: 0.1934\n",
      "Epoch [35/50], Loss: 0.1933\n",
      "Epoch [36/50], Loss: 0.1933\n",
      "Epoch [37/50], Loss: 0.1933\n",
      "Epoch [38/50], Loss: 0.1933\n",
      "Epoch [39/50], Loss: 0.1932\n",
      "Epoch [40/50], Loss: 0.1932\n",
      "Epoch [41/50], Loss: 0.1931\n",
      "Epoch [42/50], Loss: 0.1931\n",
      "Epoch [43/50], Loss: 0.1931\n",
      "Epoch [44/50], Loss: 0.1931\n",
      "Epoch [45/50], Loss: 0.1931\n",
      "Epoch [46/50], Loss: 0.1931\n",
      "Epoch [47/50], Loss: 0.1931\n",
      "Epoch [48/50], Loss: 0.1930\n",
      "Epoch [49/50], Loss: 0.1931\n",
      "Epoch [50/50], Loss: 0.1930\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.186518\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 59 out of 128 (46.09%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 59 (46.09%)\n",
      "Active features: 69 (53.91%)\n",
      "Mean activation frequency: 0.3371\n",
      "Median activation frequency: 0.2678\n",
      "Mean activation strength (when active): 0.099593\n",
      "    Dead neurons: 59/128 (46.09%)\n",
      "    Test loss: 0.186518\n",
      "    Mean activation strength: 0.099593\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2937\n",
      "Epoch [2/50], Loss: 0.1116\n",
      "Epoch [3/50], Loss: 0.0815\n",
      "Epoch [4/50], Loss: 0.0734\n",
      "Epoch [5/50], Loss: 0.0695\n",
      "Epoch [6/50], Loss: 0.0680\n",
      "Epoch [7/50], Loss: 0.0671\n",
      "Epoch [8/50], Loss: 0.0665\n",
      "Epoch [9/50], Loss: 0.0659\n",
      "Epoch [10/50], Loss: 0.0655\n",
      "Epoch [11/50], Loss: 0.0652\n",
      "Epoch [12/50], Loss: 0.0650\n",
      "Epoch [13/50], Loss: 0.0649\n",
      "Epoch [14/50], Loss: 0.0648\n",
      "Epoch [15/50], Loss: 0.0646\n",
      "Epoch [16/50], Loss: 0.0642\n",
      "Epoch [17/50], Loss: 0.0634\n",
      "Epoch [18/50], Loss: 0.0632\n",
      "Epoch [19/50], Loss: 0.0630\n",
      "Epoch [20/50], Loss: 0.0629\n",
      "Epoch [21/50], Loss: 0.0628\n",
      "Epoch [22/50], Loss: 0.0627\n",
      "Epoch [23/50], Loss: 0.0626\n",
      "Epoch [24/50], Loss: 0.0626\n",
      "Epoch [25/50], Loss: 0.0625\n",
      "Epoch [26/50], Loss: 0.0625\n",
      "Epoch [27/50], Loss: 0.0625\n",
      "Epoch [28/50], Loss: 0.0625\n",
      "Epoch [29/50], Loss: 0.0624\n",
      "Epoch [30/50], Loss: 0.0624\n",
      "Epoch [31/50], Loss: 0.0624\n",
      "Epoch [32/50], Loss: 0.0623\n",
      "Epoch [33/50], Loss: 0.0623\n",
      "Epoch [34/50], Loss: 0.0622\n",
      "Epoch [35/50], Loss: 0.0621\n",
      "Epoch [36/50], Loss: 0.0621\n",
      "Epoch [37/50], Loss: 0.0620\n",
      "Epoch [38/50], Loss: 0.0620\n",
      "Epoch [39/50], Loss: 0.0620\n",
      "Epoch [40/50], Loss: 0.0620\n",
      "Epoch [41/50], Loss: 0.0619\n",
      "Epoch [42/50], Loss: 0.0619\n",
      "Epoch [43/50], Loss: 0.0619\n",
      "Epoch [44/50], Loss: 0.0619\n",
      "Epoch [45/50], Loss: 0.0619\n",
      "Epoch [46/50], Loss: 0.0619\n",
      "Epoch [47/50], Loss: 0.0618\n",
      "Epoch [48/50], Loss: 0.0618\n",
      "Epoch [49/50], Loss: 0.0618\n",
      "Epoch [50/50], Loss: 0.0618\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.058855\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 58 out of 128 (45.31%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 58 (45.31%)\n",
      "Active features: 70 (54.69%)\n",
      "Mean activation frequency: 0.3361\n",
      "Median activation frequency: 0.2928\n",
      "Mean activation strength (when active): 0.100153\n",
      "    Dead neurons: 58/128 (45.31%)\n",
      "    Test loss: 0.058855\n",
      "    Mean activation strength: 0.100153\n",
      "\n",
      "Hidden Size: 128, k_top: 120\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 1.2209\n",
      "Epoch [2/50], Loss: 0.5862\n",
      "Epoch [3/50], Loss: 0.4430\n",
      "Epoch [4/50], Loss: 0.3833\n",
      "Epoch [5/50], Loss: 0.3587\n",
      "Epoch [6/50], Loss: 0.3475\n",
      "Epoch [7/50], Loss: 0.3402\n",
      "Epoch [8/50], Loss: 0.3302\n",
      "Epoch [9/50], Loss: 0.3198\n",
      "Epoch [10/50], Loss: 0.3135\n",
      "Epoch [11/50], Loss: 0.3100\n",
      "Epoch [12/50], Loss: 0.3068\n",
      "Epoch [13/50], Loss: 0.3037\n",
      "Epoch [14/50], Loss: 0.3020\n",
      "Epoch [15/50], Loss: 0.3008\n",
      "Epoch [16/50], Loss: 0.2996\n",
      "Epoch [17/50], Loss: 0.2973\n",
      "Epoch [18/50], Loss: 0.2959\n",
      "Epoch [19/50], Loss: 0.2924\n",
      "Epoch [20/50], Loss: 0.2909\n",
      "Epoch [21/50], Loss: 0.2888\n",
      "Epoch [22/50], Loss: 0.2856\n",
      "Epoch [23/50], Loss: 0.2835\n",
      "Epoch [24/50], Loss: 0.2826\n",
      "Epoch [25/50], Loss: 0.2820\n",
      "Epoch [26/50], Loss: 0.2815\n",
      "Epoch [27/50], Loss: 0.2811\n",
      "Epoch [28/50], Loss: 0.2808\n",
      "Epoch [29/50], Loss: 0.2806\n",
      "Epoch [30/50], Loss: 0.2802\n",
      "Epoch [31/50], Loss: 0.2799\n",
      "Epoch [32/50], Loss: 0.2798\n",
      "Epoch [33/50], Loss: 0.2795\n",
      "Epoch [34/50], Loss: 0.2794\n",
      "Epoch [35/50], Loss: 0.2792\n",
      "Epoch [36/50], Loss: 0.2790\n",
      "Epoch [37/50], Loss: 0.2789\n",
      "Epoch [38/50], Loss: 0.2788\n",
      "Epoch [39/50], Loss: 0.2788\n",
      "Epoch [40/50], Loss: 0.2787\n",
      "Epoch [41/50], Loss: 0.2787\n",
      "Epoch [42/50], Loss: 0.2787\n",
      "Epoch [43/50], Loss: 0.2786\n",
      "Epoch [44/50], Loss: 0.2786\n",
      "Epoch [45/50], Loss: 0.2785\n",
      "Epoch [46/50], Loss: 0.2785\n",
      "Epoch [47/50], Loss: 0.2784\n",
      "Epoch [48/50], Loss: 0.2783\n",
      "Epoch [49/50], Loss: 0.2782\n",
      "Epoch [50/50], Loss: 0.2782\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.270175\n",
      "Number of dead neurons in Default Sparse Autoencoder: 85 out of 128 (66.41%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 128\n",
      "Dead features: 85 (66.41%)\n",
      "Active features: 43 (33.59%)\n",
      "Mean activation frequency: 0.2408\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.089897\n",
      "    Dead neurons: 85/128 (66.41%)\n",
      "    Test loss: 0.270175\n",
      "    Mean activation strength: 0.089897\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.9027\n",
      "Epoch [2/50], Loss: 0.3434\n",
      "Epoch [3/50], Loss: 0.2496\n",
      "Epoch [4/50], Loss: 0.2231\n",
      "Epoch [5/50], Loss: 0.2119\n",
      "Epoch [6/50], Loss: 0.2069\n",
      "Epoch [7/50], Loss: 0.2039\n",
      "Epoch [8/50], Loss: 0.2018\n",
      "Epoch [9/50], Loss: 0.2001\n",
      "Epoch [10/50], Loss: 0.1987\n",
      "Epoch [11/50], Loss: 0.1975\n",
      "Epoch [12/50], Loss: 0.1966\n",
      "Epoch [13/50], Loss: 0.1951\n",
      "Epoch [14/50], Loss: 0.1941\n",
      "Epoch [15/50], Loss: 0.1935\n",
      "Epoch [16/50], Loss: 0.1931\n",
      "Epoch [17/50], Loss: 0.1929\n",
      "Epoch [18/50], Loss: 0.1927\n",
      "Epoch [19/50], Loss: 0.1926\n",
      "Epoch [20/50], Loss: 0.1924\n",
      "Epoch [21/50], Loss: 0.1923\n",
      "Epoch [22/50], Loss: 0.1922\n",
      "Epoch [23/50], Loss: 0.1921\n",
      "Epoch [24/50], Loss: 0.1921\n",
      "Epoch [25/50], Loss: 0.1920\n",
      "Epoch [26/50], Loss: 0.1919\n",
      "Epoch [27/50], Loss: 0.1919\n",
      "Epoch [28/50], Loss: 0.1918\n",
      "Epoch [29/50], Loss: 0.1917\n",
      "Epoch [30/50], Loss: 0.1916\n",
      "Epoch [31/50], Loss: 0.1915\n",
      "Epoch [32/50], Loss: 0.1915\n",
      "Epoch [33/50], Loss: 0.1914\n",
      "Epoch [34/50], Loss: 0.1914\n",
      "Epoch [35/50], Loss: 0.1912\n",
      "Epoch [36/50], Loss: 0.1912\n",
      "Epoch [37/50], Loss: 0.1912\n",
      "Epoch [38/50], Loss: 0.1911\n",
      "Epoch [39/50], Loss: 0.1910\n",
      "Epoch [40/50], Loss: 0.1910\n",
      "Epoch [41/50], Loss: 0.1909\n",
      "Epoch [42/50], Loss: 0.1909\n",
      "Epoch [43/50], Loss: 0.1909\n",
      "Epoch [44/50], Loss: 0.1908\n",
      "Epoch [45/50], Loss: 0.1908\n",
      "Epoch [46/50], Loss: 0.1908\n",
      "Epoch [47/50], Loss: 0.1908\n",
      "Epoch [48/50], Loss: 0.1908\n",
      "Epoch [49/50], Loss: 0.1908\n",
      "Epoch [50/50], Loss: 0.1907\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.184331\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 58 out of 128 (45.31%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 128\n",
      "Dead features: 58 (45.31%)\n",
      "Active features: 70 (54.69%)\n",
      "Mean activation frequency: 0.3340\n",
      "Median activation frequency: 0.2850\n",
      "Mean activation strength (when active): 0.099770\n",
      "    Dead neurons: 58/128 (45.31%)\n",
      "    Test loss: 0.184331\n",
      "    Mean activation strength: 0.099770\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2944\n",
      "Epoch [2/50], Loss: 0.1120\n",
      "Epoch [3/50], Loss: 0.0817\n",
      "Epoch [4/50], Loss: 0.0732\n",
      "Epoch [5/50], Loss: 0.0697\n",
      "Epoch [6/50], Loss: 0.0681\n",
      "Epoch [7/50], Loss: 0.0670\n",
      "Epoch [8/50], Loss: 0.0664\n",
      "Epoch [9/50], Loss: 0.0659\n",
      "Epoch [10/50], Loss: 0.0655\n",
      "Epoch [11/50], Loss: 0.0652\n",
      "Epoch [12/50], Loss: 0.0649\n",
      "Epoch [13/50], Loss: 0.0647\n",
      "Epoch [14/50], Loss: 0.0646\n",
      "Epoch [15/50], Loss: 0.0645\n",
      "Epoch [16/50], Loss: 0.0642\n",
      "Epoch [17/50], Loss: 0.0639\n",
      "Epoch [18/50], Loss: 0.0638\n",
      "Epoch [19/50], Loss: 0.0636\n",
      "Epoch [20/50], Loss: 0.0631\n",
      "Epoch [21/50], Loss: 0.0630\n",
      "Epoch [22/50], Loss: 0.0630\n",
      "Epoch [23/50], Loss: 0.0629\n",
      "Epoch [24/50], Loss: 0.0629\n",
      "Epoch [25/50], Loss: 0.0628\n",
      "Epoch [26/50], Loss: 0.0628\n",
      "Epoch [27/50], Loss: 0.0628\n",
      "Epoch [28/50], Loss: 0.0627\n",
      "Epoch [29/50], Loss: 0.0627\n",
      "Epoch [30/50], Loss: 0.0627\n",
      "Epoch [31/50], Loss: 0.0626\n",
      "Epoch [32/50], Loss: 0.0626\n",
      "Epoch [33/50], Loss: 0.0626\n",
      "Epoch [34/50], Loss: 0.0626\n",
      "Epoch [35/50], Loss: 0.0626\n",
      "Epoch [36/50], Loss: 0.0626\n",
      "Epoch [37/50], Loss: 0.0625\n",
      "Epoch [38/50], Loss: 0.0625\n",
      "Epoch [39/50], Loss: 0.0624\n",
      "Epoch [40/50], Loss: 0.0624\n",
      "Epoch [41/50], Loss: 0.0624\n",
      "Epoch [42/50], Loss: 0.0624\n",
      "Epoch [43/50], Loss: 0.0624\n",
      "Epoch [44/50], Loss: 0.0623\n",
      "Epoch [45/50], Loss: 0.0623\n",
      "Epoch [46/50], Loss: 0.0623\n",
      "Epoch [47/50], Loss: 0.0623\n",
      "Epoch [48/50], Loss: 0.0623\n",
      "Epoch [49/50], Loss: 0.0623\n",
      "Epoch [50/50], Loss: 0.0622\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.059133\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 58 out of 128 (45.31%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 128\n",
      "Dead features: 58 (45.31%)\n",
      "Active features: 70 (54.69%)\n",
      "Mean activation frequency: 0.3351\n",
      "Median activation frequency: 0.2861\n",
      "Mean activation strength (when active): 0.099338\n",
      "    Dead neurons: 58/128 (45.31%)\n",
      "    Test loss: 0.059133\n",
      "    Mean activation strength: 0.099338\n",
      "\n",
      "Hidden Size: 256, k_top: 5\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.7165\n",
      "Epoch [2/50], Loss: 0.4980\n",
      "Epoch [3/50], Loss: 0.4862\n",
      "Epoch [4/50], Loss: 0.4799\n",
      "Epoch [5/50], Loss: 0.4771\n",
      "Epoch [6/50], Loss: 0.4756\n",
      "Epoch [7/50], Loss: 0.4746\n",
      "Epoch [8/50], Loss: 0.4738\n",
      "Epoch [9/50], Loss: 0.4729\n",
      "Epoch [10/50], Loss: 0.4723\n",
      "Epoch [11/50], Loss: 0.4718\n",
      "Epoch [12/50], Loss: 0.4713\n",
      "Epoch [13/50], Loss: 0.4709\n",
      "Epoch [14/50], Loss: 0.4705\n",
      "Epoch [15/50], Loss: 0.4702\n",
      "Epoch [16/50], Loss: 0.4699\n",
      "Epoch [17/50], Loss: 0.4700\n",
      "Epoch [18/50], Loss: 0.4697\n",
      "Epoch [19/50], Loss: 0.4698\n",
      "Epoch [20/50], Loss: 0.4696\n",
      "Epoch [21/50], Loss: 0.4698\n",
      "Epoch [22/50], Loss: 0.4698\n",
      "Epoch [23/50], Loss: 0.4697\n",
      "Epoch [24/50], Loss: 0.4697\n",
      "Epoch [25/50], Loss: 0.4696\n",
      "Epoch [26/50], Loss: 0.4696\n",
      "Epoch [27/50], Loss: 0.4697\n",
      "Epoch [28/50], Loss: 0.4696\n",
      "Epoch [29/50], Loss: 0.4699\n",
      "Epoch [30/50], Loss: 0.4697\n",
      "Epoch [31/50], Loss: 0.4699\n",
      "Epoch [32/50], Loss: 0.4697\n",
      "Epoch [33/50], Loss: 0.4700\n",
      "Epoch [34/50], Loss: 0.4699\n",
      "Epoch [35/50], Loss: 0.4699\n",
      "Epoch [36/50], Loss: 0.4700\n",
      "Epoch [37/50], Loss: 0.4699\n",
      "Epoch [38/50], Loss: 0.4700\n",
      "Epoch [39/50], Loss: 0.4701\n",
      "Epoch [40/50], Loss: 0.4701\n",
      "Epoch [41/50], Loss: 0.4700\n",
      "Epoch [42/50], Loss: 0.4701\n",
      "Epoch [43/50], Loss: 0.4701\n",
      "Epoch [44/50], Loss: 0.4702\n",
      "Epoch [45/50], Loss: 0.4702\n",
      "Epoch [46/50], Loss: 0.4702\n",
      "Epoch [47/50], Loss: 0.4702\n",
      "Epoch [48/50], Loss: 0.4702\n",
      "Epoch [49/50], Loss: 0.4702\n",
      "Epoch [50/50], Loss: 0.4702\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.465247\n",
      "Number of dead neurons in Default Sparse Autoencoder: 224 out of 256 (87.50%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 256\n",
      "Dead features: 224 (87.50%)\n",
      "Active features: 32 (12.50%)\n",
      "Mean activation frequency: 0.0195\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.226054\n",
      "    Dead neurons: 224/256 (87.50%)\n",
      "    Test loss: 0.465247\n",
      "    Mean activation strength: 0.226054\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.6354\n",
      "Epoch [2/50], Loss: 0.4220\n",
      "Epoch [3/50], Loss: 0.4086\n",
      "Epoch [4/50], Loss: 0.4036\n",
      "Epoch [5/50], Loss: 0.4008\n",
      "Epoch [6/50], Loss: 0.3993\n",
      "Epoch [7/50], Loss: 0.3978\n",
      "Epoch [8/50], Loss: 0.3969\n",
      "Epoch [9/50], Loss: 0.3960\n",
      "Epoch [10/50], Loss: 0.3951\n",
      "Epoch [11/50], Loss: 0.3948\n",
      "Epoch [12/50], Loss: 0.3944\n",
      "Epoch [13/50], Loss: 0.3942\n",
      "Epoch [14/50], Loss: 0.3939\n",
      "Epoch [15/50], Loss: 0.3936\n",
      "Epoch [16/50], Loss: 0.3934\n",
      "Epoch [17/50], Loss: 0.3933\n",
      "Epoch [18/50], Loss: 0.3932\n",
      "Epoch [19/50], Loss: 0.3931\n",
      "Epoch [20/50], Loss: 0.3929\n",
      "Epoch [21/50], Loss: 0.3928\n",
      "Epoch [22/50], Loss: 0.3928\n",
      "Epoch [23/50], Loss: 0.3927\n",
      "Epoch [24/50], Loss: 0.3924\n",
      "Epoch [25/50], Loss: 0.3925\n",
      "Epoch [26/50], Loss: 0.3923\n",
      "Epoch [27/50], Loss: 0.3922\n",
      "Epoch [28/50], Loss: 0.3921\n",
      "Epoch [29/50], Loss: 0.3922\n",
      "Epoch [30/50], Loss: 0.3921\n",
      "Epoch [31/50], Loss: 0.3920\n",
      "Epoch [32/50], Loss: 0.3920\n",
      "Epoch [33/50], Loss: 0.3918\n",
      "Epoch [34/50], Loss: 0.3920\n",
      "Epoch [35/50], Loss: 0.3920\n",
      "Epoch [36/50], Loss: 0.3919\n",
      "Epoch [37/50], Loss: 0.3919\n",
      "Epoch [38/50], Loss: 0.3919\n",
      "Epoch [39/50], Loss: 0.3919\n",
      "Epoch [40/50], Loss: 0.3919\n",
      "Epoch [41/50], Loss: 0.3917\n",
      "Epoch [42/50], Loss: 0.3919\n",
      "Epoch [43/50], Loss: 0.3920\n",
      "Epoch [44/50], Loss: 0.3919\n",
      "Epoch [45/50], Loss: 0.3919\n",
      "Epoch [46/50], Loss: 0.3918\n",
      "Epoch [47/50], Loss: 0.3920\n",
      "Epoch [48/50], Loss: 0.3920\n",
      "Epoch [49/50], Loss: 0.3918\n",
      "Epoch [50/50], Loss: 0.3918\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with just weight initialization: 0.389927\n",
      "Number of dead neurons in Sparse Autoencoder with just weight initialization: 172 out of 256 (67.19%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with just weight initialization ===\n",
      "Total features: 256\n",
      "Dead features: 172 (67.19%)\n",
      "Active features: 84 (32.81%)\n",
      "Mean activation frequency: 0.0195\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.243668\n",
      "    Dead neurons: 172/256 (67.19%)\n",
      "    Test loss: 0.389927\n",
      "    Mean activation strength: 0.243668\n",
      "  Training Complete...\n",
      "Epoch [1/50], Loss: 0.2069\n",
      "Epoch [2/50], Loss: 0.1375\n",
      "Epoch [3/50], Loss: 0.1331\n",
      "Epoch [4/50], Loss: 0.1313\n",
      "Epoch [5/50], Loss: 0.1302\n",
      "Epoch [6/50], Loss: 0.1295\n",
      "Epoch [7/50], Loss: 0.1289\n",
      "Epoch [8/50], Loss: 0.1285\n",
      "Epoch [9/50], Loss: 0.1283\n",
      "Epoch [10/50], Loss: 0.1280\n",
      "Epoch [11/50], Loss: 0.1279\n",
      "Epoch [12/50], Loss: 0.1277\n",
      "Epoch [13/50], Loss: 0.1276\n",
      "Epoch [14/50], Loss: 0.1275\n",
      "Epoch [15/50], Loss: 0.1274\n",
      "Epoch [16/50], Loss: 0.1274\n",
      "Epoch [17/50], Loss: 0.1274\n",
      "Epoch [18/50], Loss: 0.1274\n",
      "Epoch [19/50], Loss: 0.1273\n",
      "Epoch [20/50], Loss: 0.1273\n",
      "Epoch [21/50], Loss: 0.1273\n",
      "Epoch [22/50], Loss: 0.1274\n",
      "Epoch [23/50], Loss: 0.1273\n",
      "Epoch [24/50], Loss: 0.1273\n",
      "Epoch [25/50], Loss: 0.1273\n",
      "Epoch [26/50], Loss: 0.1273\n",
      "Epoch [27/50], Loss: 0.1273\n",
      "Epoch [28/50], Loss: 0.1273\n",
      "Epoch [29/50], Loss: 0.1273\n",
      "Epoch [30/50], Loss: 0.1274\n",
      "Epoch [31/50], Loss: 0.1274\n",
      "Epoch [32/50], Loss: 0.1274\n",
      "Epoch [33/50], Loss: 0.1274\n",
      "Epoch [34/50], Loss: 0.1273\n",
      "Epoch [35/50], Loss: 0.1274\n",
      "Epoch [36/50], Loss: 0.1274\n",
      "Epoch [37/50], Loss: 0.1274\n",
      "Epoch [38/50], Loss: 0.1274\n",
      "Epoch [39/50], Loss: 0.1274\n",
      "Epoch [40/50], Loss: 0.1275\n",
      "Epoch [41/50], Loss: 0.1275\n",
      "Epoch [42/50], Loss: 0.1275\n",
      "Epoch [43/50], Loss: 0.1275\n",
      "Epoch [44/50], Loss: 0.1275\n",
      "Epoch [45/50], Loss: 0.1295\n",
      "Epoch [46/50], Loss: 0.1290\n",
      "Epoch [47/50], Loss: 0.1285\n",
      "Epoch [48/50], Loss: 0.1283\n",
      "Epoch [49/50], Loss: 0.1281\n",
      "Epoch [50/50], Loss: 0.1280\n",
      "Finished Training\n",
      "Test Loss for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 0.124872\n",
      "Number of dead neurons in Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss: 172 out of 256 (67.19%)\n",
      "\n",
      "=== Activation Statistics for Sparse Autoencoder with weight init., JumpReLU and Auxiliary Loss ===\n",
      "Total features: 256\n",
      "Dead features: 172 (67.19%)\n",
      "Active features: 84 (32.81%)\n",
      "Mean activation frequency: 0.0195\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.247178\n",
      "    Dead neurons: 172/256 (67.19%)\n",
      "    Test loss: 0.124872\n",
      "    Mean activation strength: 0.247178\n",
      "\n",
      "Hidden Size: 256, k_top: 10\n",
      "  Training SAE...\n",
      "Epoch [1/50], Loss: 0.7021\n",
      "Epoch [2/50], Loss: 0.4320\n",
      "Epoch [3/50], Loss: 0.4097\n",
      "Epoch [4/50], Loss: 0.4043\n",
      "Epoch [5/50], Loss: 0.4015\n",
      "Epoch [6/50], Loss: 0.3995\n",
      "Epoch [7/50], Loss: 0.3978\n",
      "Epoch [8/50], Loss: 0.3963\n",
      "Epoch [9/50], Loss: 0.3952\n",
      "Epoch [10/50], Loss: 0.3944\n",
      "Epoch [11/50], Loss: 0.3937\n",
      "Epoch [12/50], Loss: 0.3932\n",
      "Epoch [13/50], Loss: 0.3928\n",
      "Epoch [14/50], Loss: 0.3924\n",
      "Epoch [15/50], Loss: 0.3922\n",
      "Epoch [16/50], Loss: 0.3919\n",
      "Epoch [17/50], Loss: 0.3918\n",
      "Epoch [18/50], Loss: 0.3914\n",
      "Epoch [19/50], Loss: 0.3912\n",
      "Epoch [20/50], Loss: 0.3908\n",
      "Epoch [21/50], Loss: 0.3908\n",
      "Epoch [22/50], Loss: 0.3906\n",
      "Epoch [23/50], Loss: 0.3904\n",
      "Epoch [24/50], Loss: 0.3902\n",
      "Epoch [25/50], Loss: 0.3901\n",
      "Epoch [26/50], Loss: 0.3901\n",
      "Epoch [27/50], Loss: 0.3900\n",
      "Epoch [28/50], Loss: 0.3899\n",
      "Epoch [29/50], Loss: 0.3898\n",
      "Epoch [30/50], Loss: 0.3897\n",
      "Epoch [31/50], Loss: 0.3896\n",
      "Epoch [32/50], Loss: 0.3896\n",
      "Epoch [33/50], Loss: 0.3896\n",
      "Epoch [34/50], Loss: 0.3895\n",
      "Epoch [35/50], Loss: 0.3896\n",
      "Epoch [36/50], Loss: 0.3896\n",
      "Epoch [37/50], Loss: 0.3894\n",
      "Epoch [38/50], Loss: 0.3895\n",
      "Epoch [39/50], Loss: 0.3894\n",
      "Epoch [40/50], Loss: 0.3894\n",
      "Epoch [41/50], Loss: 0.3894\n",
      "Epoch [42/50], Loss: 0.3893\n",
      "Epoch [43/50], Loss: 0.3894\n",
      "Epoch [44/50], Loss: 0.3895\n",
      "Epoch [45/50], Loss: 0.3895\n",
      "Epoch [46/50], Loss: 0.3896\n",
      "Epoch [47/50], Loss: 0.3897\n",
      "Epoch [48/50], Loss: 0.3891\n",
      "Epoch [49/50], Loss: 0.3890\n",
      "Epoch [50/50], Loss: 0.3885\n",
      "Finished Training\n",
      "Test Loss for Default Sparse Autoencoder: 0.382269\n",
      "Number of dead neurons in Default Sparse Autoencoder: 216 out of 256 (84.38%)\n",
      "\n",
      "=== Activation Statistics for Default Sparse Autoencoder ===\n",
      "Total features: 256\n",
      "Dead features: 216 (84.38%)\n",
      "Active features: 40 (15.62%)\n",
      "Mean activation frequency: 0.0391\n",
      "Median activation frequency: 0.0000\n",
      "Mean activation strength (when active): 0.162069\n",
      "    Dead neurons: 216/256 (84.38%)\n",
      "    Test loss: 0.382269\n",
      "    Mean activation strength: 0.162069\n",
      "  Training SAE_Init...\n",
      "Epoch [1/50], Loss: 0.5931\n",
      "Epoch [2/50], Loss: 0.3582\n",
      "Epoch [3/50], Loss: 0.3399\n",
      "Epoch [4/50], Loss: 0.3316\n",
      "Epoch [5/50], Loss: 0.3261\n",
      "Epoch [6/50], Loss: 0.3225\n",
      "Epoch [7/50], Loss: 0.3202\n",
      "Epoch [8/50], Loss: 0.3181\n",
      "Epoch [9/50], Loss: 0.3169\n",
      "Epoch [10/50], Loss: 0.3162\n",
      "Epoch [11/50], Loss: 0.3159\n",
      "Epoch [12/50], Loss: 0.3157\n",
      "Epoch [13/50], Loss: 0.3156\n",
      "Epoch [14/50], Loss: 0.3153\n",
      "Epoch [15/50], Loss: 0.3151\n",
      "Epoch [16/50], Loss: 0.3151\n",
      "Epoch [17/50], Loss: 0.3149\n",
      "Epoch [18/50], Loss: 0.3149\n",
      "Epoch [19/50], Loss: 0.3150\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 2: Auxiliary Loss Effects\n",
    "# Tests: SAE with/without auxiliary loss\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPERIMENT 2: AUXILIARY LOSS EFFECTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "auxloss_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    for hidden_size in config['hidden_sizes']:\n",
    "        k_top = config['k_tops'][1]  # Use middle k_top value\n",
    "\n",
    "        print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "        # Test with and without auxiliary loss\n",
    "        for use_aux_loss in [False, True]:\n",
    "            model_type = 'SAE_AuxLoss' if use_aux_loss else 'SAE'\n",
    "            print(f\"  Training {'WITH' if use_aux_loss else 'WITHOUT'} auxiliary loss...\")\n",
    "\n",
    "            set_seeds(42)\n",
    "\n",
    "            # Train model\n",
    "            model = train_sparse_autoencoder(\n",
    "                train_loader=train_loader,\n",
    "                num_epochs=config['num_epochs'],\n",
    "                learning_rate=config['learning_rate'],\n",
    "                input_size=config['input_size'],\n",
    "                hidden_size=hidden_size,\n",
    "                k_top=k_top,\n",
    "                modelType=model_type,\n",
    "                dataset_type=dataset_name,\n",
    "                k_aux=2*k_top if use_aux_loss else None,\n",
    "                k_aux_param=1/32,\n",
    "                dead_feature_threshold=1000\n",
    "            )\n",
    "\n",
    "            # Evaluate\n",
    "            test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "            dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "            activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "            # Store results\n",
    "            auxloss_results['dataset'].append(dataset_name)\n",
    "            auxloss_results['hidden_size'].append(hidden_size)\n",
    "            auxloss_results['k_top'].append(k_top)\n",
    "            auxloss_results['aux_loss'].append('Yes' if use_aux_loss else 'No')\n",
    "            auxloss_results['test_loss'].append(test_loss_val)\n",
    "            auxloss_results['dead_neurons'].append(dead_neurons_count)\n",
    "            auxloss_results['dead_neuron_pct'].append(100 * dead_neurons_count / hidden_size)\n",
    "            auxloss_results['active_features'].append(activation_stats['active_features'])\n",
    "            auxloss_results['mean_activation_freq'].append(\n",
    "                activation_stats['mean_activation_frequency']\n",
    "            )\n",
    "\n",
    "            print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "                  f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "df_aux = pd.DataFrame(auxloss_results)\n",
    "df_aux.to_csv('experiment2_auxiliary_loss_results.csv', index=False)\n",
    "print(\"\\nExperiment 2 results saved to 'experiment2_auxiliary_loss_results.csv'\")\n",
    "\n"
   ],
   "id": "6c449b5b79d65d5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT 3: Combined Effects (Init + AuxLoss)\n",
    "# Tests all combinations\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPERIMENT 3: COMBINED EFFECTS (Initialization + Auxiliary Loss)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "combined_results = defaultdict(list)\n",
    "\n",
    "for dataset_name in ['mnist', 'olivetti', 'lfw']:\n",
    "    print(f\"\\n### Processing {dataset_name.upper()} Dataset ###\")\n",
    "\n",
    "    config = experiment_configs[dataset_name]\n",
    "\n",
    "    # Load data\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset_name,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    hidden_size = config['hidden_sizes'][1]  # Use middle size\n",
    "    k_top = config['k_tops'][1]\n",
    "\n",
    "    print(f\"\\nHidden Size: {hidden_size}, k_top: {k_top}\")\n",
    "\n",
    "    # Test all combinations\n",
    "    model_configs = [\n",
    "        ('SAE', 'None', 'None'),\n",
    "        ('SAE_Init', 'Tied', 'None'),\n",
    "        ('SAE_AuxLoss', 'None', 'AuxLoss'),\n",
    "        ('Complete', 'Tied', 'AuxLoss')\n",
    "    ]\n",
    "\n",
    "    for model_type, init_type, aux_type in model_configs:\n",
    "        print(f\"  Training {model_type}...\")\n",
    "\n",
    "        set_seeds(42)\n",
    "\n",
    "        # Train model\n",
    "        model = train_sparse_autoencoder(\n",
    "            train_loader=train_loader,\n",
    "            num_epochs=config['num_epochs'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            input_size=config['input_size'],\n",
    "            hidden_size=hidden_size,\n",
    "            k_top=k_top,\n",
    "            modelType=model_type,\n",
    "            dataset_type=dataset_name,\n",
    "            k_aux=2*k_top if 'AuxLoss' in aux_type else None,\n",
    "            k_aux_param=1/32,\n",
    "            dead_feature_threshold=1000,\n",
    "            JumpReLU=0.1\n",
    "        )\n",
    "\n",
    "        # Evaluate\n",
    "        test_loss_val = test_loss(model, test_loader, dataset_name)\n",
    "        dead_neurons_count = count_dead_neurons(model, train_loader, dataset_name)\n",
    "        activation_stats = get_activation_statistics(model, train_loader, dataset_name)\n",
    "\n",
    "        # Store results\n",
    "        combined_results['dataset'].append(dataset_name)\n",
    "        combined_results['model_type'].append(model_type)\n",
    "        combined_results['initialization'].append(init_type)\n",
    "        combined_results['auxiliary_loss'].append(aux_type)\n",
    "        combined_results['test_loss'].append(test_loss_val)\n",
    "        combined_results['dead_neurons'].append(dead_neurons_count)\n",
    "        combined_results['dead_neuron_pct'].append(100 * dead_neurons_count / hidden_size)\n",
    "        combined_results['active_features'].append(activation_stats['active_features'])\n",
    "\n",
    "        print(f\"    Dead neurons: {dead_neurons_count}/{hidden_size} \"\n",
    "              f\"({100*dead_neurons_count/hidden_size:.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "df_combined = pd.DataFrame(combined_results)\n",
    "df_combined.to_csv('experiment3_combined_effects_results.csv', index=False)\n",
    "print(\"\\nExperiment 3 results saved to 'experiment3_combined_effects_results.csv'\")\n",
    "\n"
   ],
   "id": "dc01c761022b13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ============================================================================\n",
    "# FIGURE GENERATION: Publication-Quality Plots\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING PUBLICATION-QUALITY FIGURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Set style for publication\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Figure 1: Dead Neuron Percentage by Initialization Strategy\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, dataset in enumerate(['mnist', 'olivetti', 'lfw']):\n",
    "    df_subset = df_init[df_init['dataset'] == dataset]\n",
    "\n",
    "    # Group by initialization and hidden size\n",
    "    pivot_data = df_subset.pivot_table(\n",
    "        values='dead_neuron_pct',\n",
    "        index='hidden_size',\n",
    "        columns='initialization',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    pivot_data.plot(kind='bar', ax=axes[idx], width=0.8)\n",
    "    axes[idx].set_title(f'{dataset.upper()} Dataset', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Hidden Size', fontsize=12)\n",
    "    axes[idx].set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "    axes[idx].legend(title='Initialization', fontsize=10)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_dead_neurons_by_initialization.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure1_dead_neurons_by_initialization.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure1_dead_neurons_by_initialization.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 2: Auxiliary Loss Impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: Dead neuron percentage\n",
    "ax = axes[0]\n",
    "df_aux_grouped = df_aux.groupby(['dataset', 'aux_loss'])['dead_neuron_pct'].mean().reset_index()\n",
    "pivot_aux = df_aux_grouped.pivot(index='dataset', columns='aux_loss', values='dead_neuron_pct')\n",
    "pivot_aux.plot(kind='bar', ax=ax, width=0.7, color=['#d62728', '#2ca02c'])\n",
    "ax.set_title('Dead Neuron Percentage\\nWith/Without Auxiliary Loss', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.legend(title='Auxiliary Loss', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel B: Test loss comparison\n",
    "ax = axes[1]\n",
    "df_loss_grouped = df_aux.groupby(['dataset', 'aux_loss'])['test_loss'].mean().reset_index()\n",
    "pivot_loss = df_loss_grouped.pivot(index='dataset', columns='aux_loss', values='test_loss')\n",
    "pivot_loss.plot(kind='bar', ax=ax, width=0.7, color=['#d62728', '#2ca02c'])\n",
    "ax.set_title('Reconstruction Loss\\nWith/Without Auxiliary Loss', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.legend(title='Auxiliary Loss', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2_auxiliary_loss_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure2_auxiliary_loss_effects.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure2_auxiliary_loss_effects.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 3: Combined Effects Summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Panel A: Dead neurons by model type\n",
    "ax = axes[0, 0]\n",
    "df_combined_grouped = df_combined.groupby(['dataset', 'model_type'])['dead_neuron_pct'].mean().reset_index()\n",
    "pivot_combined = df_combined_grouped.pivot(index='dataset', columns='model_type', values='dead_neuron_pct')\n",
    "pivot_combined.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Dead Neuron Percentage by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9, loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel B: Test loss by model type\n",
    "ax = axes[0, 1]\n",
    "df_loss_combined = df_combined.groupby(['dataset', 'model_type'])['test_loss'].mean().reset_index()\n",
    "pivot_loss_combined = df_loss_combined.pivot(index='dataset', columns='model_type', values='test_loss')\n",
    "pivot_loss_combined.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Reconstruction Loss by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9, loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel C: Scatter plot - Dead neurons vs Test loss\n",
    "ax = axes[1, 0]\n",
    "for model_type in df_combined['model_type'].unique():\n",
    "    df_model = df_combined[df_combined['model_type'] == model_type]\n",
    "    ax.scatter(df_model['dead_neuron_pct'], df_model['test_loss'],\n",
    "               label=model_type, s=100, alpha=0.7)\n",
    "ax.set_xlabel('Dead Neurons (%)', fontsize=12)\n",
    "ax.set_ylabel('Test Loss (MSE)', fontsize=12)\n",
    "ax.set_title('Dead Neurons vs Reconstruction Performance', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Model Type', fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel D: Active features comparison\n",
    "ax = axes[1, 1]\n",
    "df_active = df_combined.groupby(['dataset', 'model_type'])['active_features'].mean().reset_index()\n",
    "pivot_active = df_active.pivot(index='dataset', columns='model_type', values='active_features')\n",
    "pivot_active.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Active Feature Count by Model Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Dataset', fontsize=12)\n",
    "ax.set_ylabel('Number of Active Features', fontsize=12)\n",
    "ax.legend(title='Model Type', fontsize=9)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure3_combined_effects_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure3_combined_effects_summary.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure3_combined_effects_summary.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Figure 4: Activation Statistics Histograms\n",
    "# Compare best vs worst configurations\n",
    "print(\"\\nGenerating activation histograms for best/worst models...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, dataset in enumerate(['mnist', 'olivetti', 'lfw']):\n",
    "    print(f\"  Processing {dataset}...\")\n",
    "\n",
    "    config = experiment_configs[dataset]\n",
    "    train_loader, test_loader, dataset_mean = load_data(\n",
    "        dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        img_size=64\n",
    "    )\n",
    "\n",
    "    hidden_size = config['hidden_sizes'][1]\n",
    "    k_top = config['k_tops'][1]\n",
    "\n",
    "    # Train baseline (worst) and complete (best) models\n",
    "    set_seeds(42)\n",
    "    model_baseline = train_sparse_autoencoder(\n",
    "        train_loader, num_epochs=config['num_epochs'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        input_size=config['input_size'], hidden_size=hidden_size,\n",
    "        k_top=k_top, modelType='SAE', dataset_type=dataset\n",
    "    )\n",
    "\n",
    "    set_seeds(42)\n",
    "    model_complete = train_sparse_autoencoder(\n",
    "        train_loader, num_epochs=config['num_epochs'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        input_size=config['input_size'], hidden_size=hidden_size,\n",
    "        k_top=k_top, modelType='Complete', dataset_type=dataset,\n",
    "        k_aux=2*k_top, k_aux_param=1/32, dead_feature_threshold=1000,\n",
    "        JumpReLU=0.1\n",
    "    )\n",
    "\n",
    "    # Get activation statistics\n",
    "    stats_baseline = get_activation_statistics(model_baseline, train_loader, dataset)\n",
    "    stats_complete = get_activation_statistics(model_complete, train_loader, dataset)\n",
    "\n",
    "    # Plot histograms\n",
    "    ax = axes[0, idx]\n",
    "    ax.hist(stats_baseline['activation_frequencies'], bins=50, alpha=0.6,\n",
    "            label='Baseline SAE', color='red', edgecolor='black')\n",
    "    ax.hist(stats_complete['activation_frequencies'], bins=50, alpha=0.6,\n",
    "            label='Complete SAE', color='green', edgecolor='black')\n",
    "    ax.set_xlabel('Activation Frequency', fontsize=11)\n",
    "    ax.set_ylabel('Number of Features', fontsize=11)\n",
    "    ax.set_title(f'{dataset.upper()}: Activation Frequencies', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax = axes[1, idx]\n",
    "    active_base = stats_baseline['activation_strengths'][stats_baseline['activation_strengths'] > 0]\n",
    "    active_complete = stats_complete['activation_strengths'][stats_complete['activation_strengths'] > 0]\n",
    "    ax.hist(active_base, bins=50, alpha=0.6, label='Baseline SAE',\n",
    "            color='red', edgecolor='black')\n",
    "    ax.hist(active_complete, bins=50, alpha=0.6, label='Complete SAE',\n",
    "            color='green', edgecolor='black')\n",
    "    ax.set_xlabel('Mean Activation Strength', fontsize=11)\n",
    "    ax.set_ylabel('Number of Features', fontsize=11)\n",
    "    ax.set_title(f'{dataset.upper()}: Activation Strengths', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure4_activation_histograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('figure4_activation_histograms.pdf', bbox_inches='tight')\n",
    "print(\"Saved: figure4_activation_histograms.png/pdf\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Generate Summary Statistics Table (LaTeX format)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING SUMMARY STATISTICS TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comprehensive summary table\n",
    "summary_stats = []\n",
    "\n",
    "for dataset in ['mnist', 'olivetti', 'lfw']:\n",
    "    for model_type in ['SAE', 'SAE_Init', 'SAE_AuxLoss', 'Complete']:\n",
    "        df_subset = df_combined[\n",
    "            (df_combined['dataset'] == dataset) &\n",
    "            (df_combined['model_type'] == model_type)\n",
    "        ]\n",
    "\n",
    "        if len(df_subset) > 0:\n",
    "            summary_stats.append({\n",
    "                'Dataset': dataset.upper(),\n",
    "                'Model': model_type,\n",
    "                'Dead (%)': f\"{df_subset['dead_neuron_pct'].mean():.2f} ± {df_subset['dead_neuron_pct'].std():.2f}\",\n",
    "                'Test Loss': f\"{df_subset['test_loss'].mean():.6f} ± {df_subset['test_loss'].std():.6f}\",\n",
    "                'Active Features': f\"{df_subset['active_features'].mean():.0f}\"\n",
    "            })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Save as CSV\n",
    "df_summary.to_csv('summary_statistics.csv', index=False)\n",
    "print(\"Saved: summary_statistics.csv\")\n",
    "\n",
    "# Save as LaTeX table\n",
    "latex_table = df_summary.to_latex(index=False, escape=False, column_format='lllll')\n",
    "with open('results/dead neurons/summary_statistics.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "print(\"Saved: summary_statistics.tex\")\n",
    "\n",
    "# Print to console\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  - experiment1_initialization_results.csv\")\n",
    "print(\"  - experiment2_auxiliary_loss_results.csv\")\n",
    "print(\"  - experiment3_combined_effects_results.csv\")\n",
    "print(\"  - figure1_dead_neurons_by_initialization.png/pdf\")\n",
    "print(\"  - figure2_auxiliary_loss_effects.png/pdf\")\n",
    "print(\"  - figure3_combined_effects_summary.png/pdf\")\n",
    "print(\"  - figure4_activation_histograms.png/pdf\")\n",
    "print(\"  - summary_statistics.csv\")\n",
    "print(\"  - summary_statistics.tex\")\n",
    "print(\"\\nReady for inclusion in your paper!\")\n"
   ],
   "id": "3cb8fe1099dc1ceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MSE",
   "id": "7c3b77cf80856bb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
